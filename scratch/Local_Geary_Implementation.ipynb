{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference: https://geodacenter.github.io/workbook/6a_local_auto/lab6a.html#local-geary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate local geary\n",
    "\n",
    "Interestingly, using [this equation](https://www.biomedware.com/files/documentation/spacestat/Statistics/Gearys_C/Geary_s_C_statistic.htm) which explicitly calls for standardization of input data. We also do NOT divide by 2.\n",
    "\n",
    "$$ c_i = \\sum_j w_{ij} (z_i - z_j)^2 $$ \n",
    "\n",
    "where: \n",
    "\n",
    "$z_i = x_i - \\bar{x}$ and $z_j = x_j - \\bar{x}$, and $w_{ij}$ are the elements of the row-standardized binary symmetric spatial weight matrix W. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or, $$ c_i = (1/m^2) * \\sum_j w_{ij} (x_i - x_j)^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ m^2 = \\sum_i (x_iâˆ’\\bar{x})^2/n $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load in example data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal as lp\n",
    "import geopandas as gpd\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "guerry = lp.examples.load_example('Guerry')\n",
    "guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq = lp.weights.Queen.from_dataframe(guerry_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{66: 1.0, 35: 1.0, 68: 1.0, 36: 1.0}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{66: 0.25, 35: 0.25, 68: 0.25, 36: 0.25}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wq.transform = 'r'\n",
    "wq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_i is 5098\n",
      "x_j are 1983 4077 3710 3012\n"
     ]
    }
   ],
   "source": [
    "x = guerry_ds['Donatns']\n",
    "\n",
    "print(\"x_i is\", x[0])\n",
    "print(\"x_j are\", x[66], x[35], x[68], x[36])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    -0.336188\n",
       "1     0.450441\n",
       "2     0.879023\n",
       "3    -0.825375\n",
       "4     0.049370\n",
       "        ...   \n",
       "80    1.512380\n",
       "81    0.454785\n",
       "82    1.467288\n",
       "83   -0.555029\n",
       "84   -0.506214\n",
       "Name: Donatns, Length: 85, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate zscore of input variable\n",
    "zscore_x = (x - np.mean(x))/np.std(x)\n",
    "zscore_x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build observed local geary values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>focal</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   focal  neighbor  weight\n",
       "0      0        66     1.0\n",
       "1      0        35     1.0\n",
       "2      0        68     1.0\n",
       "3      0        36     1.0\n",
       "4      1        48     1.0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list = wq.to_adjlist(remove_symmetric=False)\n",
    "adj_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      True\n",
       "1      True\n",
       "2      True\n",
       "3      True\n",
       "4      True\n",
       "       ... \n",
       "415    True\n",
       "416    True\n",
       "417    True\n",
       "418    True\n",
       "419    True\n",
       "Name: weight, Length: 420, dtype: bool"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list.weight.values == adj_list.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "420"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sum(list(wq.weights.values()), []))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   -0.336188\n",
       "1    0.450441\n",
       "2    0.879023\n",
       "3   -0.825375\n",
       "4    0.049370\n",
       "Name: Donatns, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "zseries = pd.Series(zscore_x, index=wq.id_order)\n",
    "zseries[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.33618783, -0.33618783, -0.33618783, -0.33618783,  0.45044136])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define z_i\n",
    "zi = zseries.loc[adj_list.focal].values\n",
    "zi[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.98050808, -0.54737594, -0.62328783, -0.76766521, -0.5709562 ])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define zj\n",
    "zj = zseries.loc[adj_list.neighbor].values\n",
    "zj[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.64432025, 0.21118812, 0.2871    , 0.43147738, 1.02139756])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(zi-zj)[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#(zi-zj)**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiply by spatial weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sum(list(wq.weights.values()), []) * (zi-zj)**2\n",
    "diff = zi-zj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = sum(list(wq.weights.values()), []) * (diff)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.103787</td>\n",
       "      <td>0</td>\n",
       "      <td>0.644320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.011150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.211188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.020607</td>\n",
       "      <td>0</td>\n",
       "      <td>0.287100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.046543</td>\n",
       "      <td>0</td>\n",
       "      <td>0.431477</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.173875</td>\n",
       "      <td>1</td>\n",
       "      <td>1.021398</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  0         2\n",
       "0  0.103787  0  0.644320\n",
       "1  0.011150  0  0.211188\n",
       "2  0.020607  0  0.287100\n",
       "3  0.046543  0  0.431477\n",
       "4  0.173875  1  1.021398"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "temp = pd.DataFrame(adj_list.focal.values, test).reset_index()\n",
    "temp[2] = diff\n",
    "temp.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporarily rename the columns\n",
    "temp.columns = ['E_ij', 'ID', 'Diff_ij']\n",
    "temp = temp.groupby(by='ID').sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.18208704, 0.56001403, 0.97529461, 0.21590694, 0.61737256])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.E_ij.values[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start building function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Final form of local geary univariate a few cells below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pycodestyle_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator\n",
    "import libpysal as lp\n",
    "from esda.crand import (\n",
    "    crand as _crand_plus,\n",
    "    njit as _njit,\n",
    "    _prepare_univariate\n",
    ")\n",
    "\n",
    "\n",
    "PERMUTATIONS = 999\n",
    "\n",
    "\n",
    "class Local_Geary(BaseEstimator):\n",
    "\n",
    "    \"\"\"Local Geary - Univariate\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None, permutations=PERMUTATIONS, n_jobs=1,\n",
    "                 keep_simulations=True, seed=None):\n",
    "        \"\"\"\n",
    "        Initialize a Local_Geary estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity     : scipy.sparse matrix object\n",
    "                           the connectivity structure describing\n",
    "                           the relationships between observed units.\n",
    "                           Need not be row-standardized.\n",
    "        permutations     : int\n",
    "                           number of random permutations for calculation\n",
    "                           of pseudo p_values\n",
    "        n_jobs           : int\n",
    "                           Number of cores to be used in the conditional\n",
    "                           randomisation. If -1, all available cores are used.\n",
    "        keep_simulations : Boolean\n",
    "                           (default=True)\n",
    "                           If True, the entire matrix of replications under\n",
    "                           the null is stored in memory and accessible;\n",
    "                           otherwise, replications are not saved\n",
    "        seed             : None/int\n",
    "                           Seed to ensure reproducibility of conditional\n",
    "                           randomizations. Must be set here, and not outside\n",
    "                           of the function, since numba does not correctly\n",
    "                           interpret external seeds nor\n",
    "                           numpy.random.RandomState instances.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        localG          : numpy array\n",
    "                          array containing the observed univariate\n",
    "                          Local Geary values.\n",
    "        p_sim           : numpy array\n",
    "                          array containing the simulated\n",
    "                          p-values for each unit.\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "        self.permutations = permutations\n",
    "        self.n_jobs = n_jobs\n",
    "        self.keep_simulations = keep_simulations\n",
    "        self.seed = seed\n",
    "\n",
    "    def fit(self, x, n_jobs=1, permutations=999):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        x                : numpy.ndarray\n",
    "                           array containing continuous data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`Anselin1995`.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Guerry data replication GeoDa tutorial\n",
    "        >>> import libpysal as lp\n",
    "        >>> import geopandas as gpd\n",
    "        >>> guerry = lp.examples.load_example('Guerry')\n",
    "        >>> guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))\n",
    "        >>> w = libpysal.weights.Queen.from_dataframe(guerry_ds)\n",
    "        >>> y = guerry_ds['Donatns']\n",
    "        >>> lG = Local_Geary(connectivity=w).fit(y)\n",
    "        >>> lG.localG[0:5]\n",
    "        >>> lG.p_sim[0:5]\n",
    "        \"\"\"\n",
    "        x = np.asarray(x).flatten()\n",
    "\n",
    "        w = self.connectivity\n",
    "        w.transform = 'r'\n",
    "\n",
    "        self.localG = self._statistic(x, w)\n",
    "\n",
    "        if self.permutations:\n",
    "            self.p_sim, self.rlocalG = _crand_plus(\n",
    "                z=(x - np.mean(x))/np.std(x),\n",
    "                w=w,\n",
    "                observed=self.localG,\n",
    "                permutations=permutations,\n",
    "                keep=True,\n",
    "                n_jobs=n_jobs,\n",
    "                stat_func=_local_geary\n",
    "            )\n",
    "\n",
    "        del (self.keep_simulations, self.n_jobs,\n",
    "             self.permutations, self.seed, self.rlocalG,\n",
    "             self.connectivity)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(x, w):\n",
    "        # Caclulate z-scores for x\n",
    "        zscore_x = (x - np.mean(x))/np.std(x)\n",
    "        # Create focal (xi) and neighbor (zi) values\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "        zseries = pd.Series(zscore_x, index=w.id_order)\n",
    "        zi = zseries.loc[adj_list.focal].values\n",
    "        zj = zseries.loc[adj_list.neighbor].values\n",
    "        # Carry out local Geary calculation\n",
    "        gs = adj_list.weight.values * (zi-zj)**2\n",
    "        # Reorganize data\n",
    "        adj_list_gs = pd.DataFrame(adj_list.focal.values, gs).reset_index()\n",
    "        adj_list_gs.columns = ['gs', 'ID']\n",
    "        adj_list_gs = adj_list_gs.groupby(by='ID').sum()\n",
    "\n",
    "        localG = adj_list_gs.gs.values\n",
    "\n",
    "        return (localG)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Conditional Randomization Function Implementations\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Note: does not using the scaling parameter\n",
    "\n",
    "\n",
    "@_njit(fastmath=True)\n",
    "def _local_geary(i, z, permuted_ids, weights_i, scaling):\n",
    "    zi, zrand = _prepare_univariate(i, z, permuted_ids, weights_i)\n",
    "    return (zi-zrand)**2 @ weights_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "functest = Local_Geary(connectivity=wq).fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.82087039e-01, 5.60014026e-01, 9.75294606e-01, 2.15906938e-01,\n",
       "       6.17372564e-01, 3.84450059e-02, 2.43181756e-01, 9.71802819e-01,\n",
       "       4.06447101e-02, 7.24722785e-01, 6.30952854e-02, 2.42104497e-02,\n",
       "       1.59496916e+01, 9.29326006e-01, 9.65188634e-01, 1.32383286e+00,\n",
       "       3.31775497e-01, 2.99446505e+00, 9.43946814e-01, 2.99570159e+00,\n",
       "       3.66702291e-01, 2.09592365e+00, 1.46515861e+00, 1.82118455e-01,\n",
       "       3.10216680e+00, 5.43063937e-01, 5.74532559e+00, 4.79160197e-02,\n",
       "       1.58993089e-01, 7.18327253e-01, 1.24297849e+00, 8.72629331e-02,\n",
       "       7.52809650e-01, 4.56515485e-01, 3.86766562e-01, 1.17632604e-01,\n",
       "       6.90884685e-01, 2.87206102e+00, 4.10455112e-01, 4.04349959e-01,\n",
       "       1.14211758e-01, 9.59519953e-01, 3.51347976e-01, 7.30240974e-01,\n",
       "       4.40370938e-01, 7.20360356e-02, 1.66241706e+00, 5.83258909e+00,\n",
       "       2.30332507e-01, 4.38369688e-01, 8.41461470e-01, 1.52959486e+00,\n",
       "       4.32157479e-02, 2.08325903e+00, 1.19722984e+00, 1.28169257e+00,\n",
       "       1.32443562e-01, 3.97452281e-01, 3.39175467e+00, 1.55325208e-02,\n",
       "       1.08504192e+00, 1.20141728e+00, 4.42727015e-01, 3.16097426e+00,\n",
       "       3.38714881e+00, 1.61732976e+00, 2.05483294e-01, 2.95666506e+00,\n",
       "       6.42017171e-01, 4.21213806e-01, 2.66678544e-02, 4.02155064e-01,\n",
       "       1.17112566e-01, 4.57596388e-01, 2.18572511e+00, 1.95661321e-01,\n",
       "       5.57923492e-02, 8.23656724e-02, 2.20496135e-02, 1.02137241e-01,\n",
       "       1.43925735e+00, 9.93140340e-01, 8.76795695e-01, 1.22224557e+00,\n",
       "       3.66964823e-01])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functest.localG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.21 , 0.052, 0.073, 0.17 , 0.454, 0.005, 0.18 , 0.403, 0.024,\n",
       "       0.297, 0.01 , 0.015, 0.127, 0.446, 0.012, 0.033, 0.003, 0.162,\n",
       "       0.342, 0.055, 0.002, 0.16 , 0.282, 0.082, 0.074, 0.351, 0.036,\n",
       "       0.011, 0.025, 0.299, 0.234, 0.004, 0.474, 0.003, 0.117, 0.077,\n",
       "       0.319, 0.181, 0.3  , 0.16 , 0.041, 0.34 , 0.202, 0.499, 0.28 ,\n",
       "       0.002, 0.223, 0.025, 0.136, 0.246, 0.288, 0.259, 0.029, 0.067,\n",
       "       0.452, 0.344, 0.072, 0.285, 0.03 , 0.017, 0.259, 0.377, 0.467,\n",
       "       0.121, 0.425, 0.161, 0.073, 0.093, 0.307, 0.194, 0.104, 0.23 ,\n",
       "       0.017, 0.251, 0.011, 0.172, 0.032, 0.037, 0.01 , 0.001, 0.028,\n",
       "       0.473, 0.002, 0.347, 0.258])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functest.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.189, 0.062, 0.074, 0.152, 0.488])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import libpysal as lp\n",
    "import geopandas as gpd\n",
    "guerry = lp.examples.load_example('Guerry')\n",
    "guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))\n",
    "w = lp.weights.Queen.from_dataframe(guerry_ds)\n",
    "y = guerry_ds['Donatns']\n",
    "lG = Local_Geary(connectivity=w).fit(y)\n",
    "lG.localG[0:5]\n",
    "lG.p_sim[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 1.070s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import libpysal\n",
    "from libpysal.common import pandas, RTOL, ATOL\n",
    "from esda.local_geary import Local_Geary\n",
    "import numpy as np\n",
    "\n",
    "PANDAS_EXTINCT = pandas is None\n",
    "\n",
    "#from ..local_geary import Local_Geary\n",
    "\n",
    "class Local_Geary_Tester(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        np.random.seed(10)\n",
    "        self.w = libpysal.io.open(libpysal.examples.get_path(\"stl.gal\")).read()\n",
    "        f = libpysal.io.open(libpysal.examples.get_path(\"stl_hom.txt\"))\n",
    "        self.y = np.array(f.by_col['HR8893'])\n",
    "\n",
    "    def test_local_geary(self):\n",
    "        lG = Local_Geary(connectivity=self.w).fit(self.y)\n",
    "        self.assertAlmostEqual(lG.localG[0], 0.696703432)\n",
    "        self.assertAlmostEqual(lG.p_sim[0], 0.19)\n",
    "        \n",
    "suite = unittest.TestSuite()\n",
    "test_classes = [\n",
    "    Local_Geary_Tester\n",
    "]\n",
    "for i in test_classes:\n",
    "    a = unittest.TestLoader().loadTestsFromTestCase(i)\n",
    "    suite.addTest(a)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    runner = unittest.TextTestRunner()\n",
    "    runner.run(suite)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Identify obs of interest ('GeoDa quads', but not really)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Source](https://geodacenter.github.io/workbook/6a_local_auto/lab6a.html#principle-1)\n",
    "\n",
    ">Those locations identified as significant and with the Local Geary statistic smaller than its mean, suggest positive spatial autocorrelation (small differences imply similarity). For those observations that can be classified in the upper-right or lower-left quadrants of a matching Moran scatter plot, we can identify the association as high-high or low-low. However, given that the squared difference can cross the mean, there may be observations for which such a classification is not possible. We will refer to those as other positive spatial autocorrelation.\n",
    "\n",
    ">For negative spatial autocorrelation (large values imply dissimilarity), it is not possible to assess whether the association is between high-low or low-high outliers, since the squaring of the differences removes the sign."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use a slightly different approach and do not interact with the Local Moran scatterplot. We need to first define the mean of the calculated Local Geary statistic, and define the mean of the input variable (`y`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.157045600541073\n",
      "6723.317647058823\n"
     ]
    }
   ],
   "source": [
    "# Mean of local geary\n",
    "Eij_mean = np.mean(functest.localG); print(Eij_mean)\n",
    "# Mean of x variable\n",
    "y_mean = np.mean(y); print(y_mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify areas as outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    80\n",
       "True      5\n",
       "Name: Donatns, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outliers = (functest.localG < Eij_mean) & (y > y_mean) & (functest.p_sim<=0.05)\n",
    "pd.value_counts(outliers)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify areas as clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    69\n",
       "True     16\n",
       "Name: Donatns, dtype: int64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clusters = (functest.localG < Eij_mean) & (y < y_mean) & (functest.p_sim<=0.05)\n",
    "pd.value_counts(clusters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify areas as 'other'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    79\n",
       "True      6\n",
       "dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "other = (functest.localG > Eij_mean) & (functest.p_sim<=0.05)\n",
    "pd.value_counts(other)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Not significant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     58\n",
       "False    27\n",
       "dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = (functest.p_sim>0.05)\n",
    "pd.value_counts(neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Old implementation - bad\n",
    "#if self.geoda_quads:\n",
    "#    from esda import Moran_Local\n",
    "#    localm = Moran_Local(y=x, \n",
    "#                         w=w, \n",
    "#                         geoda_quads=True)\n",
    "#\n",
    "#    Eij_mean = np.mean(self.localG)\n",
    "#\n",
    "#    # Create empty vector\n",
    "#    self.q = np.ones(len(x))*5\n",
    "#    # 1: high high\n",
    "#    self.q[(self.localG < E_ij_mean) & (self.p_sim<=self.sig) & (localm.q==1)] = 1\n",
    "#    # 2: low low\n",
    "#    self.q[(self.localG < E_ij_mean) & (self.p_sim<=self.sig) & (localm.q==2)] = 2\n",
    "#    # 4: negative - 2*mean appropriate?\n",
    "#    self.q[(self.localG > 2*E_ij_mean) & (self.p_sim<=self.sig) & (localm.q!=2) & (localm.q!=4)] = 4\n",
    "#    # 5: not significant\n",
    "#    self.q[self.p_sim > self.sig] = 0\n",
    "#    # 0: other - all remaining obs? not sure how to define, need to double check...\n",
    "#    # Do nothing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should be 57, this is close enough..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start working on inference (note: now implemented above)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 'New' `_crand()` engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.crand import (\n",
    "    crand as _crand_plus,\n",
    "    njit as _njit,\n",
    "    _prepare_univariate\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_njit(fastmath=True)\n",
    "def _local_geary(i, z, permuted_ids, weights_i, scaling):\n",
    "    zi, zrand = _prepare_univariate(i, z, permuted_ids, weights_i)\n",
    "    return (zi-zrand)**2 @ weights_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.188 0.042 0.058 0.16  0.479 0.003 0.153 0.453 0.017 0.275 0.009 0.007\n",
      " 0.134 0.472 0.01  0.035 0.001 0.146 0.332 0.06  0.002 0.139 0.302 0.095\n",
      " 0.07  0.341 0.023 0.008 0.028 0.283 0.223 0.008 0.496 0.003 0.1   0.086\n",
      " 0.312 0.173 0.3   0.156 0.059 0.362 0.191 0.488 0.275 0.006 0.196 0.018\n",
      " 0.124 0.232 0.284 0.235 0.022 0.056 0.435 0.321 0.071 0.294 0.021 0.016\n",
      " 0.241 0.38  0.449 0.143 0.414 0.129 0.078 0.099 0.318 0.199 0.097 0.231\n",
      " 0.018 0.262 0.003 0.175 0.038 0.037 0.011 0.001 0.033 0.492 0.003 0.333\n",
      " 0.27 ]\n",
      "[[1.73354558 0.48582724 0.39120719 ... 1.09739692 0.30315983 1.15158028]\n",
      " [1.2329202  0.70714724 0.79341306 ... 1.25615194 1.00711015 0.79559242]\n",
      " [1.78399622 1.40691833 1.24765407 ... 2.0946598  1.85841311 1.02120587]\n",
      " ...\n",
      " [3.1149016  3.08453218 2.92127521 ... 3.40044339 3.17740559 3.47494539]\n",
      " [1.1715959  0.44600353 3.85646581 ... 0.21532951 0.49830135 0.22095061]\n",
      " [0.82826412 0.16964085 4.48525585 ... 0.20116451 0.37692207 0.24373652]]\n"
     ]
    }
   ],
   "source": [
    "p_sim, rlocalG = _crand_plus(z=np.array(zscore_x), w=wq, observed=np.array(functest.localG), \n",
    "            permutations=999, keep=True, n_jobs=1, \n",
    "            stat_func=_local_geary)\n",
    "\n",
    "print(p_sim)\n",
    "print(rlocalG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rebuilding function with obs of interest ('GeoDa quads', but not really)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pycodestyle_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator\n",
    "import libpysal as lp\n",
    "from esda.crand import (\n",
    "    crand as _crand_plus,\n",
    "    njit as _njit,\n",
    "    _prepare_univariate\n",
    ")\n",
    "\n",
    "\n",
    "class Local_Geary(BaseEstimator):\n",
    "\n",
    "    \"\"\"Local Geary - Univariate\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None, labels=False, sig=0.05,\n",
    "                 permutations=999, n_jobs=1, keep_simulations=True,\n",
    "                 seed=None):\n",
    "        \"\"\"\n",
    "        Initialize a Local_Geary estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity     : scipy.sparse matrix object\n",
    "                           the connectivity structure describing\n",
    "                           the relationships between observed units.\n",
    "                           Need not be row-standardized.\n",
    "        labels           : boolean\n",
    "                           (default=False)\n",
    "                           If True use, label if an observation\n",
    "                           belongs to an outlier, cluster, other,\n",
    "                           or non-significant group. 1 = outlier,\n",
    "                           2 = cluster, 3 = other, 4 = non-significant.\n",
    "                           Note that this is not the exact same as the\n",
    "                           cluster map produced by GeoDa.\n",
    "        sig              : float\n",
    "                           (default=0.05)\n",
    "                           Default significance threshold used for\n",
    "                           creation of labels groups.\n",
    "        permutations     : int\n",
    "                           (default=999)\n",
    "                           number of random permutations for calculation\n",
    "                           of pseudo p_values\n",
    "        n_jobs           : int\n",
    "                           (default=1)\n",
    "                           Number of cores to be used in the conditional\n",
    "                           randomisation. If -1, all available cores are used.\n",
    "        keep_simulations : Boolean\n",
    "                           (default=True)\n",
    "                           If True, the entire matrix of replications under\n",
    "                           the null is stored in memory and accessible;\n",
    "                           otherwise, replications are not saved\n",
    "        seed             : None/int\n",
    "                           Seed to ensure reproducibility of conditional\n",
    "                           randomizations. Must be set here, and not outside\n",
    "                           of the function, since numba does not correctly\n",
    "                           interpret external seeds nor\n",
    "                           numpy.random.RandomState instances.\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        localG          : numpy array\n",
    "                          array containing the observed univariate\n",
    "                          Local Geary values.\n",
    "        p_sim           : numpy array\n",
    "                          array containing the simulated\n",
    "                          p-values for each unit.\n",
    "        labs            : numpy array\n",
    "                          array containing the labels for if each observation.\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "        self.labels = labels\n",
    "        self.sig = sig\n",
    "        self.permutations = permutations\n",
    "        self.n_jobs = n_jobs\n",
    "        self.keep_simulations = keep_simulations\n",
    "        self.seed = seed\n",
    "\n",
    "    def fit(self, x):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        x                : numpy.ndarray\n",
    "                           array containing continuous data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`Anselin1995`.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Guerry data replication GeoDa tutorial\n",
    "        >>> import libpysal as lp\n",
    "        >>> import geopandas as gpd\n",
    "        >>> guerry = lp.examples.load_example('Guerry')\n",
    "        >>> guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))\n",
    "        >>> w = libpysal.weights.Queen.from_dataframe(guerry_ds)\n",
    "        >>> y = guerry_ds['Donatns']\n",
    "        >>> lG = Local_Geary(connectivity=w).fit(y)\n",
    "        >>> lG.localG[0:5]\n",
    "        >>> lG.p_sim[0:5]\n",
    "        \"\"\"\n",
    "        x = np.asarray(x).flatten()\n",
    "\n",
    "        w = self.connectivity\n",
    "        w.transform = 'r'\n",
    "        \n",
    "        permutations = self.permutations\n",
    "        sig = self.sig\n",
    "        keep_simulations = self.keep_simulations\n",
    "        n_jobs = self.n_jobs\n",
    "        seed = self.seed\n",
    "\n",
    "        self.localG = self._statistic(x, w)\n",
    "\n",
    "        if permutations:\n",
    "            self.p_sim, self.rlocalG = _crand_plus(\n",
    "                z=(x - np.mean(x))/np.std(x),\n",
    "                w=w,\n",
    "                observed=self.localG,\n",
    "                permutations=permutations,\n",
    "                keep=keep_simulations,\n",
    "                n_jobs=n_jobs,\n",
    "                stat_func=_local_geary\n",
    "            )\n",
    "\n",
    "        if self.labels:\n",
    "            Eij_mean = np.mean(self.localG)\n",
    "            x_mean = np.mean(x)\n",
    "            # Create empty vector to fill\n",
    "            self.labs = np.empty(len(x)) * np.nan\n",
    "            # Outliers\n",
    "            self.labs[(self.localG < Eij_mean) &\n",
    "                      (x > x_mean) &\n",
    "                      (self.p_sim <= sig)] = 1\n",
    "            # Clusters\n",
    "            self.labs[(self.localG < Eij_mean) &\n",
    "                      (x < x_mean) &\n",
    "                      (self.p_sim <= sig)] = 2\n",
    "            # Other\n",
    "            self.labs[(self.localG > Eij_mean) &\n",
    "                      (self.p_sim <= sig)] = 3\n",
    "            # Non-significant\n",
    "            self.labs[self.p_sim > sig] = 4\n",
    "\n",
    "        del (self.keep_simulations, self.n_jobs,\n",
    "             self.permutations, self.seed, self.rlocalG,\n",
    "             self.connectivity, self.labels)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(x, w):\n",
    "        # Caclulate z-scores for x\n",
    "        zscore_x = (x - np.mean(x))/np.std(x)\n",
    "        # Create focal (xi) and neighbor (zi) values\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "        zseries = pd.Series(zscore_x, index=w.id_order)\n",
    "        zi = zseries.loc[adj_list.focal].values\n",
    "        zj = zseries.loc[adj_list.neighbor].values\n",
    "        # Carry out local Geary calculation\n",
    "        gs = adj_list.weight.values * (zi-zj)**2\n",
    "        # Reorganize data\n",
    "        adj_list_gs = pd.DataFrame(adj_list.focal.values, gs).reset_index()\n",
    "        adj_list_gs.columns = ['gs', 'ID']\n",
    "        adj_list_gs = adj_list_gs.groupby(by='ID').sum()\n",
    "\n",
    "        localG = adj_list_gs.gs.values\n",
    "\n",
    "        return (localG)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Conditional Randomization Function Implementations\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Note: does not using the scaling parameter\n",
    "\n",
    "@_njit(fastmath=True)\n",
    "def _local_geary(i, z, permuted_ids, weights_i, scaling):\n",
    "    zi, zrand = _prepare_univariate(i, z, permuted_ids, weights_i)\n",
    "    return (zi-zrand)**2 @ weights_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "functest = Local_Geary(connectivity=wq, labels=True).fit(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    58\n",
       "2.0    16\n",
       "3.0     6\n",
       "1.0     5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(functest.labs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "functest = Local_Geary(connectivity=wq, labels=True).fit(guerry_ds['Suicids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.0    52\n",
       "2.0    22\n",
       "1.0     6\n",
       "3.0     5\n",
       "dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(functest.labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try with updated `keep_simulations` parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "functest = Local_Geary(connectivity=wq, labels=True, n_jobs=2, keep_simulations=False).fit(guerry_ds['Suicids'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.179, 0.05 , 0.07 , 0.14 , 0.464, 0.003, 0.15 , 0.445, 0.019,\n",
       "       0.289, 0.01 , 0.012, 0.144, 0.465, 0.006, 0.045, 0.003, 0.158,\n",
       "       0.321, 0.074, 0.002, 0.17 , 0.302, 0.102, 0.071, 0.358, 0.029,\n",
       "       0.01 , 0.037, 0.303, 0.264, 0.008, 0.475, 0.002, 0.128, 0.088,\n",
       "       0.319, 0.2  , 0.313, 0.159, 0.052, 0.361, 0.204, 0.499, 0.29 ,\n",
       "       0.006, 0.237, 0.031, 0.142, 0.249, 0.276, 0.266, 0.023, 0.05 ,\n",
       "       0.434, 0.339, 0.079, 0.292, 0.027, 0.022, 0.255, 0.388, 0.453,\n",
       "       0.126, 0.396, 0.146, 0.081, 0.115, 0.293, 0.176, 0.107, 0.219,\n",
       "       0.013, 0.247, 0.008, 0.148, 0.036, 0.04 , 0.013, 0.002, 0.033,\n",
       "       0.496, 0.003, 0.391, 0.235])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import libpysal as lp\n",
    "import geopandas as gpd\n",
    "guerry = lp.examples.load_example('Guerry')\n",
    "guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))\n",
    "w = libpysal.weights.Queen.from_dataframe(guerry_ds)\n",
    "y = guerry_ds['Donatns']\n",
    "lG = Local_Geary(connectivity=w, n_jobs=2, keep_simulations=False).fit(y)\n",
    "lG.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multivariate Local Geary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ c_i = \\sum_{h=1}^m \\sum_j w_{ij} (x_{hi} - x_{hj})^2 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load in the sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal as lp\n",
    "import geopandas as gpd\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "guerry = lp.examples.load_example('Guerry')\n",
    "guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "wq = lp.weights.Queen.from_dataframe(guerry_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = guerry_ds['Donatns']\n",
    "y = guerry_ds['Suicids']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [x,y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Standardize each variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([-0.33618783,  0.45044136,  0.87902293, -0.82537479,  0.0493701 ,\n",
       "        -0.7312606 , -0.06687644, -0.65803769, -0.64438596, -0.85660829,\n",
       "        -0.72650318, -0.91204259,  4.3657987 , -0.54406643,  1.42281681,\n",
       "         1.35083496,  0.58695866,  1.71053735, -0.86529576,  0.75781212,\n",
       "         0.88398719, -0.42120087, -0.67996319, -0.80551773,  1.03188092,\n",
       "        -0.44891802,  3.56220827, -0.76021881, -0.91783423, -0.80158769,\n",
       "        -0.3407384 , -1.04318193,  0.19912544,  0.9497637 ,  0.10976866,\n",
       "        -0.54737594, -0.76766521,  1.10365593, -0.22697399, -0.67789475,\n",
       "        -0.82268582,  0.32819633, -0.40754914, -0.31633077, -0.47394619,\n",
       "        -0.96871795, -0.47849676, -0.31943343, -0.5709562 , -0.56061398,\n",
       "        -0.95485938, -0.58150526, -0.52276146,  1.65799887,  0.57744381,\n",
       "         0.771257  , -0.13058451, -0.25282954,  0.5209753 , -0.20339373,\n",
       "        -0.15726743, -0.70830087, -0.14940735,  1.01781551,  1.60277142,\n",
       "        -0.14940735, -0.98050808,  1.02960564, -0.62328783, -0.6963039 ,\n",
       "        -0.52110671,  0.10790706, -0.29378473, -0.56185505,  2.11657287,\n",
       "        -0.36390497, -0.67727421, -0.44788379, -0.8841186 , -1.13295239,\n",
       "         1.51238043,  0.4547851 ,  1.46728835, -0.55502918, -0.50621391]),\n",
       " array([-0.04719523, -0.75643306,  2.47837872, -0.71149891, -0.64976635,\n",
       "         0.51194274, -0.32954266,  2.78189981, -0.81525944,  0.95748385,\n",
       "         2.55981588, -0.9072994 , -0.15041284,  1.62303304, -0.34480813,\n",
       "        -0.62974239, -0.54354674,  0.35012231, -0.6511396 ,  1.23079335,\n",
       "         1.31916065, -0.01573813,  0.13327591, -0.40561455, -0.73529134,\n",
       "        -0.68668453, -0.36323529, -0.58202979,  0.62668929,  0.79818638,\n",
       "        -0.55239305, -0.18036894,  0.27666918, -0.36735505, -0.67847694,\n",
       "        -0.00772216, -0.06517528, -0.03646469, -0.70578234,  1.11288511,\n",
       "         4.047082  , -0.29470033, -0.78894406,  0.3917351 ,  0.06336769,\n",
       "        -0.81197001, -0.10087988,  0.60829408, -0.90004989, -0.54070443,\n",
       "        -0.26142287, -0.66634121, -0.73624942, -0.0741174 , -0.34953468,\n",
       "        -0.22788992, -0.7238582 , -0.97478046, -0.07817329, -0.67438912,\n",
       "         1.3295399 ,  0.94141997,  3.56158877,  0.04235371, -0.57145893,\n",
       "        -0.4881056 , -0.62319548,  0.10210623, -0.45773433, -0.23111547,\n",
       "        -1.05021363, -0.86207782, -0.93259282, -1.05570665, -0.38271633,\n",
       "        -0.75627338,  1.03674935,  0.37685286, -0.73890012, -0.55865254,\n",
       "         1.0042703 , -0.46836907, -0.09644076, -0.11138687, -0.75777438])]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy import stats\n",
    "zseries = [stats.zscore(i) for i in variables]\n",
    "zseries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the adj lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>focal</th>\n",
       "      <th>neighbor</th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>68</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>48</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   focal  neighbor  weight\n",
       "0      0        66     1.0\n",
       "1      0        35     1.0\n",
       "2      0        68     1.0\n",
       "3      0        36     1.0\n",
       "4      1        48     1.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list = wq.to_adjlist(remove_symmetric=False)\n",
    "adj_list.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0    -0.336188\n",
       " 1     0.450441\n",
       " 2     0.879023\n",
       " 3    -0.825375\n",
       " 4     0.049370\n",
       "         ...   \n",
       " 80    1.512380\n",
       " 81    0.454785\n",
       " 82    1.467288\n",
       " 83   -0.555029\n",
       " 84   -0.506214\n",
       " Length: 85, dtype: float64,\n",
       " 0    -0.047195\n",
       " 1    -0.756433\n",
       " 2     2.478379\n",
       " 3    -0.711499\n",
       " 4    -0.649766\n",
       "         ...   \n",
       " 80    1.004270\n",
       " 81   -0.468369\n",
       " 82   -0.096441\n",
       " 83   -0.111387\n",
       " 84   -0.757774\n",
       " Length: 85, dtype: float64]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# The zseries\n",
    "zseries = [pd.Series(i, index=wq.id_order) for i in zseries]\n",
    "zseries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The focal values\n",
    "focal = [zseries[i].loc[adj_list.focal].values for\n",
    "         i in range(len(variables))]\n",
    "# The neighbor values\n",
    "neighbor = [zseries[i].loc[adj_list.neighbor].values for\n",
    "            i in range(len(variables))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.3361878263899247"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(focal)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.9805080804028404"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(neighbor)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4151485897312682"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(np.array(focal)[0][0] - np.array(neighbor)[0][0])**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4151485897312682"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = (np.array(focal) - np.array(neighbor))**2\n",
    "temp[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = sum(list(wq.weights.values()), []) * (np.array(focal) - np.array(neighbor))**2\n",
    "#gs_2 = adj_list.weight.values * (np.array(focal) - np.array(neighbor))**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sum(list(wq.weights.values()), [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp = pd.DataFrame(gs).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp['ID'] = adj_list.focal.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ID</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.728348</td>\n",
       "      <td>0.502200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3.360084</td>\n",
       "      <td>0.282630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.851768</td>\n",
       "      <td>29.604873</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.863628</td>\n",
       "      <td>0.121489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.852118</td>\n",
       "      <td>0.475642</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0          1\n",
       "ID                     \n",
       "0   0.728348   0.502200\n",
       "1   3.360084   0.282630\n",
       "2   5.851768  29.604873\n",
       "3   0.863628   0.121489\n",
       "4   1.852118   0.475642"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list_gs = temp.groupby(by='ID').sum()\n",
    "adj_list_gs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k = len(variables)\n",
    "k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "0      0.615274\n",
       "1      1.821357\n",
       "2     17.728320\n",
       "3      0.492558\n",
       "4      1.163880\n",
       "        ...    \n",
       "80     6.629720\n",
       "81     3.154587\n",
       "82     3.872022\n",
       "83     4.307689\n",
       "84     1.080905\n",
       "Length: 85, dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list_gs.sum(axis=1)/k"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rough cut of function, final form at end of notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator\n",
    "import libpysal as lp\n",
    "\n",
    "PERMUTATIONS=999\n",
    "\n",
    "class Local_Geary_MV(BaseEstimator):\n",
    "    \"\"\"Local Geary - Multivariate\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None, permutations=999):\n",
    "        \"\"\"\n",
    "        connectivity     : scipy.sparse matrix object\n",
    "                           the connectivity structure describing\n",
    "                           the relationships between observed units.\n",
    "                           Need not be row-standardized.\n",
    "        permutations     : int\n",
    "                           number of random permutations for calculation of pseudo\n",
    "                           p_values                           \n",
    "        Attributes\n",
    "        ----------\n",
    "        localG          : numpy array\n",
    "                          array containing the observed multivariate\n",
    "                          Local Geary values.\n",
    "        p_sim           : numpy array\n",
    "                          array containing the simulated\n",
    "                          p-values for each unit.\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "        self.permutations = permutations\n",
    "\n",
    "    def fit(self, variables, permutations=999):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        variables        : numpy.ndarray\n",
    "                           array containing continuous data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`Anselin1995`.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Guerry data replication GeoDa tutorial\n",
    "        >>> import libpysal\n",
    "        >>> import geopandas as gpd\n",
    "        >>> guerry = lp.examples.load_example('Guerry')\n",
    "        >>> guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))\n",
    "        >>> w = libpysal.weights.Queen.from_dataframe(guerry_ds)\n",
    "        \"\"\"\n",
    "        self.variables = np.array(variables, dtype='float')\n",
    "\n",
    "        w = self.connectivity\n",
    "        w.transform = 'r'\n",
    "\n",
    "        self.localG = self._statistic(variables, w)\n",
    "\n",
    "        if permutations:\n",
    "            pass\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(variables, w):\n",
    "        # Caclulate z-scores for input variables\n",
    "        zseries = [stats.zscore(i) for i in variables]\n",
    "        # Define denominator adjustment\n",
    "        k = len(variables)\n",
    "        # Create focal and neighbor values\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "        zseries = [pd.Series(i, index=w.id_order) for i in zseries]\n",
    "        focal = [zseries[i].loc[adj_list.focal].values for\n",
    "                 i in range(len(variables))]\n",
    "        neighbor = [zseries[i].loc[adj_list.neighbor].values for\n",
    "                    i in range(len(variables))]\n",
    "        # Carry out local Geary calculation\n",
    "        gs = adj_list.weight.values * \\\n",
    "        (np.array(focal) - np.array(neighbor))**2\n",
    "        # Reorganize data\n",
    "        temp = pd.DataFrame(gs).T\n",
    "        temp['ID'] = adj_list.focal.values\n",
    "        adj_list_gs = temp.groupby(by='ID').sum()\n",
    "        localG = adj_list_gs.sum(axis=1)/k\n",
    "        \n",
    "        return (localG)\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Conditional Randomization Function Implementations\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Note: does not using the scaling parameter\n",
    "\n",
    "@_njit(fastmath=True)\n",
    "def _local_geary(i, z, permuted_ids, weights_i, scaling):\n",
    "    zi, zrand = _prepare_univariate(i, z, permuted_ids, weights_i)\n",
    "    return (zi-zrand)**2 @ weights_i    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID\n",
       "0     0.153819\n",
       "1     0.303560\n",
       "2     2.954720\n",
       "3     0.123140\n",
       "4     0.387960\n",
       "        ...   \n",
       "80    1.657430\n",
       "81    0.525764\n",
       "82    0.645337\n",
       "83    0.717948\n",
       "84    0.216181\n",
       "Length: 85, dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "functest = Local_Geary_MV(connectivity=wq).fit([x,y])\n",
    "functest.localG"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Working on inference - unlikely that numba will work..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal as lp\n",
    "import geopandas as gpd\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "guerry = lp.examples.load_example('Guerry')\n",
    "guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))\n",
    "x = guerry_ds['Donatns']\n",
    "y = guerry_ds['Suicids']\n",
    "variables = np.array([x,y])\n",
    "wq = lp.weights.Queen.from_dataframe(guerry_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "zseries = np.array([stats.zscore(i) for i in variables])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations = 99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Get length based on first variable\n",
    "n = len(variables[0])\n",
    "joins = np.zeros((n, permutations))\n",
    "n_1 = n - 1\n",
    "prange = list(range(permutations))\n",
    "k = wq.max_neighbors + 1\n",
    "nn = n - 1\n",
    "rids = np.array([np.random.permutation(nn)[0:k] for i in prange])\n",
    "ids = np.arange(wq.n)\n",
    "ido = wq.id_order\n",
    "w = [wq.weights[ido[i]] for i in ids]\n",
    "wc = [wq.cardinalities[ido[i]] for i in ids]\n",
    "\n",
    "for i in range(wq.n):\n",
    "    idsi = ids[ids != i]\n",
    "    np.random.shuffle(idsi)\n",
    "    vars_rand = []\n",
    "    for j in range(variables.shape[0]):\n",
    "        vars_rand.append(zseries[j][idsi[rids[:, 0:wc[i]]]])\n",
    "    # vars rand as tmp\n",
    "    # Calculate diff\n",
    "    diff = []\n",
    "    for z in range(variables.shape[0]):\n",
    "        diff.append((np.array((zseries[z][i] - vars_rand[z])**2 * w[i])).sum(1))\n",
    "    # add up differences\n",
    "    temp = np.array([sum(x) for x in zip(*diff)])\n",
    "    # Assign to object to be returned\n",
    "    joins[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(99, 85)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = np.array(np.transpose(joins)); sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "above = sim >= np.array(functest.localG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.09, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.03, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.09, 0.01, 0.03, 0.01, 0.01, 0.01, 0.02, 0.01, 0.01, 0.04,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.25, 0.01, 0.21,\n",
       "       0.02, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01,\n",
       "       0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.01])"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "larger = above.sum(0)\n",
    "low_extreme = (permutations - larger) < larger\n",
    "larger[low_extreme] = permutations - larger[low_extreme]\n",
    "p_sim = (larger + 1.0) / (permutations + 1.0)\n",
    "p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "permutations=999"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get length based on first variable\n",
    "nvars = variables.shape[0]\n",
    "n = len(variables[0])\n",
    "joins = np.zeros((n, permutations))\n",
    "n_1 = n - 1\n",
    "prange = list(range(permutations))\n",
    "k = wq.max_neighbors + 1\n",
    "nn = n - 1\n",
    "rids = np.array([np.random.permutation(nn)[0:k] for i in prange])\n",
    "ids = np.arange(wq.n)\n",
    "ido = wq.id_order\n",
    "w = [wq.weights[ido[i]] for i in ids]\n",
    "wc = [wq.cardinalities[ido[i]] for i in ids]\n",
    "\n",
    "for i in range(wq.n):\n",
    "    idsi = ids[ids != i]\n",
    "    np.random.shuffle(idsi)\n",
    "    vars_rand = []\n",
    "    for j in range(nvars):\n",
    "        vars_rand.append(zseries[j][idsi[rids[:, 0:wc[i]]]])\n",
    "    # vars rand as tmp\n",
    "    # Calculate diff\n",
    "    diff = []\n",
    "    for z in range(nvars):\n",
    "        diff.append((np.array((zseries[z][i] - vars_rand[z])**2 * w[i])).sum(1)/nvars)\n",
    "    # add up differences\n",
    "    temp = np.array([sum(x) for x in zip(*diff)])\n",
    "    # Assign to object to be returned\n",
    "    joins[i] = temp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(999, 85)\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.001, 0.001, 0.001, 0.027, 0.001, 0.001, 0.002, 0.001,\n",
       "       0.001, 0.001, 0.001, 0.002, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.004, 0.001, 0.001, 0.243, 0.001, 0.001, 0.001, 0.004,\n",
       "       0.013, 0.001, 0.001, 0.085, 0.072, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.012, 0.001, 0.001, 0.001, 0.006, 0.001, 0.001, 0.001,\n",
       "       0.205, 0.001, 0.285, 0.001, 0.001, 0.003, 0.066, 0.001, 0.001,\n",
       "       0.088, 0.002, 0.001, 0.001, 0.003, 0.001, 0.001, 0.058, 0.001,\n",
       "       0.221, 0.002, 0.409, 0.015, 0.004, 0.012, 0.001, 0.001, 0.002,\n",
       "       0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001, 0.001,\n",
       "       0.001, 0.001, 0.004, 0.001])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = np.array(np.transpose(joins)); print(sim.shape)\n",
    "print()\n",
    "above = sim >= np.array(functest.localG)\n",
    "larger = above.sum(0)\n",
    "low_extreme = (permutations - larger) < larger\n",
    "larger[low_extreme] = permutations - larger[low_extreme]\n",
    "p_sim = (larger + 1.0) / (permutations + 1.0)\n",
    "p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement into final form of function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pycodestyle_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator\n",
    "import libpysal as lp\n",
    "\n",
    "\n",
    "class Local_Geary_MV(BaseEstimator):\n",
    "\n",
    "    \"\"\"Local Geary - Multivariate\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None, permutations=999):\n",
    "        \"\"\"\n",
    "        Initialize a Local_Geary_MV estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity     : scipy.sparse matrix object\n",
    "                           the connectivity structure describing\n",
    "                           the relationships between observed units.\n",
    "                           Need not be row-standardized.\n",
    "        permutations     : int\n",
    "                           (default=999)\n",
    "                           number of random permutations for calculation\n",
    "                           of pseudo p_values\n",
    "        Attributes\n",
    "        ----------\n",
    "        localG          : numpy array\n",
    "                          array containing the observed multivariate\n",
    "                          Local Geary values.\n",
    "        p_sim           : numpy array\n",
    "                          array containing the simulated\n",
    "                          p-values for each unit.\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "        self.permutations = permutations\n",
    "\n",
    "    def fit(self, variables):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        variables        : numpy.ndarray\n",
    "                           array containing continuous data\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`Anselin1995`.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        Guerry data replication GeoDa tutorial\n",
    "        >>> import libpysal\n",
    "        >>> import geopandas as gpd\n",
    "        >>> guerry = lp.examples.load_example('Guerry')\n",
    "        >>> guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))\n",
    "        >>> w = libpysal.weights.Queen.from_dataframe(guerry_ds)\n",
    "        >>> import libpysal\n",
    "        >>> import geopandas as gpd\n",
    "        >>> guerry = lp.examples.load_example('Guerry')\n",
    "        >>> guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))\n",
    "        >>> w = libpysal.weights.Queen.from_dataframe(guerry_ds)\n",
    "        >>> x1 = guerry_ds['Donatns']\n",
    "        >>> x2 = guerry_ds['Suicids']\n",
    "        >>> lG_mv = Local_Geary(connectivity=w).fit([x1,x2])\n",
    "        >>> lG_mv.localG[0:5]\n",
    "        >>> lG_mv.p_sim[0:5]\n",
    "        \"\"\"\n",
    "        self.variables = np.array(variables, dtype='float')\n",
    "\n",
    "        w = self.connectivity\n",
    "        w.transform = 'r'\n",
    "\n",
    "        self.n = len(variables[0])\n",
    "        self.w = w\n",
    "        \n",
    "        permutations = self.permutations\n",
    "\n",
    "        # Caclulate z-scores for input variables\n",
    "        # to be used in _statistic and _crand\n",
    "        zvariables = [stats.zscore(i) for i in variables]\n",
    "\n",
    "        self.localG = self._statistic(variables, zvariables, w)\n",
    "\n",
    "        if permutations:\n",
    "            self._crand(zvariables)\n",
    "            sim = np.transpose(self.Gs)\n",
    "            above = sim >= self.localG\n",
    "            larger = above.sum(0)\n",
    "            low_extreme = (permutations - larger) < larger\n",
    "            larger[low_extreme] = permutations - larger[low_extreme]\n",
    "            self.p_sim = (larger + 1.0) / (permutations + 1.0)\n",
    "\n",
    "        del (self.n, self.permutations, self.Gs,\n",
    "             self.connectivity)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(variables, zvariables, w):\n",
    "        # Define denominator adjustment\n",
    "        k = len(variables)\n",
    "        # Create focal and neighbor values\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "        zseries = [pd.Series(i, index=w.id_order) for i in zvariables]\n",
    "        focal = [zseries[i].loc[adj_list.focal].values for\n",
    "                 i in range(len(variables))]\n",
    "        neighbor = [zseries[i].loc[adj_list.neighbor].values for\n",
    "                    i in range(len(variables))]\n",
    "        # Carry out local Geary calculation\n",
    "        gs = adj_list.weight.values * \\\n",
    "            (np.array(focal) - np.array(neighbor))**2\n",
    "        # Reorganize data\n",
    "        temp = pd.DataFrame(gs).T\n",
    "        temp['ID'] = adj_list.focal.values\n",
    "        adj_list_gs = temp.groupby(by='ID').sum()\n",
    "        localG = np.array(adj_list_gs.sum(axis=1)/k)\n",
    "\n",
    "        return (localG)\n",
    "\n",
    "    def _crand(self, zvariables):\n",
    "        \"\"\"\n",
    "        conditional randomization\n",
    "\n",
    "        for observation i with ni neighbors,  the candidate set cannot include\n",
    "        i (we don't want i being a neighbor of i). we have to sample without\n",
    "        replacement from a set of ids that doesn't include i. numpy doesn't\n",
    "        directly support sampling wo replacement and it is expensive to\n",
    "        implement this. instead we omit i from the original ids,  permute the\n",
    "        ids and take the first ni elements of the permuted ids as the\n",
    "        neighbors to i in each randomization.\n",
    "\n",
    "        \"\"\"\n",
    "        nvars = self.variables.shape[0]\n",
    "        n = self.variables.shape[1]\n",
    "        Gs = np.zeros((self.n, self.permutations))\n",
    "        n_1 = self.n - 1\n",
    "        prange = list(range(self.permutations))\n",
    "        k = self.w.max_neighbors + 1\n",
    "        nn = self.n - 1\n",
    "        rids = np.array([np.random.permutation(nn)[0:k] for i in prange])\n",
    "        ids = np.arange(self.w.n)\n",
    "        ido = self.w.id_order\n",
    "        w = [self.w.weights[ido[i]] for i in ids]\n",
    "        wc = [self.w.cardinalities[ido[i]] for i in ids]\n",
    "\n",
    "        for i in range(self.w.n):\n",
    "            idsi = ids[ids != i]\n",
    "            np.random.shuffle(idsi)\n",
    "            vars_rand = []\n",
    "            for j in range(nvars):\n",
    "                vars_rand.append(zvariables[j][idsi[rids[:, 0:wc[i]]]])\n",
    "            # vars rand as tmp\n",
    "            # Calculate diff\n",
    "            diff = []\n",
    "            for z in range(nvars):\n",
    "                diff.append((np.array((zvariables[z][i]-vars_rand[z])**2\n",
    "                                      * w[i])).sum(1)/nvars)\n",
    "            # add up differences\n",
    "            temp = np.array([sum(x) for x in zip(*diff)])\n",
    "            # Assign to object to be returned\n",
    "            Gs[i] = temp\n",
    "        self.Gs = Gs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test on data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "finaltest = Local_Geary_MV(connectivity=wq).fit([x,y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.15381853, 0.30355953, 2.95472008, 0.12313959, 0.38795991,\n",
       "       1.30965103, 0.23377826, 3.06565788, 0.03298004, 0.91999877,\n",
       "       2.98954356, 0.0547241 , 8.12866872, 1.79010883, 0.50938085,\n",
       "       0.98143553, 1.23413236, 1.81836585, 0.55610066, 2.35686284,\n",
       "       1.06675706, 1.12552938, 0.74266791, 0.2087418 , 1.63044552,\n",
       "       0.3321312 , 3.52879191, 0.97300142, 1.2151608 , 1.11753386,\n",
       "       0.73890484, 1.34938525, 0.53489888, 0.49244999, 0.26092712,\n",
       "       0.26520938, 0.40195695, 1.67716168, 0.23640991, 1.4606562 ,\n",
       "       5.85492147, 0.74226135, 0.21032708, 0.90616062, 0.31530565,\n",
       "       4.30743642, 0.95572731, 3.15545158, 0.1576923 , 0.29022339,\n",
       "       0.5313531 , 0.81757624, 0.08418979, 1.28639067, 0.6360191 ,\n",
       "       1.32843439, 0.06698162, 0.21321003, 1.80717048, 0.01005432,\n",
       "       1.35896344, 1.90771844, 4.07391556, 3.66613113, 1.72818279,\n",
       "       0.84588107, 0.57173376, 1.58384441, 1.14442728, 0.26679484,\n",
       "       0.01680013, 0.20773941, 0.06654543, 0.25644334, 1.30015845,\n",
       "       0.10450023, 0.4689966 , 0.50278497, 0.0212912 , 0.16336422,\n",
       "       1.65743005, 0.52576449, 0.64533705, 0.71794809, 0.21618102])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaltest.localG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.013, 0.008, 0.02 , 0.019, 0.234, 0.471, 0.118, 0.068, 0.001,\n",
       "       0.063, 0.036, 0.002, 0.129, 0.14 , 0.003, 0.03 , 0.443, 0.109,\n",
       "       0.1  , 0.288, 0.004, 0.39 , 0.49 , 0.03 , 0.452, 0.088, 0.048,\n",
       "       0.382, 0.353, 0.232, 0.458, 0.448, 0.084, 0.01 , 0.034, 0.037,\n",
       "       0.127, 0.361, 0.044, 0.268, 0.012, 0.493, 0.017, 0.496, 0.056,\n",
       "       0.039, 0.485, 0.04 , 0.014, 0.073, 0.146, 0.38 , 0.006, 0.062,\n",
       "       0.309, 0.39 , 0.005, 0.011, 0.163, 0.003, 0.122, 0.262, 0.025,\n",
       "       0.048, 0.245, 0.372, 0.188, 0.379, 0.48 , 0.043, 0.001, 0.019,\n",
       "       0.001, 0.013, 0.008, 0.006, 0.004, 0.086, 0.001, 0.001, 0.054,\n",
       "       0.117, 0.002, 0.391, 0.041])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finaltest.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tests (multivariate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.211\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.090s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "import unittest\n",
    "import libpysal\n",
    "from libpysal.common import pandas, RTOL, ATOL\n",
    "from esda.local_geary import Local_Geary\n",
    "import numpy as np\n",
    "\n",
    "PANDAS_EXTINCT = pandas is None\n",
    "\n",
    "#from ..local_geary_mv import Local_Geary_MV\n",
    "\n",
    "class Local_Geary_MV_Tester(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        np.random.seed(100)\n",
    "        self.w = libpysal.io.open(libpysal.examples.get_path(\"stl.gal\")).read()\n",
    "        f = libpysal.io.open(libpysal.examples.get_path(\"stl_hom.txt\"))\n",
    "        self.y1 = np.array(f.by_col['HR8893'])\n",
    "        self.y2 = np.array(f.by_col['HC8488'])\n",
    "\n",
    "    def test_local_geary_mv(self):\n",
    "        lG_mv = Local_Geary_MV(connectivity=self.w).fit([self.y1, self.y2])\n",
    "        print(lG_mv.p_sim[0])\n",
    "        self.assertAlmostEqual(lG_mv.localG[0], 0.4096931479581422)\n",
    "        self.assertAlmostEqual(lG_mv.p_sim[0], 0.211)\n",
    "        \n",
    "suite = unittest.TestSuite()\n",
    "test_classes = [\n",
    "    Local_Geary_MV_Tester\n",
    "]\n",
    "for i in test_classes:\n",
    "    a = unittest.TestLoader().loadTestsFromTestCase(i)\n",
    "    suite.addTest(a)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    runner = unittest.TextTestRunner()\n",
    "    runner.run(suite)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "yeetw = libpysal.io.open(libpysal.examples.get_path(\"stl.gal\")).read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = libpysal.io.open(libpysal.examples.get_path(\"stl_hom.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "y1 = np.array(f.by_col['HR8893'])\n",
    "y2 = np.array(f.by_col['HC8488'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "lG_mv_test = Local_Geary_MV(connectivity = yeetw).fit([y1, y2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4096931479581422"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lG_mv_test.localG[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.204"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lG_mv_test.p_sim[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
