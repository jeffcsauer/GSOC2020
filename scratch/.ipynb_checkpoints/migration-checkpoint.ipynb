{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook\n",
    "\n",
    "The purpose of this notebook is to migrate the workbook pseudo code of `LOSH_*.ipynb` and `OLJC_*.ipynb` into functions that match the `PySAL` structure. These will be expanded over time and built out. \n",
    "\n",
    "**Table of contents**\n",
    "1. [Univariate Local Join Counts](#ULJC)\n",
    "2. [Bivariate Local Join Counts](#BVLJC)\n",
    "3. [Multivariate Local Join Counts](#MVLJC)\n",
    "4. [LOSH](#LOSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pep8 styling throughout notebook\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn pep8 style checking ON\n",
    "#%pycodestyle_on\n",
    "# Note that you can turn on line numbers with ESC+L!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn pep8 style checking OFF to resume testing functions\n",
    "#%pycodestyle_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LJC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate <a name=\"ULJC\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First draft of implementation is in 'legacy' format (matching functions like moran.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Univariate local join counts for binary attributes\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Sergio J. Rey <srey@asu.edu> , Luc Anselin <luc.anselin@asu.edu>\"\n",
    "\n",
    "from libpysal.weights.spatial_lag import lag_spatial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Join_Counts_Local_old(object):\n",
    "\n",
    "    \"\"\"Univariate Local Join Counts\n",
    "    Parameters\n",
    "    ----------\n",
    "    y               : array\n",
    "                      binary variable measured across n spatial units\n",
    "    w               : W\n",
    "                      spatial weights instance\n",
    "    Attributes\n",
    "    ----------\n",
    "    y            : array\n",
    "                   original variable\n",
    "    w            : W\n",
    "                   original w object\n",
    "    bb           : float\n",
    "                   number of black-black joins\n",
    "    Notes\n",
    "    -----\n",
    "    Technical details and derivations can be found in :cite:`anselinli2019`.\n",
    "    \"\"\"\n",
    "    def __init__(self, y, w):\n",
    "        y = np.asarray(y).flatten()\n",
    "        w.transformation = 'b'\n",
    "        self.w = w\n",
    "        # The following line differs from esda.Join_Counts() function\n",
    "        self.adj_list = self.w.to_adjlist(remove_symmetric=False)\n",
    "        self.y = y\n",
    "        results = self.__calc(self.y)\n",
    "        # As there is only one item being returned we just use\n",
    "        # results. Once more need sto be returned in last line\n",
    "        # of __calc, this would change back to results[0]\n",
    "        self.bb = results\n",
    "\n",
    "    def __calc(self, z):\n",
    "        adj_list = self.adj_list\n",
    "        zseries = pd.Series(z, index=self.w.id_order)\n",
    "        focal = zseries.loc[adj_list.focal].values\n",
    "        neighbor = zseries.loc[adj_list.neighbor].values\n",
    "        BB = (focal == 1) & (neighbor == 1)\n",
    "        adj_list_BB = pd.DataFrame(adj_list.focal.values,\n",
    "                                   BB.astype('uint8')).reset_index()\n",
    "        adj_list_BB.columns = ['BB', 'ID']\n",
    "        adj_list_BB = adj_list_BB.groupby(by='ID').sum()\n",
    "        BB = adj_list_BB.BB.values\n",
    "        return (BB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above function is working but is in the 'old' `moran.py` or `join_counts.py` formatting style. Levi suggested making them in the form of scikit-learn or scipy. I'm leaning torwards the scikit-learn style and so I'm emulating `lee.py`. Note that the following `Local_Join_Count` is the preferred function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on format of: https://github.com/pysal/esda/blob/master/esda/lee.py\n",
    "import numpy\n",
    "from sklearn.base import BaseEstimator\n",
    "import libpysal\n",
    "\n",
    "\n",
    "class Local_Join_Count(BaseEstimator):\n",
    "\n",
    "    \"\"\"Local Join Count Statistic\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None):\n",
    "        \"\"\"\n",
    "        Initialize a Join_Counts_Local estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity:   scipy.sparse matrix object\n",
    "                        the connectivity structure describing the relationships\n",
    "                        between observed units. Need not be row-standardized.\n",
    "        Attributes\n",
    "        ----------\n",
    "        BB_:  numpy.ndarray (1,)\n",
    "              array containing the estimated Local Join Count coefficients,\n",
    "              where element [0,0] is the number of Local Join Counts, ...\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "\n",
    "    def fit(self, y):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        y       :   numpy.ndarray\n",
    "                    array containing binary (0/1) data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations found in :cite:`AnselinLi2019`.\n",
    "        \"\"\"\n",
    "        y = np.asarray(y).flatten()\n",
    "\n",
    "        w = self.connectivity\n",
    "        # Binary weights are needed for this statistic\n",
    "        w.transformation = 'b'\n",
    "\n",
    "        self.BB_ = self._statistic(y, w)\n",
    "\n",
    "        # Need the >>> return self to get the associated .BB_ attribute\n",
    "        # (significance in future, i.e. self.reference_distribution_ in lee.py)\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(y, w):\n",
    "        # Create adjacency list. Note that remove_symmetric=False - this is\n",
    "        # different from the esda.Join_Counts() function.\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "        zseries = pd.Series(y, index=w.id_order)\n",
    "        focal = zseries.loc[adj_list.focal].values\n",
    "        neighbor = zseries.loc[adj_list.neighbor].values\n",
    "        BB = (focal == 1) & (neighbor == 1)\n",
    "        adj_list_BB = pd.DataFrame(adj_list.focal.values,\n",
    "                                   BB.astype('uint8')).reset_index()\n",
    "        adj_list_BB.columns = ['BB', 'ID']\n",
    "        adj_list_BB = adj_list_BB.groupby(by='ID').sum()\n",
    "        BB = adj_list_BB.BB.values\n",
    "        return (BB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test both the old and new function with some inputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new y_1 [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import libpysal\n",
    "import pandas as pd\n",
    "# Create a 16x16 grid\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "y_1 = np.ones(16)\n",
    "# Set the first 9 of the ones to 0\n",
    "y_1[0:8] = 0\n",
    "print('new y_1', y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Join_Counts_Local_old at 0x2013d748>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Join_Counts_Local_old(y_1, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 2 3 3 2 2 3 3 2]\n"
     ]
    }
   ],
   "source": [
    "test_ljc_uni = Join_Counts_Local_old(y_1, w)\n",
    "vars(test_ljc_uni)\n",
    "print(test_ljc_uni.bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 2, 2, 3, 3, 2], dtype=uint64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = Local_Join_Count(connectivity=w).fit(y_1)\n",
    "temp.BB_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to ensure equivalency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ljc_uni.bb == temp.BB_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created `%t` as an alias for `%timeit`.\n",
      "Created `%%t` as an alias for `%%timeit`.\n"
     ]
    }
   ],
   "source": [
    "# Compare speed of two functions\n",
    "%alias_magic t timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.8 ms ± 980 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%t Local_Join_Count(connectivity=w).fit(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.8 ms ± 1.52 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%t Join_Counts_Local_old(y_1, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No apparent difference in speed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Local Join Count  <a name=\"BVLJC\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pysal/esda/blob/master/esda/lee.py\n",
    "import numpy\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import utils\n",
    "\n",
    "\n",
    "class Local_Join_Count_BV(BaseEstimator):\n",
    "\n",
    "    \"\"\"Global Spatial Pearson Statistic\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None):\n",
    "        \"\"\"\n",
    "        Initialize a Join_Counts_Local estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity:   scipy.sparse matrix object\n",
    "                        the connectivity structure describing the relationships\n",
    "                        between observed units. Will be row-standardized.\n",
    "        Attributes\n",
    "        ----------\n",
    "        BJC_:  numpy.ndarray (1,)\n",
    "               array containing the estimated Bivariate Local Join Counts ...\n",
    "        CLC_:  numpy.ndarray (1,)\n",
    "               array containing the estimated Bivariate Local Join Counts ...\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "\n",
    "    def fit(self, x, z, case=None):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        y       :   numpy.ndarray\n",
    "                    array containing binary (0/1) data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`Lee2001`.\n",
    "        \"\"\"\n",
    "        x = np.asarray(x).flatten()\n",
    "        z = np.asarray(z).flatten()\n",
    "\n",
    "        w = self.connectivity\n",
    "        w.transformation = 'b'\n",
    "\n",
    "        self.LJC_ = self._statistic(x, z, w, case=case)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(x, z, w, case=None):\n",
    "        # Create adjacency list. Note that remove_symmetric=False - this is\n",
    "        # different from the esda.Join_Counts() function.\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "\n",
    "        # First, set up a series that maps the y values\n",
    "        # (input as self.y) to the weights table\n",
    "        zseries_x = pd.Series(x, index=w.id_order)\n",
    "        zseries_z = pd.Series(z, index=w.id_order)\n",
    "\n",
    "        # Next, map the y values to the focal (i) values\n",
    "        focal_x = zseries_x.loc[adj_list.focal].values\n",
    "        focal_z = zseries_z.loc[adj_list.focal].values\n",
    "\n",
    "        # Repeat the mapping but for the neighbor (j) values\n",
    "        neighbor_x = zseries_x.loc[adj_list.neighbor].values\n",
    "        neighbor_z = zseries_z.loc[adj_list.neighbor].values\n",
    "\n",
    "        if case == \"BJC\":\n",
    "            BJC = (focal_x == 1) & (focal_z == 0) & \\\n",
    "                  (neighbor_x == 0) & (neighbor_z == 1)\n",
    "            adj_list_BJC = pd.DataFrame(adj_list.focal.values,\n",
    "                                        BJC.astype('uint8')).reset_index()\n",
    "            adj_list_BJC.columns = ['BJC', 'ID']\n",
    "            adj_list_BJC = adj_list_BJC.groupby(by='ID').sum()\n",
    "            return adj_list_BJC.BJC.values\n",
    "        elif case == \"CLC\":\n",
    "            CLC = (focal_x == 1) & (focal_z == 1) & \\\n",
    "                  (neighbor_x == 1) & (neighbor_z == 1)\n",
    "            adj_list_CLC = pd.DataFrame(adj_list.focal.values,\n",
    "                                        CLC.astype('uint8')).reset_index()\n",
    "            adj_list_CLC.columns = ['CLC', 'ID']\n",
    "            adj_list_CLC = adj_list_CLC.groupby(by='ID').sum()\n",
    "            return (adj_list_CLC.CLC.values)\n",
    "        else:\n",
    "            print(\"Please specify which type of bivariate Local Join Count \\\n",
    "            you would like to calculate (either 'BJC' or 'CLC'). See Anselin \\\n",
    "            and Li 2019 p. 9-10 for more information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test some values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "z [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "x = y_1\n",
    "z = [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
    "\n",
    "print('x', x)\n",
    "print('z', z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Case 1\n",
    "temp2 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"BJC\")\n",
    "print(temp2.LJC_)\n",
    "# Case 2\n",
    "temp2 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"CLC\")\n",
    "print(temp2.LJC_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify which type of bivariate Local Join Count             you would like to calculate (either 'BJC' or 'CLC'). See Anselin             and Li 2019 p. 9-10 for more information\n",
      "Local_Join_Count_BV(connectivity=<libpysal.weights.weights.W object at 0x20121B68>)\n",
      "Please specify which type of bivariate Local Join Count             you would like to calculate (either 'BJC' or 'CLC'). See Anselin             and Li 2019 p. 9-10 for more information\n",
      "Local_Join_Count_BV(connectivity=<libpysal.weights.weights.W object at 0x20121B68>)\n"
     ]
    }
   ],
   "source": [
    "# Try with a purposefully wrong input or blnak\n",
    "# Improper input\n",
    "print(Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"ThisIsWrong\"))\n",
    "# No input for case\n",
    "print(Local_Join_Count_BV(connectivity=w).fit(x, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Local Join Count <a name=\"MVLJC\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import utils\n",
    "\n",
    "\n",
    "class Local_Join_Count_MV(BaseEstimator):\n",
    "\n",
    "    \"\"\"Global Spatial Pearson Statistic\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None):\n",
    "        \"\"\"\n",
    "        Initialize a Join_Counts_Local estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity:   scipy.sparse matrix object\n",
    "                        the connectivity structure describing the relationships\n",
    "                        between observed units. Will be row-standardized.\n",
    "        Attributes\n",
    "        ----------\n",
    "        MJC_:  numpy.ndarray (1,)\n",
    "               array containing the Multivariate Local Join Counts ...\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "\n",
    "    def fit(self, variables):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        y       :   numpy.ndarray\n",
    "                    array containing binary (0/1) data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`Lee2001`.\n",
    "        \"\"\"\n",
    "\n",
    "        # Need not be flattened?\n",
    "\n",
    "        w = self.connectivity\n",
    "        w.transformation = 'b'\n",
    "\n",
    "        self.MJC_ = self._statistic(variables, w)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(variables, w):\n",
    "        # Create adjacency list. Note that remove_symmetric=False -\n",
    "        # different from the esda.Join_Counts() function.\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "\n",
    "        # The zseries\n",
    "        zseries = [pd.Series(i, index=w.id_order) for i in variables]\n",
    "        # The focal values\n",
    "        focal = [zseries[i].loc[adj_list.focal].values for\n",
    "                 i in range(len(variables))]\n",
    "        # The neighbor values\n",
    "        neighbor = [zseries[i].loc[adj_list.neighbor].values for\n",
    "                    i in range(len(variables))]\n",
    "\n",
    "        # Find instances where all surrounding \n",
    "        # focal and neighbor values == 1\n",
    "        focal_all = np.array(np.all(np.dstack(focal)==1, \n",
    "                                    axis=2))\n",
    "        neighbor_all = np.array(np.all(np.dstack(neighbor)==1, \n",
    "                                       axis=2))\n",
    "        MCLC = (focal_all == True) & (neighbor_all == True)\n",
    "        # Convert list of True/False to boolean array \n",
    "        # and unlist (necessary for building pd.DF)\n",
    "        MCLC = list(MCLC*1)\n",
    "        \n",
    "        # Create a df that uses the adjacency list\n",
    "        # focal values and the BBs counts\n",
    "        adj_list_MCLC = pd.DataFrame(adj_list.focal.values,\n",
    "                                     MCLC).reset_index()\n",
    "        # Temporarily rename the columns\n",
    "        adj_list_MCLC.columns = ['MCLC', 'ID']\n",
    "        adj_list_MCLC = adj_list_MCLC.groupby(by='ID').sum()\n",
    "\n",
    "        return (adj_list_MCLC.MCLC.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "z [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "y [0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "x = x.astype(np.int32)\n",
    "print('x', x)\n",
    "print('z', z)\n",
    "y = [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n",
    "y = np.asarray(y).flatten()\n",
    "print('y', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = Local_Join_Count_MV(connectivity=w).fit([x, y, z])\n",
    "temp.MJC_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSH  <a name=\"LOSH\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pysal/esda/blob/master/esda/lee.py\n",
    "import numpy\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn import utils\n",
    "import pysal.lib as lp\n",
    "\n",
    "\n",
    "class LOSH(BaseEstimator):\n",
    "    \"\"\"Local Join Count Statistic\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None):\n",
    "        \"\"\"\n",
    "        Initialize a Join_Counts_Local estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity:   scipy.sparse matrix object\n",
    "                        the connectivity structure describing the relationships\n",
    "                        between observed units. Will be row-standardized.\n",
    "        Attributes\n",
    "        ----------\n",
    "        LOSH_:  numpy.ndarray (1,)\n",
    "              array containing the estimated Local Join Count coefficients,\n",
    "              where element [0,0] is the number of Local Join Counts, ...\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "\n",
    "    def fit(self, y):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        y       :   numpy.ndarray\n",
    "                    array containing continuous data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`OrdGetis2012`.\n",
    "        \"\"\"\n",
    "        y = np.asarray(y).flatten()\n",
    "\n",
    "        w = self.connectivity\n",
    "        w.transform = 'r'\n",
    "\n",
    "        self.LOSH_ = self._statistic(y, w)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(y, w, a=2):\n",
    "        # Calculate mean of y values (due to row-standardization)\n",
    "        ymean = lp.weights.lag_spatial(w, y)\n",
    "        # Calculate residuals of y values\n",
    "        yresid = y-ymean\n",
    "        # Adjust residuals based on interest:\n",
    "        # Scenario 1: a = 1, an absolute deivations measure $H_{i} = 1$\n",
    "        # Scenario 2 (default): a = 2, a variance measure $H_{i} = 2$\n",
    "        yresid = abs(yresid)**a\n",
    "        # Calculate average of residuals (used as\n",
    "        # denominator in $H_{i}$ calculation)\n",
    "        yresid_mean = np.mean(yresid)\n",
    "        # Carry out final $H_{i}$ calculation by dividing\n",
    "        # spatial average of residuals by mean of residuals\n",
    "        lag_resid = lp.weights.lag_spatial(w, yresid)\n",
    "        Hi = lag_resid/yresid_mean\n",
    "\n",
    "        return (Hi, ymean, yresid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test values based on existing Global Spatial Autocorrelation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pysal.lib as lp\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import shapely.geometry as geom\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file('C:/Users/jeffe/Dropbox/Maryland/PhD_Courses/GEOG788P/MnM4SDS_Fall2019/lectures/data/neighborhoods.gpkg')\n",
    "listings = gpd.read_file('C:/Users/jeffe/Dropbox/Maryland/PhD_Courses/GEOG788P/MnM4SDS_Fall2019/lectures/data/listings.gpkg')\n",
    "listings['price'] = listings.price.str.replace('$', '').str.replace(',','_').astype(float)\n",
    "median_price = gpd.sjoin(listings[['price', 'geometry']], df, op='within')\\\n",
    "                  .groupby('index_right').price.median()\n",
    "df['median_pri'] = median_price.values\n",
    "# Make sure missing values are taken care of\n",
    "pd.isnull(df['median_pri']).sum()\n",
    "df = df\n",
    "df['median_pri'].fillna((df['median_pri'].mean()), inplace=True)\n",
    "y = df['median_pri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = lp.weights.Queen.from_dataframe(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass through function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.02994733, 0.05037736, 0.81581523, 0.58861133, 0.28585921,\n",
       "        1.54412407, 0.25892339, 2.44041661, 1.01286471, 0.55501043,\n",
       "        0.05265041, 0.11646834, 0.94735105, 0.80400132, 0.95965242,\n",
       "        1.62640221, 1.08534645, 1.84522653, 1.21784382, 4.22455343,\n",
       "        0.30323733, 0.84392127, 3.15858551, 1.02282182, 2.40780699,\n",
       "        0.86367122, 0.21005193, 0.08462695, 0.48074693, 3.40823975,\n",
       "        0.0585616 , 0.78132661, 0.02524374, 0.90833485, 0.17737994,\n",
       "        1.02251044, 4.2363653 , 0.57443862, 0.55754422, 2.46548278,\n",
       "        0.79040233, 0.17213714, 0.34326507, 0.61876324]),\n",
       " array([115.        ,  92.5       , 221.6       , 128.33333333,\n",
       "        112.9       ,  98.33333333, 112.5       , 172.5       ,\n",
       "        197.6       , 111.        , 101.33333333,  70.        ,\n",
       "        112.66666667, 147.25      , 125.27777778, 132.3125    ,\n",
       "         80.        , 119.375     , 137.        , 203.7       ,\n",
       "         77.33333333, 119.5       , 203.08333333, 114.83333333,\n",
       "        162.1875    ,  98.4       ,  79.6       ,  91.4375    ,\n",
       "         88.5       , 165.875     ,  85.        , 156.625     ,\n",
       "         89.6       , 193.08333333,  94.58333333, 196.33333333,\n",
       "        233.6       , 101.5625    , 121.35714286, 187.85714286,\n",
       "        111.7       ,  80.66666667, 229.        , 154.85714286]),\n",
       " array([1.22500000e+03, 3.06250000e+02, 7.50760000e+02, 4.44444444e+01,\n",
       "        2.91600000e+01, 1.87777778e+03, 2.72250000e+02, 6.25000000e+00,\n",
       "        1.29960000e+02, 2.35225000e+03, 1.77777778e+00, 2.50000000e+01,\n",
       "        2.27211111e+03, 1.04006250e+03, 2.47229938e+03, 1.04409766e+03,\n",
       "        3.60000000e+03, 3.75390625e+02, 1.44000000e+02, 1.36900000e+01,\n",
       "        3.36111111e+02, 2.50000000e-01, 2.20117361e+03, 1.64694444e+02,\n",
       "        1.60972656e+02, 7.05600000e+01, 1.58760000e+02, 5.71914062e+01,\n",
       "        1.22500000e+01, 5.34765625e+02, 1.00000000e+02, 1.34139062e+03,\n",
       "        5.77600000e+01, 2.01403403e+04, 1.73611111e-01, 2.14677778e+03,\n",
       "        1.29960000e+02, 8.90664062e+01, 9.83270408e+02, 3.95102041e+03,\n",
       "        2.78890000e+02, 2.77777778e+00, 6.25000000e+02, 4.92002041e+03]))"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = LOSH(connectivity=w).fit(y)\n",
    "temp.LOSH_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
