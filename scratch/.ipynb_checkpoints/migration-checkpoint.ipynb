{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Purpose of this notebook\n",
    "\n",
    "The purpose of this notebook is to migrate the workbook pseudo code of `LOSH_*.ipynb` and `OLJC_*.ipynb` into functions that match the `PySAL` structure. These will be expanded over time and built out. \n",
    "\n",
    "**Table of contents**\n",
    "1. [Univariate Local Join Counts](#ULJC)\n",
    "2. [Bivariate Local Join Counts](#BVLJC)\n",
    "3. [Multivariate Local Join Counts](#MVLJC)\n",
    "4. [LOSH](#LOSH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load pep8 styling throughout notebook\n",
    "%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn pep8 style checking ON\n",
    "#%pycodestyle_on\n",
    "# Note that you can turn on line numbers with ESC+L!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Turn pep8 style checking OFF to resume testing functions\n",
    "#%pycodestyle_off"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LJC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Univariate <a name=\"ULJC\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First draft of implementation is in 'legacy' format (matching functions like moran.py). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Univariate local join counts for binary attributes\n",
    "\"\"\"\n",
    "\n",
    "__author__ = \"Sergio J. Rey <srey@asu.edu> , Luc Anselin <luc.anselin@asu.edu>\"\n",
    "\n",
    "from libpysal.weights.spatial_lag import lag_spatial\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class Join_Counts_Local_old(object):\n",
    "\n",
    "    \"\"\"Univariate Local Join Counts\n",
    "    Parameters\n",
    "    ----------\n",
    "    y               : array\n",
    "                      binary variable measured across n spatial units\n",
    "    w               : W\n",
    "                      spatial weights instance\n",
    "    Attributes\n",
    "    ----------\n",
    "    y            : array\n",
    "                   original variable\n",
    "    w            : W\n",
    "                   original w object\n",
    "    bb           : float\n",
    "                   number of black-black joins\n",
    "    Notes\n",
    "    -----\n",
    "    Technical details and derivations can be found in :cite:`anselinli2019`.\n",
    "    \"\"\"\n",
    "    def __init__(self, y, w):\n",
    "        y = np.asarray(y).flatten()\n",
    "        w.transformation = 'b'\n",
    "        self.w = w\n",
    "        # The following line differs from esda.Join_Counts() function\n",
    "        self.adj_list = self.w.to_adjlist(remove_symmetric=False)\n",
    "        self.y = y\n",
    "        results = self.__calc(self.y)\n",
    "        # As there is only one item being returned we just use\n",
    "        # results. Once more need sto be returned in last line\n",
    "        # of __calc, this would change back to results[0]\n",
    "        self.bb = results\n",
    "\n",
    "    def __calc(self, z):\n",
    "        adj_list = self.adj_list\n",
    "        zseries = pd.Series(z, index=self.w.id_order)\n",
    "        focal = zseries.loc[adj_list.focal].values\n",
    "        neighbor = zseries.loc[adj_list.neighbor].values\n",
    "        BB = (focal == 1) & (neighbor == 1)\n",
    "        adj_list_BB = pd.DataFrame(adj_list.focal.values,\n",
    "                                   BB.astype('uint8')).reset_index()\n",
    "        adj_list_BB.columns = ['BB', 'ID']\n",
    "        adj_list_BB = adj_list_BB.groupby(by='ID').sum()\n",
    "        BB = adj_list_BB.BB.values\n",
    "        return (BB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above function is working but is in the 'old' `moran.py` or `join_counts.py` formatting style. Levi suggested making them in the form of scikit-learn or scipy. I'm leaning torwards the scikit-learn style and so I'm emulating `lee.py`. Note that the following `Local_Join_Count` is the preferred function. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Based on format of: https://github.com/pysal/esda/blob/master/esda/lee.py\n",
    "import numpy\n",
    "from sklearn.base import BaseEstimator\n",
    "import libpysal\n",
    "\n",
    "\n",
    "class Local_Join_Count(BaseEstimator):\n",
    "\n",
    "    \"\"\"Local Join Count Statistic\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None):\n",
    "        \"\"\"\n",
    "        Initialize a Join_Counts_Local estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity:   scipy.sparse matrix object\n",
    "                        the connectivity structure describing the relationships\n",
    "                        between observed units. Need not be row-standardized.\n",
    "        Attributes\n",
    "        ----------\n",
    "        BB_:  numpy.ndarray (1,)\n",
    "              array containing the estimated Local Join Count coefficients,\n",
    "              where element [0,0] is the number of Local Join Counts, ...\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "\n",
    "    def fit(self, y):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        y       :   numpy.ndarray\n",
    "                    array containing binary (0/1) data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations found in :cite:`AnselinLi2019`.\n",
    "        \"\"\"\n",
    "        y = np.asarray(y).flatten()\n",
    "\n",
    "        w = self.connectivity\n",
    "        # Binary weights are needed for this statistic\n",
    "        w.transformation = 'b'\n",
    "\n",
    "        self.BB_ = self._statistic(y, w)\n",
    "\n",
    "        # Need the >>> return self to get the associated .BB_ attribute\n",
    "        # (significance in future, i.e. self.reference_distribution_ in lee.py)\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(y, w):\n",
    "        # Create adjacency list. Note that remove_symmetric=False - this is\n",
    "        # different from the esda.Join_Counts() function.\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "        zseries = pd.Series(y, index=w.id_order)\n",
    "        focal = zseries.loc[adj_list.focal].values\n",
    "        neighbor = zseries.loc[adj_list.neighbor].values\n",
    "        BB = (focal == 1) & (neighbor == 1)\n",
    "        adj_list_BB = pd.DataFrame(adj_list.focal.values,\n",
    "                                   BB.astype('uint8')).reset_index()\n",
    "        adj_list_BB.columns = ['BB', 'ID']\n",
    "        adj_list_BB = adj_list_BB.groupby(by='ID').sum()\n",
    "        BB = adj_list_BB.BB.values\n",
    "        return (BB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test both the old and new function with some inputs..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new y_1 [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import libpysal\n",
    "import pandas as pd\n",
    "# Create a 16x16 grid\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "y_1 = np.ones(16)\n",
    "# Set the first 9 of the ones to 0\n",
    "y_1[0:8] = 0\n",
    "print('new y_1', y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.Join_Counts_Local_old at 0x1f8c2c70>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Join_Counts_Local_old(y_1, w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 2 3 3 2 2 3 3 2]\n"
     ]
    }
   ],
   "source": [
    "test_ljc_uni = Join_Counts_Local_old(y_1, w)\n",
    "vars(test_ljc_uni)\n",
    "print(test_ljc_uni.bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 2, 2, 3, 3, 2], dtype=uint64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = Local_Join_Count(connectivity=w).fit(y_1)\n",
    "temp.BB_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test to ensure equivalency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_ljc_uni.bb == temp.BB_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created `%t` as an alias for `%timeit`.\n",
      "Created `%%t` as an alias for `%%timeit`.\n"
     ]
    }
   ],
   "source": [
    "# Compare speed of two functions\n",
    "%alias_magic t timeit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.61 ms ± 1.09 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%t Local_Join_Count(connectivity=w).fit(y_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5.64 ms ± 1.16 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%t Join_Counts_Local_old(y_1, w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No apparent difference in speed?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bivariate Local Join Count  <a name=\"BVLJC\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pysal/esda/blob/master/esda/lee.py\n",
    "import numpy\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Local_Join_Count_BV(BaseEstimator):\n",
    "\n",
    "    \"\"\"Global Spatial Pearson Statistic\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None):\n",
    "        \"\"\"\n",
    "        Initialize a Join_Counts_Local estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity:   scipy.sparse matrix object\n",
    "                        the connectivity structure describing the relationships\n",
    "                        between observed units. Will be row-standardized.\n",
    "        Attributes\n",
    "        ----------\n",
    "        BJC_:  numpy.ndarray (1,)\n",
    "               array containing the estimated Bivariate Local Join Counts ...\n",
    "        CLC_:  numpy.ndarray (1,)\n",
    "               array containing the estimated Bivariate Local Join Counts ...\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "\n",
    "    def fit(self, x, z, case=None):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        y       :   numpy.ndarray\n",
    "                    array containing binary (0/1) data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`Lee2001`.\n",
    "        \"\"\"\n",
    "        x = np.asarray(x).flatten()\n",
    "        z = np.asarray(z).flatten()\n",
    "\n",
    "        w = self.connectivity\n",
    "        w.transformation = 'b'\n",
    "\n",
    "        self.LJC_ = self._statistic(x, z, w, case=case)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(x, z, w, case=None):\n",
    "        # Create adjacency list. Note that remove_symmetric=False - this is\n",
    "        # different from the esda.Join_Counts() function.\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "\n",
    "        # First, set up a series that maps the y values\n",
    "        # (input as self.y) to the weights table\n",
    "        zseries_x = pd.Series(x, index=w.id_order)\n",
    "        zseries_z = pd.Series(z, index=w.id_order)\n",
    "\n",
    "        # Next, map the y values to the focal (i) values\n",
    "        focal_x = zseries_x.loc[adj_list.focal].values\n",
    "        focal_z = zseries_z.loc[adj_list.focal].values\n",
    "\n",
    "        # Repeat the mapping but for the neighbor (j) values\n",
    "        neighbor_x = zseries_x.loc[adj_list.neighbor].values\n",
    "        neighbor_z = zseries_z.loc[adj_list.neighbor].values\n",
    "\n",
    "        if case == \"BJC\":\n",
    "            BJC = (focal_x == 1) & (focal_z == 0) & \\\n",
    "                  (neighbor_x == 0) & (neighbor_z == 1)\n",
    "            adj_list_BJC = pd.DataFrame(adj_list.focal.values,\n",
    "                                        BJC.astype('uint8')).reset_index()\n",
    "            adj_list_BJC.columns = ['BJC', 'ID']\n",
    "            adj_list_BJC = adj_list_BJC.groupby(by='ID').sum()\n",
    "            return adj_list_BJC.BJC.values\n",
    "        elif case == \"CLC\":\n",
    "            CLC = (focal_x == 1) & (focal_z == 1) & \\\n",
    "                  (neighbor_x == 1) & (neighbor_z == 1)\n",
    "            adj_list_CLC = pd.DataFrame(adj_list.focal.values,\n",
    "                                        CLC.astype('uint8')).reset_index()\n",
    "            adj_list_CLC.columns = ['CLC', 'ID']\n",
    "            adj_list_CLC = adj_list_CLC.groupby(by='ID').sum()\n",
    "            return (adj_list_CLC.CLC.values)\n",
    "        else:\n",
    "            print(\"Please specify which type of bivariate Local Join Count \\\n",
    "            you would like to calculate (either 'BJC' or 'CLC'). See Anselin \\\n",
    "            and Li 2019 p. 9-10 for more information\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test some values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "z [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "x = y_1\n",
    "z = [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
    "\n",
    "print('x', x)\n",
    "print('z', z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Case 1\n",
    "temp2 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"BJC\")\n",
    "print(temp2.LJC_)\n",
    "# Case 2\n",
    "temp2 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"CLC\")\n",
    "print(temp2.LJC_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please specify which type of bivariate Local Join Count             you would like to calculate (either 'BJC' or 'CLC'). See Anselin             and Li 2019 p. 9-10 for more information\n",
      "Local_Join_Count_BV(connectivity=<libpysal.weights.weights.W object at 0x1F8C03D0>)\n",
      "Please specify which type of bivariate Local Join Count             you would like to calculate (either 'BJC' or 'CLC'). See Anselin             and Li 2019 p. 9-10 for more information\n",
      "Local_Join_Count_BV(connectivity=<libpysal.weights.weights.W object at 0x1F8C03D0>)\n"
     ]
    }
   ],
   "source": [
    "# Try with a purposefully wrong input or blnak\n",
    "# Improper input\n",
    "print(Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"ThisIsWrong\"))\n",
    "# No input for case\n",
    "print(Local_Join_Count_BV(connectivity=w).fit(x, z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multivariate Local Join Count <a name=\"MVLJC\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "class Local_Join_Count_MV(BaseEstimator):\n",
    "\n",
    "    \"\"\"Global Spatial Pearson Statistic\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None):\n",
    "        \"\"\"\n",
    "        Initialize a Join_Counts_Local estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity:   scipy.sparse matrix object\n",
    "                        the connectivity structure describing the relationships\n",
    "                        between observed units. Will be row-standardized.\n",
    "        Attributes\n",
    "        ----------\n",
    "        MJC_:  numpy.ndarray (1,)\n",
    "               array containing the Multivariate Local Join Counts ...\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "\n",
    "    def fit(self, variables):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        y       :   numpy.ndarray\n",
    "                    array containing binary (0/1) data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`Lee2001`.\n",
    "        \"\"\"\n",
    "\n",
    "        # Need not be flattened?\n",
    "\n",
    "        w = self.connectivity\n",
    "        w.transformation = 'b'\n",
    "\n",
    "        self.MJC_ = self._statistic(variables, w)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(variables, w):\n",
    "        # Create adjacency list. Note that remove_symmetric=False -\n",
    "        # different from the esda.Join_Counts() function.\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "\n",
    "        # The zseries\n",
    "        zseries = [pd.Series(i, index=w.id_order) for i in variables]\n",
    "        # The focal values\n",
    "        focal = [zseries[i].loc[adj_list.focal].values for\n",
    "                 i in range(len(variables))]\n",
    "        # The neighbor values\n",
    "        neighbor = [zseries[i].loc[adj_list.neighbor].values for\n",
    "                    i in range(len(variables))]\n",
    "\n",
    "        # Find instances where all surrounding \n",
    "        # focal and neighbor values == 1\n",
    "        focal_all = np.array(np.all(np.dstack(focal)==1, \n",
    "                                    axis=2))\n",
    "        neighbor_all = np.array(np.all(np.dstack(neighbor)==1, \n",
    "                                       axis=2))\n",
    "        MCLC = (focal_all == True) & (neighbor_all == True)\n",
    "        # Convert list of True/False to boolean array \n",
    "        # and unlist (necessary for building pd.DF)\n",
    "        MCLC = list(MCLC*1)\n",
    "        \n",
    "        # Create a df that uses the adjacency list\n",
    "        # focal values and the BBs counts\n",
    "        adj_list_MCLC = pd.DataFrame(adj_list.focal.values,\n",
    "                                     MCLC).reset_index()\n",
    "        # Temporarily rename the columns\n",
    "        adj_list_MCLC.columns = ['MCLC', 'ID']\n",
    "        adj_list_MCLC = adj_list_MCLC.groupby(by='ID').sum()\n",
    "\n",
    "        return (adj_list_MCLC.MCLC.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "z [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "y [0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "x = x.astype(np.int32)\n",
    "print('x', x)\n",
    "print('z', z)\n",
    "y = [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n",
    "y = np.asarray(y).flatten()\n",
    "print('y', y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp = Local_Join_Count_MV(connectivity=w).fit([x, y, z])\n",
    "temp.MJC_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LOSH  <a name=\"LOSH\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://github.com/pysal/esda/blob/master/esda/lee.py\n",
    "import numpy\n",
    "from scipy import sparse\n",
    "from scipy import stats\n",
    "from sklearn.base import BaseEstimator\n",
    "import pysal.lib as lp\n",
    "\n",
    "\n",
    "class losh(BaseEstimator):\n",
    "    \"\"\"Local spatial heteroscedasticity (LOSH)\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None, inference=None, standardization=None):\n",
    "        \"\"\"\n",
    "        Initialize a losh estimator\n",
    "\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity: scipy.sparse matrix object\n",
    "                      the connectivity structure describing the relationships\n",
    "                      between observed units.\n",
    "        standardization: str\n",
    "                         defines whether or not the user wants\n",
    "                         row-standardized weights or abstract weights. options\n",
    "                         are \"row\" or \"abstract\".\n",
    "        inference: str\n",
    "                   describes type of inference to be used. options are\n",
    "                   \"chi-square\", \"permutation\", or \"simulation\".\n",
    "\n",
    "        Attributes\n",
    "        ----------\n",
    "        LOSH_: numpy.ndarray (1,)\n",
    "               array containing the estimated Local Join Count coefficients,\n",
    "               where element [0,0] is the number of Local Join Counts, ...\n",
    "        \"\"\"\n",
    "        \n",
    "        self.connectivity = connectivity\n",
    "        self.inference = inference\n",
    "        self.standardization = standardization\n",
    "\n",
    "    def fit(self, y, a=None, standardization=None):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        y       :   numpy.ndarray\n",
    "                    array containing continuous data\n",
    "        a       :   int\n",
    "                    residual multiplier. Default is 2 in order to generate a\n",
    "                    variance measure. Users may use 1 for absolute deviations.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`OrdGetis2012`.\n",
    "        \"\"\"\n",
    "        y = np.asarray(y).flatten()\n",
    "\n",
    "        if self.standardization is None:\n",
    "            print(\"Warning: No standardization specified, row-standardization assumed.\")\n",
    "            w = self.connectivity\n",
    "            w.transform = 'r'\n",
    "        elif self.standardization == \"row\":\n",
    "            w = self.connectivity\n",
    "            w.transform = 'r'\n",
    "        elif self.standardization == \"abstract\":\n",
    "            w = self.connectivity\n",
    "\n",
    "        self.Hi, self.ylag, self.yresid, self.VarHi = self._statistic(y, w, a)\n",
    "        \n",
    "        if self.inference is None:\n",
    "            return self\n",
    "        elif self.inference == \"chi-square\":\n",
    "            print(\"Note: chi-square inference selected. This assumes a=2.\")\n",
    "            dof = 2/self.VarHi\n",
    "            Zi = (2*self.Hi)/self.VarHi\n",
    "            self.pval = 1 - stats.chi2.cdf(Zi, dof)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(y, w, a):\n",
    "        # Define what type of variance to use\n",
    "        if a is None:\n",
    "            a = 2\n",
    "        else:\n",
    "            a = a\n",
    "        \n",
    "        transform = w.get_transform()\n",
    "        \n",
    "        # Calculate spatial lag (mean when row standardized, sum when not)\n",
    "        ylag = lp.weights.lag_spatial(w, y)\n",
    "        # Calculate residuals of y values\n",
    "        yresid = y-ylag\n",
    "        # Adjust residuals based on multiplier\n",
    "        yresid = abs(yresid)**a\n",
    "        \n",
    "        # Calculate average of residuals (used as\n",
    "        # denominator in $H_{i}$ calculation and \n",
    "        # in variance alculation)\n",
    "        yresid_mean = np.mean(yresid)\n",
    "        # Carry out final $H_{i}$ calculation by dividing\n",
    "        # spatial average of residuals by mean of residuals\n",
    "        lag_resid = lp.weights.lag_spatial(w, yresid)\n",
    "        \n",
    "        # Define denominator of $H_i$ calculation.\n",
    "        # If row standardized, use mean of residuals.\n",
    "        if transform == \"R\":\n",
    "            denom = np.mean(yresid)\n",
    "        # If not row standardized, use sum of lagged y values.\n",
    "        else:\n",
    "            denom = ylag\n",
    "        \n",
    "        # Calculate Hi\n",
    "        Hi = lag_resid/denom\n",
    "        \n",
    "        # Calculate variance\n",
    "        n = len(y)\n",
    "        # Calculate VarHi\n",
    "        VarHi =    ((len(y)-1)**-1) * \\\n",
    "                   ((yresid_mean)**-2) * \\\n",
    "                   ((np.sum(yresid**2)/n) - yresid_mean**2) * \\\n",
    "                   ((n * (1/np.array(list(w.cardinalities.values())))) - \\\n",
    "                   [np.sum(list(w[y].values())) for y in range(len(y))])       \n",
    "\n",
    "        return (Hi, ylag, yresid, VarHi)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test values based on existing Global Spatial Autocorrelation notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load modules\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import pysal.lib as lp\n",
    "import matplotlib.pyplot as plt\n",
    "import rasterio as rio\n",
    "import numpy as np\n",
    "import shapely.geometry as geom\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = gpd.read_file('https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/neighborhoods.gpkg')\n",
    "listings = gpd.read_file('https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/listings.gpkg')\n",
    "listings['price'] = listings.price.str.replace('$', '').str.replace(',','_').astype(float)\n",
    "median_price = gpd.sjoin(listings[['price', 'geometry']], df, op='within')\\\n",
    "                  .groupby('index_right').price.median()\n",
    "df['median_pri'] = median_price.values\n",
    "# Make sure missing values are taken care of\n",
    "pd.isnull(df['median_pri']).sum()\n",
    "df = df\n",
    "df['median_pri'].fillna((df['median_pri'].mean()), inplace=True)\n",
    "y = df['median_pri']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "w = lp.weights.Queen.from_dataframe(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'O'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.get_transform()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "w.transform = 'r'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'R'"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.get_transform()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass through function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: chi-square inference selected. This assumes a=2.\n"
     ]
    }
   ],
   "source": [
    "temp = losh(connectivity=w, standardization=\"row\", inference=\"chi-square\").fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02994733, 0.05037736, 0.81581523, 0.58861133, 0.28585921,\n",
       "       1.54412407, 0.25892339, 2.44041661, 1.01286471, 0.55501043,\n",
       "       0.05265041, 0.11646834, 0.94735105, 0.80400132, 0.95965242,\n",
       "       1.62640221, 1.08534645, 1.84522653, 1.21784382, 4.22455343,\n",
       "       0.30323733, 0.84392127, 3.15858551, 1.02282182, 2.40780699,\n",
       "       0.86367122, 0.21005193, 0.08462695, 0.48074693, 3.40823975,\n",
       "       0.0585616 , 0.78132661, 0.02524374, 0.90833485, 0.17737994,\n",
       "       1.02251044, 4.2363653 , 0.57443862, 0.55754422, 2.46548278,\n",
       "       0.79040233, 0.17213714, 0.34326507, 0.61876324])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp.Hi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
