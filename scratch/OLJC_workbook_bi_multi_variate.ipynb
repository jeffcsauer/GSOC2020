{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate local join counts (LJC), bivariate LJC, multivariate LJC\n",
    "\n",
    "### Univariate local join counts (LJC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review, the global black-black (1-1) count is the total across the entire study area:\n",
    "\n",
    "$$BB = \\sum_{i} \\sum_j w_{ij} x_{i} x_{j}$$\n",
    "\n",
    "However, the local is: \n",
    "\n",
    "$$BB_i = x_i \\sum_{j} w_{ij} x_j$$\n",
    "\n",
    "...where a count of the neighbors with an observation of $x_j=1$ for those locations where $x_i=1$. This focuses on the BB counts of a given polygon (x_i)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we will do now is to remake the data as it appears in the docstrings of the join_count function and try to get the bivariate, then multivariate, up and running.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new y_1 [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import libpysal\n",
    "import pandas as pd\n",
    "\n",
    "# Create a 16x16 grid\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "y_1 = np.ones(16)\n",
    "# Set the first 9 of the ones to 0\n",
    "y_1[0:8] = 0\n",
    "print('new y_1', y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carry out some standardization processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the input vector y\n",
    "y_1 = np.asarray(y_1).flatten()\n",
    "print(y_1)\n",
    "# ensure weights are binary transformed\n",
    "w.transformation = 'b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify univariate local join counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "0       0         4     1.0\n",
      "1       0         1     1.0\n",
      "2       1         0     1.0\n",
      "3       1         5     1.0\n",
      "4       1         2     1.0\n",
      "5       2         1     1.0\n",
      "6       2         6     1.0\n",
      "7       2         3     1.0\n",
      "8       3         2     1.0\n",
      "9       3         7     1.0\n",
      "10      4         0     1.0\n",
      "11      4         8     1.0\n",
      "12      4         5     1.0\n",
      "13      5         1     1.0\n",
      "14      5         4     1.0\n",
      "15      5         9     1.0\n",
      "16      5         6     1.0\n",
      "17      6         2     1.0\n",
      "18      6         5     1.0\n",
      "19      6        10     1.0\n",
      "20      6         7     1.0\n",
      "21      7         3     1.0\n",
      "22      7         6     1.0\n",
      "23      7        11     1.0\n",
      "24      8         4     1.0\n",
      "25      8        12     1.0\n",
      "26      8         9     1.0\n",
      "27      9         5     1.0\n",
      "28      9         8     1.0\n",
      "29      9        13     1.0\n",
      "30      9        10     1.0\n",
      "31     10         6     1.0\n",
      "32     10         9     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "35     11         7     1.0\n",
      "36     11        10     1.0\n",
      "37     11        15     1.0\n",
      "38     12         8     1.0\n",
      "39     12        13     1.0\n",
      "40     13         9     1.0\n",
      "41     13        12     1.0\n",
      "42     13        14     1.0\n",
      "43     14        10     1.0\n",
      "44     14        13     1.0\n",
      "45     14        15     1.0\n",
      "46     15        11     1.0\n",
      "47     15        14     1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list = w.to_adjlist(remove_symmetric=False) \n",
    "print(adj_list)\n",
    "zseries_var1 = pd.Series(y_1, index=w.id_order)\n",
    "focal_var1 = zseries_var1.loc[adj_list.focal].values\n",
    "neighbor_var1 = zseries_var1.loc[adj_list.neighbor].values\n",
    "# Identify which adjacency lists are both equal to 1\n",
    "BBs = (focal_var1 == 1) & (neighbor_var1 == 1)\n",
    "BBs\n",
    "# also convert to a 0/1 array\n",
    "BBs.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to map these T/F to the arrangement of the vector. While I got the correct output, it's a bit messy. This part is tricky and will likely need optimization - can we exploit the natural structure of the adjacency list without needing to make a new dataframe and run a groupby? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 2, 2, 3, 3, 2], dtype=uint64)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "temp = pd.DataFrame(adj_list.focal.values, BBs.astype('uint8')).reset_index()\n",
    "# Temporarily rename the columns\n",
    "temp.columns = ['BB', 'ID']\n",
    "temp = temp.groupby(by='ID').sum()\n",
    "temp.BB.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will still need to sort out inference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate local join counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to bivariate local join counts. Using the nomenclature `x` and `z` to represent the two variables.\n",
    "\n",
    "Firstly, the **co-location** of the events at location $i$ need to be taken into account. As explained in the other workbook, there are two kinds of bivariate local join counts considered. \n",
    "\n",
    "**Case 1: no in-situ co-location**: 'where $x_i$ and $z_i$ do NOT take on the same value at either location $i$ (itself) or $j$ (neighbors)\n",
    "\n",
    "- Example: when $x_i=1$ for location $i$, then $z_i=0$. We count the number of neighbors of $i$ when $x_i=1$ for which the value of $z_j=1$ but the value of $x_j=0$\n",
    "\n",
    "This effectively becomes a combination of identifcation where `x` is in a black(1)-white(0) join, and where `y` is in a white(0)-black(1) join.\n",
    "\n",
    "Let's experiment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "z [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "x = y_1\n",
    "z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "\n",
    "print('x', x)\n",
    "print('z', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carry out some standardization procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the input vector y\n",
    "x = np.asarray(x).flatten()\n",
    "z = np.asarray(z).flatten()\n",
    "print(x)\n",
    "print(z)\n",
    "# ensure weights are binary transformed\n",
    "w.transformation = 'b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create adjacency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "0       0         4     1.0\n",
      "1       0         1     1.0\n",
      "2       1         0     1.0\n",
      "3       1         5     1.0\n",
      "4       1         2     1.0\n",
      "5       2         1     1.0\n",
      "6       2         6     1.0\n",
      "7       2         3     1.0\n",
      "8       3         2     1.0\n",
      "9       3         7     1.0\n",
      "10      4         0     1.0\n",
      "11      4         8     1.0\n",
      "12      4         5     1.0\n",
      "13      5         1     1.0\n",
      "14      5         4     1.0\n",
      "15      5         9     1.0\n",
      "16      5         6     1.0\n",
      "17      6         2     1.0\n",
      "18      6         5     1.0\n",
      "19      6        10     1.0\n",
      "20      6         7     1.0\n",
      "21      7         3     1.0\n",
      "22      7         6     1.0\n",
      "23      7        11     1.0\n",
      "24      8         4     1.0\n",
      "25      8        12     1.0\n",
      "26      8         9     1.0\n",
      "27      9         5     1.0\n",
      "28      9         8     1.0\n",
      "29      9        13     1.0\n",
      "30      9        10     1.0\n",
      "31     10         6     1.0\n",
      "32     10         9     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "35     11         7     1.0\n",
      "36     11        10     1.0\n",
      "37     11        15     1.0\n",
      "38     12         8     1.0\n",
      "39     12        13     1.0\n",
      "40     13         9     1.0\n",
      "41     13        12     1.0\n",
      "42     13        14     1.0\n",
      "43     14        10     1.0\n",
      "44     14        13     1.0\n",
      "45     14        15     1.0\n",
      "46     15        11     1.0\n",
      "47     15        14     1.0\n"
     ]
    }
   ],
   "source": [
    "adj_list = w.to_adjlist(remove_symmetric=False) \n",
    "print(adj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now be able to use this adjacency list to run comparisons between `x` and `z`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, set up a series that maps the y values (input as self.y) to the weights table \n",
    "zseries_x = pd.Series(x, index=w.id_order)\n",
    "zseries_z = pd.Series(z, index=w.id_order)\n",
    "\n",
    "# Next, map the y values to the focal (i) values \n",
    "focal_x = zseries_x.loc[adj_list.focal].values\n",
    "focal_z = zseries_z.loc[adj_list.focal].values\n",
    "\n",
    "# Repeat the mapping but for the neighbor (j) values\n",
    "neighbor_x = zseries_x.loc[adj_list.neighbor].values\n",
    "neighbor_z = zseries_z.loc[adj_list.neighbor].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `y_1` and `y_2` vectors have been mapped to focal and neighbor objects (respectively `_var1` and `_var2`). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BJC = (focal_x == 1) & (focal_z == 0) & (neighbor_x == 0) & (neighbor_z == 1)\n",
    "BJC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], dtype=uint64)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "temp = pd.DataFrame(adj_list.focal.values, BJC.astype('uint8')).reset_index()\n",
    "# Temporarily rename the columns\n",
    "temp.columns = ['BJC', 'ID']\n",
    "temp = temp.groupby(by='ID').sum()\n",
    "temp.BJC.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appears to be working! Now onto the next case..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2: co-location cluster (CLC)**. This is when the interest is in co-located events being surrounded by other co-located events.\n",
    "\n",
    "This requires $x_i=z_i=1$ as well as $x_j=z_j=1$ for the neighbors. Reviewing, we formally write this as:\n",
    "\n",
    "$$ CLC_i = x_i * z_i \\sum_j w_{ij} x_j z_j $$\n",
    "\n",
    "Given that $x_i=z_i=1$, this becomes:\n",
    "\n",
    "$$ CLC_i = 1 * 1 \\sum_j w_{ij} x_j z_j $$\n",
    "\n",
    "Let's now implement this from the above code. The only thing we need to change is how `BJC` are calculated (now `CLC`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "        True,  True, False, False, False, False, False,  True, False,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLC = (focal_x == 1) & (focal_z == 1) & (neighbor_x == 1) & (neighbor_z == 1)\n",
    "CLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2], dtype=uint64)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "temp = pd.DataFrame(adj_list.focal.values, CLC.astype('uint8')).reset_index()\n",
    "# Temporarily rename the columns\n",
    "temp.columns = ['CLC', 'ID']\n",
    "temp = temp.groupby(by='ID').sum()\n",
    "temp.CLC.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appears to be working! Now onto the multivariate case..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate local join counts\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multivariate local join counts, at least those laid out in Anselin and Li 2019, is specific to expanding co-location clusters. Formally:\n",
    "\n",
    "$$ CLC_i = \\Pi^m_{h=1} x_{hi} \\sum_j w_{ij} \\Pi^m_{h=1} x_{hj} $$\n",
    "\n",
    "From our example above, let's consider the variables `x`, `z`, and a new third variable called `y`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "z [0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1]\n",
      "y [0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "x = x.astype(np.int32)\n",
    "print('x', x)\n",
    "print('z', z)\n",
    "y = [0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1]\n",
    "y = np.asarray(y).flatten()\n",
    "print('y', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we could expand the conditions above, I want to build this out from the onset as handling several input variables. So let's make a quick toy function that handles multiple inputs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multipleinputs(inputs):\n",
    "    # Printing them...\n",
    "    print(inputs)    \n",
    "    # looping through each input...\n",
    "    for i in inputs:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1], dtype=int64), array([0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]), array([0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1])]\n",
      "[0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "[0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1]\n",
      "[0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "multipleinputs([x,y,z])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need some kind of function that can:\n",
    "- create the zseries\n",
    "- map the focal values\n",
    "- map the nieghbor values\n",
    "- run equivalency checks\n",
    "\n",
    "We should be able to do this with a few list comprehension functions. Let's try:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [x,y,z]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The zseries\n",
    "zseries = [pd.Series(i, index=w.id_order) for i in variables]\n",
    "# The focal values\n",
    "focal = [zseries[i].loc[adj_list.focal].values for i in range(len(variables))]\n",
    "# The neighbor values\n",
    "neighbor = [zseries[i].loc[adj_list.neighbor].values for i in range(len(variables))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the results and manually validate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     1\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    1\n",
      "15    1\n",
      "dtype: int32, 0     0\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    1\n",
      "12    0\n",
      "13    0\n",
      "14    1\n",
      "15    1\n",
      "dtype: int32, 0     0\n",
      "1     1\n",
      "2     0\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     0\n",
      "9     0\n",
      "10    1\n",
      "11    1\n",
      "12    0\n",
      "13    0\n",
      "14    1\n",
      "15    1\n",
      "dtype: int32]\n",
      "[array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1]), array([0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1]), array([0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1,\n",
      "       1, 1, 1, 1])]\n",
      "[array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0,\n",
      "       0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "       1, 1, 1, 1]), array([1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1,\n",
      "       1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
      "       0, 1, 1, 1]), array([1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1,\n",
      "       0, 1, 1, 1])]\n"
     ]
    }
   ],
   "source": [
    "print(zseries)\n",
    "print(focal)\n",
    "print(neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the most important part, we need to expand the following function to as many variables are input. For former co-location cluster (CLC) now becomes the multivariate co-location cluster (MCLC):\n",
    "\n",
    "`MCLC = (focal_x == 1) & (focal_z == 1) & (focal_y == 1) & (neighbor_x == 1) & (neighbor_z == 1) & (neighbor_y == 1) & \n",
    "... (focal_m == 1) & (neighbor_m == 1)`\n",
    "\n",
    "From this point we can use a trick from the original pysal esda join count implementation. Because we need the `focal` and `neighbor` values to all equal 1, we can multiply them. Any 0 will automatically reduce to 0, leaving only the valid 1 candidates left."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "focal_all = np.multiply(*focal)\n",
    "neighbor_all = np.multiply(*neighbor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1\n",
      " 1 0 0 0 0 0 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(focal_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 1 0 0 0 0 1 0 0 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "print(neighbor_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can return to the original implementation of `CLC` and identify those that are both 1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False,  True, False, False, False, False, False, False, False,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCLC = (focal_all == 1) & (neighbor_all == 1)\n",
    "MCLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2], dtype=uint64)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "temp = pd.DataFrame(adj_list.focal.values, MCLC.astype('uint8')).reset_index()\n",
    "# Temporarily rename the columns\n",
    "temp.columns = ['MCLC', 'ID']\n",
    "temp = temp.groupby(by='ID').sum()\n",
    "temp.MCLC.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Amazingly, it works!!! I thought this part would be the hardest for sure (this must mean that the hardest has yet to come!) There is likely some optimization to be done, but I'm quite relieved to have been able to at least pseudo-coded all of the functions in about 3-4 working days. There is still a major hurdle - inference - but I am going to get supervisor input on that. \n",
    "\n",
    "The next step is migrating the pseudo-code into functions that match the structure of existing pysal esda functions. That will be in a new workbook called `migration.ipynb`. After they have been migrated I'll then isolate each into a `.py` file."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}