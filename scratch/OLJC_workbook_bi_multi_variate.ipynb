{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Univariate local join counts (LJC), bivariate LJC, multivariate LJC\n",
    "\n",
    "### Univariate local join counts (LJC)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To review, the global black-black (1-1) count is the total across the entire study area:\n",
    "\n",
    "$$BB = \\sum_{i} \\sum_j w_{ij} x_{i} x_{j}$$\n",
    "\n",
    "However, the local is: \n",
    "\n",
    "$$BB_i = x_i \\sum_{j} w_{ij} x_j$$\n",
    "\n",
    "...where a count of the neighbors with an observation of $x_j=1$ for those locations where $x_i=1$. This focuses on the BB counts of a given polygon (x_i)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What we will do now is to remake the data as it appears in the docstrings of the join_count function and try to get the bivariate, then multivariate, up and running.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new y_1 [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import libpysal\n",
    "import pandas as pd\n",
    "\n",
    "# Create a 16x16 grid\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "y_1 = np.ones(16)\n",
    "# Set the first 9 of the ones to 0\n",
    "y_1[0:8] = 0\n",
    "print('new y_1', y_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carry out some standardization processes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the input vector y\n",
    "y_1 = np.asarray(y_1).flatten()\n",
    "print(y_1)\n",
    "# ensure weights are binary transformed\n",
    "w.transformation = 'b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Identify univariate local join counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "0       0         4     1.0\n",
      "1       0         1     1.0\n",
      "2       1         0     1.0\n",
      "3       1         5     1.0\n",
      "4       1         2     1.0\n",
      "5       2         1     1.0\n",
      "6       2         6     1.0\n",
      "7       2         3     1.0\n",
      "8       3         2     1.0\n",
      "9       3         7     1.0\n",
      "10      4         0     1.0\n",
      "11      4         8     1.0\n",
      "12      4         5     1.0\n",
      "13      5         1     1.0\n",
      "14      5         4     1.0\n",
      "15      5         9     1.0\n",
      "16      5         6     1.0\n",
      "17      6         2     1.0\n",
      "18      6         5     1.0\n",
      "19      6        10     1.0\n",
      "20      6         7     1.0\n",
      "21      7         3     1.0\n",
      "22      7         6     1.0\n",
      "23      7        11     1.0\n",
      "24      8         4     1.0\n",
      "25      8        12     1.0\n",
      "26      8         9     1.0\n",
      "27      9         5     1.0\n",
      "28      9         8     1.0\n",
      "29      9        13     1.0\n",
      "30      9        10     1.0\n",
      "31     10         6     1.0\n",
      "32     10         9     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "35     11         7     1.0\n",
      "36     11        10     1.0\n",
      "37     11        15     1.0\n",
      "38     12         8     1.0\n",
      "39     12        13     1.0\n",
      "40     13         9     1.0\n",
      "41     13        12     1.0\n",
      "42     13        14     1.0\n",
      "43     14        10     1.0\n",
      "44     14        13     1.0\n",
      "45     14        15     1.0\n",
      "46     15        11     1.0\n",
      "47     15        14     1.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1], dtype=uint8)"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "adj_list = w.to_adjlist(remove_symmetric=False) \n",
    "print(adj_list)\n",
    "zseries_var1 = pd.Series(y_1, index=w.id_order)\n",
    "focal_var1 = zseries_var1.loc[adj_list.focal].values\n",
    "neighbor_var1 = zseries_var1.loc[adj_list.neighbor].values\n",
    "# Identify which adjacency lists are both equal to 1\n",
    "BBs = (focal_var1 == 1) & (neighbor_var1 == 1)\n",
    "BBs\n",
    "# also convert to a 0/1 array\n",
    "BBs.astype('uint8')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to map these T/F to the arrangement of the vector. While I got the correct output, it's a bit messy. This part is tricky and will likely need optimization - can we exploit the natural structure of the adjacency list without needing to make a new dataframe and run a groupby? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 2, 3, 3, 2, 2, 3, 3, 2], dtype=uint64)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "temp = pd.DataFrame(adj_list.focal.values, BBs.astype('uint8')).reset_index()\n",
    "# Temporarily rename the columns\n",
    "temp.columns = ['BB', 'ID']\n",
    "temp = temp.groupby(by='ID').sum()\n",
    "temp.BB.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will still need to sort out inference!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bivariate local join counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to bivariate local join counts. Using the nomenclature `x` and `z` to represent the two variables.\n",
    "\n",
    "Firstly, the **co-location** of the events at location $i$ need to be taken into account. As explained in the other workbook, there are two kinds of bivariate local join counts considered. \n",
    "\n",
    "**Case 1: no in-situ co-location**: 'where $x_i$ and $z_i$ do NOT take on the same value at either location $i$ (itself) or $j$ (neighbors)\n",
    "\n",
    "- Example: when $x_i=1$ for location $i$, then $z_i=0$. We count the number of neighbors of $i$ when $x_i=1$ for which the value of $z_j=1$ but the value of $x_j=0$\n",
    "\n",
    "This effectively becomes a combination of identifcation where `x` is in a black(1)-white(0) join, and where `y` is in a white(0)-black(1) join.\n",
    "\n",
    "Let's experiment..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "z [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "x = y_1\n",
    "z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "\n",
    "print('x', x)\n",
    "print('z', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carry out some standardization procedures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the input vector y\n",
    "x = np.asarray(x).flatten()\n",
    "z = np.asarray(z).flatten()\n",
    "print(x)\n",
    "print(z)\n",
    "# ensure weights are binary transformed\n",
    "w.transformation = 'b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create adjacency list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "0       0         4     1.0\n",
      "1       0         1     1.0\n",
      "2       1         0     1.0\n",
      "3       1         5     1.0\n",
      "4       1         2     1.0\n",
      "5       2         1     1.0\n",
      "6       2         6     1.0\n",
      "7       2         3     1.0\n",
      "8       3         2     1.0\n",
      "9       3         7     1.0\n",
      "10      4         0     1.0\n",
      "11      4         8     1.0\n",
      "12      4         5     1.0\n",
      "13      5         1     1.0\n",
      "14      5         4     1.0\n",
      "15      5         9     1.0\n",
      "16      5         6     1.0\n",
      "17      6         2     1.0\n",
      "18      6         5     1.0\n",
      "19      6        10     1.0\n",
      "20      6         7     1.0\n",
      "21      7         3     1.0\n",
      "22      7         6     1.0\n",
      "23      7        11     1.0\n",
      "24      8         4     1.0\n",
      "25      8        12     1.0\n",
      "26      8         9     1.0\n",
      "27      9         5     1.0\n",
      "28      9         8     1.0\n",
      "29      9        13     1.0\n",
      "30      9        10     1.0\n",
      "31     10         6     1.0\n",
      "32     10         9     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "35     11         7     1.0\n",
      "36     11        10     1.0\n",
      "37     11        15     1.0\n",
      "38     12         8     1.0\n",
      "39     12        13     1.0\n",
      "40     13         9     1.0\n",
      "41     13        12     1.0\n",
      "42     13        14     1.0\n",
      "43     14        10     1.0\n",
      "44     14        13     1.0\n",
      "45     14        15     1.0\n",
      "46     15        11     1.0\n",
      "47     15        14     1.0\n"
     ]
    }
   ],
   "source": [
    "adj_list = w.to_adjlist(remove_symmetric=False) \n",
    "print(adj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should now be able to use this adjacency list to run comparisons between `x` and `z`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, set up a series that maps the y values (input as self.y) to the weights table \n",
    "zseries_x = pd.Series(x, index=w.id_order)\n",
    "zseries_z = pd.Series(z, index=w.id_order)\n",
    "\n",
    "# Next, map the y values to the focal (i) values \n",
    "focal_x = zseries_x.loc[adj_list.focal].values\n",
    "focal_z = zseries_z.loc[adj_list.focal].values\n",
    "\n",
    "# Repeat the mapping but for the neighbor (j) values\n",
    "neighbor_x = zseries_x.loc[adj_list.neighbor].values\n",
    "neighbor_z = zseries_z.loc[adj_list.neighbor].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the `y_1` and `y_2` vectors have been mapped to focal and neighbor objects (respectively `_var1` and `_var2`). \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BJC = (focal_x == 1) & (focal_z == 0) & (neighbor_x == 0) & (neighbor_z == 1)\n",
    "BJC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], dtype=uint64)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "temp = pd.DataFrame(adj_list.focal.values, BJC.astype('uint8')).reset_index()\n",
    "# Temporarily rename the columns\n",
    "temp.columns = ['BJC', 'ID']\n",
    "temp = temp.groupby(by='ID').sum()\n",
    "temp.BJC.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appears to be working! Now onto the next case..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Case 2:**"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
