{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# See after the copy-pasted function for a detailed workthrough of how the join counts are calculated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# examining pysal esda implementation of global join counts\n",
    "\n",
    "\"\"\"\n",
    "Spatial autocorrelation for binary attributes\n",
    "\"\"\"\n",
    "__author__ = \"Sergio J. Rey <srey@asu.edu> , Luc Anselin <luc.anselin@asu.edu>\"\n",
    "\n",
    "from libpysal.weights.spatial_lag import lag_spatial\n",
    "from esda.tabular import _univariate_handler # change from .tabular to esda.tabular when working on independent machine\n",
    "from scipy.stats import chi2_contingency\n",
    "from scipy.stats import chi2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "__all__ = ['Join_Counts']\n",
    "\n",
    "PERMUTATIONS = 999\n",
    "\n",
    "\n",
    "class Join_Counts(object):\n",
    "    \"\"\"Binary Join Counts\n",
    "    Parameters\n",
    "    ----------\n",
    "    y               : array\n",
    "                      binary variable measured across n spatial units\n",
    "    w               : W\n",
    "                      spatial weights instance\n",
    "    permutations    : int\n",
    "                      number of random permutations for calculation of pseudo-p_values\n",
    "    Attributes\n",
    "    ----------\n",
    "    y            : array\n",
    "                   original variable\n",
    "    w            : W\n",
    "                   original w object\n",
    "    permutations : int\n",
    "                   number of permutations\n",
    "    bb           : float\n",
    "                   number of black-black joins\n",
    "    ww           : float\n",
    "                   number of white-white joins\n",
    "    bw           : float\n",
    "                   number of black-white joins\n",
    "    J            : float\n",
    "                   number of joins\n",
    "    sim_bb       : array\n",
    "                   (if permutations>0)\n",
    "                   vector of bb values for permuted samples\n",
    "    p_sim_bb     : array\n",
    "                  (if permutations>0)\n",
    "                   p-value based on permutations (one-sided)\n",
    "                   null: spatial randomness\n",
    "                   alternative: the observed bb is greater than under randomness\n",
    "    mean_bb      : float\n",
    "                   average of permuted bb values\n",
    "    min_bb       : float\n",
    "                   minimum of permuted bb values\n",
    "    max_bb       : float\n",
    "                   maximum of permuted bb values\n",
    "    sim_bw       : array\n",
    "                   (if permutations>0)\n",
    "                   vector of bw values for permuted samples\n",
    "    p_sim_bw     : array\n",
    "                   (if permutations>0)\n",
    "                   p-value based on permutations (one-sided)\n",
    "                   null: spatial randomness\n",
    "                   alternative: the observed bw is greater than under randomness\n",
    "    mean_bw      : float\n",
    "                   average of permuted bw values\n",
    "    min_bw       : float\n",
    "                   minimum of permuted bw values\n",
    "    max_bw       : float\n",
    "                   maximum of permuted bw values\n",
    "    chi2         : float\n",
    "                   Chi-square statistic on contingency table for join counts\n",
    "    chi2_p       : float\n",
    "                   Analytical p-value for chi2\n",
    "    chi2_dof     : int\n",
    "                   Degrees of freedom for analytical chi2\n",
    "    crosstab     : DataFrame\n",
    "                   Contingency table for observed join counts\n",
    "    expected     : DataFrame\n",
    "                   Expected contingency table for the null \n",
    "    p_sim_chi2   : float\n",
    "                   p-value for chi2 under random spatial permutations\n",
    "    Examples\n",
    "    --------\n",
    "    >>> import numpy as np\n",
    "    >>> import libpysal\n",
    "    >>> w = libpysal.weights.lat2W(4, 4)\n",
    "    >>> y = np.ones(16)\n",
    "    >>> y[0:8] = 0\n",
    "    >>> np.random.seed(12345)\n",
    "    >>> from esda.join_counts import Join_Counts\n",
    "    >>> jc = Join_Counts(y, w)\n",
    "    >>> jc.bb\n",
    "    10.0\n",
    "    >>> jc.bw\n",
    "    4.0\n",
    "    >>> jc.ww\n",
    "    10.0\n",
    "    >>> jc.J\n",
    "    24.0\n",
    "    >>> len(jc.sim_bb)\n",
    "    999\n",
    "    >>> round(jc.p_sim_bb, 3)\n",
    "    0.003\n",
    "    >>> round(np.mean(jc.sim_bb), 3)\n",
    "    5.547\n",
    "    >>> np.max(jc.sim_bb)\n",
    "    10.0\n",
    "    >>> np.min(jc.sim_bb)\n",
    "    0.0\n",
    "    >>> len(jc.sim_bw)\n",
    "    999\n",
    "    >>> jc.p_sim_bw\n",
    "    1.0\n",
    "    >>> np.mean(jc.sim_bw)\n",
    "    12.811811811811811\n",
    "    >>> np.max(jc.sim_bw)\n",
    "    24.0\n",
    "    >>> np.min(jc.sim_bw)\n",
    "    7.0\n",
    "    >>> round(jc.chi2_p, 3)\n",
    "    0.004\n",
    "    >>> jc.p_sim_chi2\n",
    "    0.002\n",
    "    Notes\n",
    "    -----\n",
    "    Technical details and derivations can be found in :cite:`cliff81`.\n",
    "    \"\"\"\n",
    "    def __init__(self, y, w, permutations=PERMUTATIONS):\n",
    "        y = np.asarray(y).flatten()\n",
    "        w.transformation = 'b'  # ensure we have binary weights\n",
    "        self.w = w\n",
    "        self.adj_list = self.w.to_adjlist(remove_symmetric=True) # a function of the weights method in pysal, \n",
    "        # to_adjlist(self[, remove_symmetric, â€¦]) which computes an adjacency list representation of a weights object.\n",
    "        self.y = y\n",
    "        self.permutations = permutations\n",
    "        self.J = w.s0 / 2.\n",
    "        results = self.__calc(self.y)\n",
    "        self.bb = results[0]\n",
    "        self.ww = results[1]\n",
    "        self.bw = results[2]\n",
    "        self.chi2 = results[3]\n",
    "        self.chi2_p = results[4]\n",
    "        self.chi2_dof = results[5]\n",
    "        self.autocorr_pos = self.bb + self.ww\n",
    "        self.autocorr_neg = self.bw\n",
    "\n",
    "        crosstab = pd.DataFrame(data=results[-1])\n",
    "        id_names = ['W', 'B']\n",
    "        idx = pd.Index(id_names, name='Focal')\n",
    "        crosstab.set_index(idx, inplace=True)\n",
    "        crosstab.columns = pd.Index(id_names, name='Neighbor')\n",
    "        self.crosstab = crosstab\n",
    "        expected = pd.DataFrame(data=results[6])\n",
    "        expected.set_index(idx, inplace=True)\n",
    "        expected.columns = pd.Index(id_names, name='Neighbor')\n",
    "        self.expected = expected\n",
    "        self.calc = self.__calc\n",
    "\n",
    "        if permutations:\n",
    "            sim = []\n",
    "            i = 0\n",
    "            while i < permutations:\n",
    "                try:\n",
    "                    res = self.__calc(np.random.permutation(self.y))\n",
    "                    sim.append(res)\n",
    "                    i += 1\n",
    "                except ValueError:\n",
    "                    # expected count of 0 -> inadmissible\n",
    "                    pass\n",
    "            sim_jc = np.array(sim, dtype=object)\n",
    "            self.sim_bb = sim_jc[:, 0]\n",
    "            self.min_bb = np.min(self.sim_bb)\n",
    "            self.mean_bb = np.mean(self.sim_bb)\n",
    "            self.max_bb = np.max(self.sim_bb)\n",
    "            self.sim_bw = sim_jc[:, 2]\n",
    "            self.min_bw = np.min(self.sim_bw)\n",
    "            self.mean_bw = np.mean(self.sim_bw)\n",
    "            self.max_bw = np.max(self.sim_bw)\n",
    "            self.sim_autocurr_pos = sim_jc[:, 0]+sim_jc[:, 1]\n",
    "            self.sim_autocurr_neg = sim_jc[:, 2]\n",
    "            self.sim_chi2 = sim_jc[:, 3]\n",
    "\n",
    "            stat = ((self.autocorr_pos - np.mean(self.sim_autocurr_pos))**2 / np.mean(self.sim_autocurr_pos)**2 +\n",
    "                                              (self.autocorr_neg - np.mean(self.sim_autocurr_neg))**2 / np.mean(self.sim_autocurr_pos)**2)\n",
    "            self.sim_autocorr_chi2 = 1 - chi2.cdf(stat, 1)\n",
    "\n",
    "            p_sim_bb = self.__pseudop(self.sim_bb, self.bb)\n",
    "            p_sim_bw = self.__pseudop(self.sim_bw, self.bw)\n",
    "            p_sim_chi2 = self.__pseudop(self.sim_chi2, self.chi2)\n",
    "            p_sim_autocorr_pos = self.__pseudop(self.sim_autocurr_pos, self.autocorr_pos)\n",
    "            p_sim_autocorr_neg = self.__pseudop(self.sim_autocurr_neg, self.autocorr_neg)\n",
    "            self.p_sim_bb = p_sim_bb\n",
    "            self.p_sim_bw = p_sim_bw\n",
    "            self.p_sim_chi2 = p_sim_chi2\n",
    "            self.p_sim_autocorr_pos = p_sim_autocorr_pos\n",
    "            self.p_sim_autocorr_neg = p_sim_autocorr_neg\n",
    "\n",
    "    def __calc(self, z):\n",
    "        adj_list = self.adj_list\n",
    "        zseries = pd.Series(z, index=self.w.id_order)\n",
    "        focal = zseries.loc[adj_list.focal].values\n",
    "        neighbor = zseries.loc[adj_list.neighbor].values\n",
    "        sim = focal == neighbor\n",
    "        dif = 1 - sim\n",
    "        bb = (focal * sim).sum()\n",
    "        ww = ((1-focal) * sim).sum()\n",
    "        bw = (focal * dif).sum()\n",
    "        wb = ((1-focal) * dif).sum()\n",
    "        table = [[ww, wb],\n",
    "                [bw, bb]]\n",
    "        chi2 = chi2_contingency(table)\n",
    "        stat, pvalue, dof, expected = chi2\n",
    "        return (bb, ww, bw+wb, stat, pvalue, dof, expected, np.array(table))\n",
    "\n",
    "    def __pseudop(self, sim, jc):\n",
    "        above = sim >=jc\n",
    "        larger = sum(above)\n",
    "        psim = (larger + 1.) / (self.permutations + 1.)\n",
    "        return psim\n",
    "\n",
    "    @property\n",
    "    def _statistic(self):\n",
    "        return self.bw\n",
    "\n",
    "    @classmethod\n",
    "    def by_col(cls, df, cols, w=None, inplace=False, pvalue='sim', outvals=None, **stat_kws):\n",
    "        \"\"\"\n",
    "        Function to compute a Join_Count statistic on a dataframe\n",
    "        Arguments\n",
    "        ---------\n",
    "        df          :   pandas.DataFrame\n",
    "                        a pandas dataframe with a geometry column\n",
    "        cols        :   string or list of string\n",
    "                        name or list of names of columns to use to compute the statistic\n",
    "        w           :   pysal weights object\n",
    "                        a weights object aligned with the dataframe. If not provided, this\n",
    "                        is searched for in the dataframe's metadata\n",
    "        inplace     :   bool\n",
    "                        a boolean denoting whether to operate on the dataframe inplace or to\n",
    "                        return a series contaning the results of the computation. If\n",
    "                        operating inplace, the derived columns will be named\n",
    "                        'column_join_count'\n",
    "        pvalue      :   string\n",
    "                        a string denoting which pvalue should be returned. Refer to the\n",
    "                        the Join_Count statistic's documentation for available p-values\n",
    "        outvals     :   list of strings\n",
    "                        list of arbitrary attributes to return as columns from the\n",
    "                        Join_Count statistic\n",
    "        **stat_kws  :   keyword arguments\n",
    "                        options to pass to the underlying statistic. For this, see the\n",
    "                        documentation for the Join_Count statistic.\n",
    "        Returns\n",
    "        --------\n",
    "        If inplace, None, and operation is conducted on dataframe in memory. Otherwise,\n",
    "        returns a copy of the dataframe with the relevant columns attached.\n",
    "        \"\"\"\n",
    "        if outvals is None:\n",
    "            outvals = []\n",
    "            outvals.extend(['bb', 'p_sim_bw', 'p_sim_bb'])\n",
    "            pvalue = ''\n",
    "        return _univariate_handler(df, cols, w=w, inplace=inplace, pvalue=pvalue,\n",
    "                                   outvals=outvals, stat=cls,\n",
    "                                   swapname='bw', **stat_kws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working through docstrings example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{4: 1.0, 1: 1.0}\n",
      "{0: 1.0, 5: 1.0, 2: 1.0}\n",
      "{1: 1.0, 6: 1.0, 3: 1.0}\n",
      "{2: 1.0, 7: 1.0}\n",
      "{0: 1.0, 8: 1.0, 5: 1.0}\n",
      "{1: 1.0, 4: 1.0, 9: 1.0, 6: 1.0}\n",
      "{11: 1.0, 14: 1.0}\n",
      "original y [1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "adulterated y [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import libpysal\n",
    "# Create a 16x16 grid of weights\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "print(w[0])\n",
    "print(w[1])\n",
    "print(w[2])\n",
    "print(w[3])\n",
    "print(w[4])\n",
    "print(w[5])\n",
    "# ...\n",
    "print(w[15])\n",
    "# Create a vector of 16 ones\n",
    "y = np.ones(16)\n",
    "print('original y', y)\n",
    "# Set the first 9 of the ones to 0\n",
    "y[0:8] = 0\n",
    "print('adulterated y', y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(12345)\n",
    "from esda.join_counts import Join_Counts\n",
    "jc = Join_Counts(y,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "10.0\n",
      "4.0\n"
     ]
    }
   ],
   "source": [
    "# print number of black-black (1-1) joins\n",
    "print(jc.bb)\n",
    "# print number of white-white (0-0) joins\n",
    "print(jc.ww)\n",
    "# print number of black-white (0-1) joins\n",
    "print(jc.bw)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# So what is going on here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "<libpysal.weights.weights.W object at 0x20E72250>\n"
     ]
    }
   ],
   "source": [
    "# print out input and weights\n",
    "print(y)\n",
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "1       0         1     1.0\n",
      "3       1         5     1.0\n",
      "5       2         1     1.0\n",
      "7       2         3     1.0\n",
      "10      4         0     1.0\n",
      "12      4         5     1.0\n",
      "16      5         6     1.0\n",
      "17      6         2     1.0\n",
      "21      7         3     1.0\n",
      "22      7         6     1.0\n",
      "23      7        11     1.0\n",
      "24      8         4     1.0\n",
      "25      8        12     1.0\n",
      "27      9         5     1.0\n",
      "28      9         8     1.0\n",
      "31     10         6     1.0\n",
      "32     10         9     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "37     11        15     1.0\n",
      "39     12        13     1.0\n",
      "40     13         9     1.0\n",
      "44     14        13     1.0\n",
      "45     14        15     1.0\n",
      "{4: 1.0, 1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "# The functions begins like many other pysal functions\n",
    "\n",
    "# Flatten the input vector y\n",
    "y = np.asarray(y).flatten()\n",
    "\n",
    "# ensure weights are binary transformed\n",
    "w.transformation = 'b' \n",
    "\n",
    "# 'new' step to me: the adjacency list\n",
    "# this creates a list object of unique focal-neighbor pairs. \n",
    "# The remove_symmetric=True ensure that there are not duplicated (but reversed) adjacency pairs\n",
    "adj_list = w.to_adjlist(remove_symmetric=True) \n",
    "print(adj_list)\n",
    "print(w[0])\n",
    "\n",
    "# From this list we can validate neighbors. For example, in our \n",
    "# 4x4 grid, we know that the upper-left hand corner of the grid (w[0]) \n",
    "# only touches its right neighbor and bottom (note: we are NOT using a queen contiguity in this example). \n",
    "# Thus, the first weight object will capture these relationships and they will be reflected in the adj_list table \n",
    "# see [0 1 1.0] and [4 0 1.0]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have an adjacency setup and values in `y`, we need to calculate the various bb, bw, and ww combinations. `Join_Counts` does this in a series of clever maneuvers. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, set up a series that maps the y values (input as self.y) to the weights table \n",
    "zseries = pd.Series(y, index=w.id_order)\n",
    "# Next, map the y values to the focal (i) values \n",
    "focal = zseries.loc[adj_list.focal].values\n",
    "# Repeat the mapping but for the neighbor (j) values\n",
    "neighbor = zseries.loc[adj_list.neighbor].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's spend a bit of time examining what exactly is going on here. The `focal` object takes on the length 24. Note that this is the same number of total rows as the above `adj_list`. The command:\n",
    "\n",
    "`focal = zseries.loc[adj_list.focal].values`\n",
    "\n",
    "is using the **numerical value** as an **index** into the zseries (i.e. y list) object. This means that each focal will be assigned the y value corresponding to the location in the zeries (i.e. y list). For example, the focal 10 should get the `zseries[10]` value. Let's check:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Value of focal 10 (starts at row 16)\n",
    "print(focal[16])\n",
    "# Value of zeries at 10\n",
    "print(zseries[10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This process is repeated based on neighbors:\n",
    "\n",
    "`neighbor = zseries.loc[adj_list.neighbor].values`\n",
    "\n",
    "Although the same, note the overall more random pattern of values in the neighbors column. This will result in different patterns in the focal and neighbor objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(focal)\n",
    "print(neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have defined these nice vectors, how do we actually identify the the different bb/ww/bw counts? Well, we first run a comparison that compares **if a focal value equals the neighbor value** (captured in the `sim` object):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        True, False, False,  True, False,  True, False,  True,  True,\n",
       "        True,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim = focal == neighbor\n",
    "sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At first glance, this array of T/F may not seem like much. But, it is very powerful! If we combine it with the focal-neighbor informaiton from before, we can **identify which focal-neighborhood pairs are both equal to 1 (i.e. 1=1 or black-black), are both equal to 0 (i.e. 0=0 or white-white), or are discordant (i.e. 0-1 or black-white).**\n",
    "\n",
    "Before working through the logic of each, we need to create an object called `dif`. `dif` stands for difference - if the difference is 0, the focal-neighborhood pairs can be either 0 or 1. However, if the difference is 1, we know the pairs are discordant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dif = 1 - sim\n",
    "dif"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have all of our relevant elements defined, we can work through the logic of each bb/ww/bw/wb combination. \n",
    "\n",
    "**bb black-black 1-1**\n",
    "\n",
    "`bb = (focal * sim).sum()`\n",
    "\n",
    "We can get the count of bb values by multipling the `focal` object (1/0s) by the `sim` object (T/Fs). This will identify where the focal-neighbors are in agreement (1 or 0). By taking the sum, we count only the the 1 values. This provides us with a count of the focal-neighbors that are both 1.  \n",
    "\n",
    "**ww white-white 0-0**\n",
    "\n",
    "`ww = ((1-focal) * sim).sum()`\n",
    "\n",
    "We first want to identify what parts of the focal are indeed equal to 0. To create this vector, we subtract each element of the `focal` vector from 1. This will result in a 1 value where the `focal` value is originally 0, and a 0 value where the `focal` value is originally 1. We can now multiply this 'flipped' `focal` vector by the `sim` object to identify where both the `focal` vector and `neighbor` vector have the same values (these values could be 0 or 1s, but now we have reduced the `focal` vector to only its instances of 0). As the agreements have now been recoded to 1, we can again take the sum to get a count of the focal-neighbors that are both 0. \n",
    "\n",
    "**bw black-white 1-0**\n",
    "\n",
    "`bw = (focal * dif).sum()`\n",
    "\n",
    "Note that the above equation is the same as the bb equation, except we swap in the `dif` vector. If the `dif` vector is equal to 1, we know the pairs are discordant. We multiply `focal` by `dif` to identify where original `focal` values of 1 do not agree with neighbor values (i.e. 0). This is a series of 1 times 0 or 1 operations. The resulting temporary vector identifies where the original `focal` value is 1 and the neighbor is 0, and we take the sum of these instances to get the `bw` counts. \n",
    "\n",
    "**wb white-black 0-1**\n",
    "\n",
    "`wb = ((1-focal) * dif).sum()`\n",
    "\n",
    "Note that the above equation is the same as the ww equation, except we swap in the `dif` vector. We first want to identify what parts of the focal are indeed equal to 0. To create this vector, we subtract each element of the `focal` vector from 1. This will result in a 1 value where the `focal` value is originally 0, and a 0 value where the `focal` value is originally 1. We can now multiply this 'flipped' `focal` vector by the `dif` vector to create a temporary vector where the original `focal` values of 0 (now coded as 1) agree with the `dif` vector. Again, the `dif` vector captures discordance generally, we use the flipped `focal` values to identify where the discordance is 0-1. We take the sum of these instances to get the `wb` counts. \n",
    "\n",
    "    If you want to visually confirm the process, these commands render the `wb` counts step by step:\n",
    "\n",
    "    `print((1-focal))`\n",
    "\n",
    "    `print(dif)`\n",
    "\n",
    "    `print((1-focal)*dif) # we can see that the sum of this vector would be 1`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0\n",
      "10.0\n",
      "3.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "# Calculate each of the combinations of interest\n",
    "bb = (focal * sim).sum(); print(bb)\n",
    "ww = ((1-focal) * sim).sum(); print(ww)\n",
    "bw = (focal * dif).sum(); print(bw)\n",
    "wb = ((1-focal) * dif).sum(); print(wb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then input these values into a table and use an existing python function called `chi2_contigency` to get some inference values. **Note that bw and wb are reported TOGETHER!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10.0 10.0 4.0 8.479632255856034 0.003591446953916693 1 [[5.95833333 5.04166667]\n",
      " [7.04166667 5.95833333]] [[10.  1.]\n",
      " [ 3. 10.]]\n"
     ]
    }
   ],
   "source": [
    "table = [[ww, wb],\n",
    "        [bw, bb]]\n",
    "# Feed into chi2_continency function\n",
    "chi2 = chi2_contingency(table)\n",
    "# Extract values from object\n",
    "stat, pvalue, dof, expected = chi2\n",
    "# Print\n",
    "print(bb, \n",
    "      ww, \n",
    "      bw+wb, \n",
    "      stat, \n",
    "      pvalue, \n",
    "      dof, \n",
    "      expected, \n",
    "      np.array(table))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concluding thought\n",
    "\n",
    "Quite an interesting breakdown! there is still a bit to go in regards to identify how to exploit this approach for the OLJC, but I feel much better having walked through this example.\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
