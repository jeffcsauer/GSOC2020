{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This is the validation notebook for the PySAL implementation of the local join count (LJC) multivariate statistic. This notebook will begin with a brief review of the multivariate LJC and a manual calculation of the values on a 'toy' dataset. We will then introduce the PySAL implementation of the `Local_Join_Count_MV` function. Output from the `Local_Join_Count_MV` function will be compared to the results from the manual calculation on the 'toy' dataset. Following the 'toy' dataset will be a comparison of the PySAL `Local_Join_Count_MV` function to the external `GeoDa` results on an external dataset. As of now, calculations of inference are not included in the function.\n",
    "\n",
    "1. [Review of the bivariate LJC statistic](#Review)\n",
    "2. [Manual calculations on a 'toy' dataset](#Toy)\n",
    "3. [Implementation of Local_Join_Count_MV function](#LJC)\n",
    "4. [Application of Local_Join_Count_MV function on the 'toy' dataset](#LJCToy)\n",
    "5. [Application of Local_Join_Count_MV function on 'real world' datasets](#LJCRealWorld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of the multivariate LJC statistic <a name=\"Review\"></a>\n",
    "\n",
    "Multivariate local join counts, at least those laid out in Anselin and Li 2019, is an expansion of the bivariate local join count statistic (case 2) for co-location clusters. Formally:\n",
    "\n",
    "$$ CLC_i = \\Pi^m_{h=1} x_{hi} \\sum_j w_{ij} \\Pi^m_{h=1} x_{hj} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual calculations on a 'toy' dataset <a name=\"Toy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the multivariate test, let's consider the variables `x`, `z`, and a new third variable called `y`. We now create a small 'toy' dataset to illustrate the local join counts. This toy dataset is a 4x4 lattice grid filled with 0s and 1s for each of the x, z, y binary variables. Note that for a given cell, the value of the x variable comes first, the value of the z variable comes second, and the value of the y variable comes third. \n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0,0,0 | 0,1,1 | 0,0,1 | 0,1,1 |\n",
    "| 0,1,1 | 0,1,1 | 0,1,1 | 0,1,1 |\n",
    "| 1,0,0 | 1,0,0 | 1,1,0 | 1,1,1 |\n",
    "| 1,0,0 | 1,0,0 | 1,1,1 | 1,1,1 |\n",
    "\n",
    "The arrangement of the above grid is captured in the `x`, `z`, and `y` objects below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "z [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "y [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import libpysal\n",
    "import pandas as pd\n",
    "\n",
    "# Create a 16x16 grid\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "y_1 = np.ones(16)\n",
    "# Set the first 9 of the ones to 0\n",
    "y_1[0:8] = 0\n",
    "# Set x equal to y_1\n",
    "x = y_1\n",
    "x = x.astype(np.int32)\n",
    "# Create another random sequences of 0 and 1\n",
    "z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "y = [0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1]\n",
    "print('x', x)\n",
    "print('z', z)\n",
    "print('y', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given cell of the above table, we are interest in the adjacent grid cells that are equal to 1. We can find these through the use of **binary weights**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "[0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1]\n",
      "[0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the input vector y\n",
    "x = np.asarray(x).flatten()\n",
    "z = np.asarray(z).flatten()\n",
    "y = np.asarray(y).flatten()\n",
    "print(x)\n",
    "print(z)\n",
    "print(y)\n",
    "# ensure weights are binary transformed\n",
    "w.transform = 'b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does PySAL identify these cells? Through an adjacency list. This creates a list object of unique focal ($i$) and neighbor ($j$) pairs. The `remove_symmetric=True` ensure that there are not duplicated (but reversed) adjacency pairs. This is a great shortcut when calculating global join counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "1       0         1     1.0\n",
      "3       1         5     1.0\n",
      "5       2         1     1.0\n",
      "7       2         3     1.0\n",
      "10      4         0     1.0\n",
      "12      4         5     1.0\n",
      "16      5         6     1.0\n",
      "17      6         2     1.0\n",
      "21      7         3     1.0\n",
      "22      7         6     1.0\n",
      "23      7        11     1.0\n",
      "24      8         4     1.0\n",
      "25      8        12     1.0\n",
      "27      9         5     1.0\n",
      "28      9         8     1.0\n",
      "31     10         6     1.0\n",
      "32     10         9     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "37     11        15     1.0\n",
      "39     12        13     1.0\n",
      "40     13         9     1.0\n",
      "44     14        13     1.0\n",
      "45     14        15     1.0\n",
      "{4: 1.0, 1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "adj_list = w.to_adjlist(remove_symmetric=True) \n",
    "print(adj_list)\n",
    "print(w[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list we can validate neighbors. For example, in our 4x4 grid, we know that the upper-left hand corner of the grid (w[0]) only touches its right and bottom neighbor(remember: we are not using a queen contiguity in this example). Thus, the first weight object will capture these relationships and they will be reflected in the adj_list table (see row 1 [0 1 1.0] and 4 [4 0 1.0]). \n",
    "\n",
    "**However, the Local Join Count (LJC) statistics do not use the `remove_symmetric=True`.** This allows us to identify the specific join counts for each area $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "0       0         4     1.0\n",
      "1       0         1     1.0\n",
      "2       1         0     1.0\n",
      "3       1         5     1.0\n",
      "4       1         2     1.0\n",
      "5       2         1     1.0\n",
      "6       2         6     1.0\n",
      "7       2         3     1.0\n",
      "8       3         2     1.0\n",
      "9       3         7     1.0\n",
      "10      4         0     1.0\n",
      "11      4         8     1.0\n",
      "12      4         5     1.0\n",
      "13      5         1     1.0\n",
      "14      5         4     1.0\n",
      "15      5         9     1.0\n",
      "16      5         6     1.0\n",
      "17      6         2     1.0\n",
      "18      6         5     1.0\n",
      "19      6        10     1.0\n",
      "20      6         7     1.0\n",
      "21      7         3     1.0\n",
      "22      7         6     1.0\n",
      "23      7        11     1.0\n",
      "24      8         4     1.0\n",
      "25      8        12     1.0\n",
      "26      8         9     1.0\n",
      "27      9         5     1.0\n",
      "28      9         8     1.0\n",
      "29      9        13     1.0\n",
      "30      9        10     1.0\n",
      "31     10         6     1.0\n",
      "32     10         9     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "35     11         7     1.0\n",
      "36     11        10     1.0\n",
      "37     11        15     1.0\n",
      "38     12         8     1.0\n",
      "39     12        13     1.0\n",
      "40     13         9     1.0\n",
      "41     13        12     1.0\n",
      "42     13        14     1.0\n",
      "43     14        10     1.0\n",
      "44     14        13     1.0\n",
      "45     14        15     1.0\n",
      "46     15        11     1.0\n",
      "47     15        14     1.0\n"
     ]
    }
   ],
   "source": [
    "adj_list = w.to_adjlist(remove_symmetric=False) \n",
    "print(adj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now mirror the existing implementation of `Join_Counts` to create some objects that count the number of 1 value for the focal ($i$) and neighbor ($j$) cells. We do this for both the x, z, and y variables. **Note: perhaps an area for optimization?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [x,y,z]\n",
    "# The zseries\n",
    "zseries = [pd.Series(i, index=w.id_order) for i in variables]\n",
    "# The focal values\n",
    "focal = np.array([zseries[i].loc[adj_list.focal].values for i in range(len(variables))])\n",
    "# The neighbor values\n",
    "neighbor = np.array([zseries[i].loc[adj_list.neighbor].values for i in range(len(variables))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the results and manually validate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     1\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    1\n",
      "15    1\n",
      "dtype: int32, 0     0\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    1\n",
      "12    0\n",
      "13    0\n",
      "14    1\n",
      "15    1\n",
      "dtype: int32, 0     0\n",
      "1     1\n",
      "2     0\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     0\n",
      "9     0\n",
      "10    1\n",
      "11    1\n",
      "12    0\n",
      "13    0\n",
      "14    1\n",
      "15    1\n",
      "dtype: int32]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  1 1 0 0 0 0 0 1 1 1 1 1]\n",
      " [0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1\n",
      "  1 1 0 0 0 0 0 1 1 1 1 1]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1\n",
      "  0 1 0 0 0 0 1 0 0 1 1 1]\n",
      " [1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1\n",
      "  1 1 0 0 0 0 1 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(zseries)\n",
    "print(focal)\n",
    "print(neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the most important part, we need to expand the following function to as many variables are input. For former co-location cluster (CLC) now becomes the multivariate co-location cluster (MCLC):\n",
    "\n",
    "`MCLC = (focal_x == 1) & (focal_z == 1) & (focal_y == 1) & (neighbor_x == 1) & (neighbor_z == 1) & (neighbor_y == 1) & \n",
    "... (focal_m == 1) & (neighbor_m == 1)`\n",
    "\n",
    "From this point we need to do a bit of code golf. We have a list-of-lists and we need to check to make sure that the vlaues across all the lists have the value of interest (1). Thus, we can combine the `np.all()` function with an `np.dstack()==1` conditional function. This does scalable, row-wise evaluation to find rows where all are equal to True (i.e. all values equal 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False  True\n",
      "   True  True False False False False False  True  True  True  True  True]]\n",
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False  True\n",
      "  False False False False False False False False False  True  True False\n",
      "  False  True False False False False  True False False  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "focal_all = np.all(np.dstack(focal)==1, axis=2)\n",
    "neighbor_all = np.all(np.dstack(neighbor)==1, axis=2)\n",
    "print(focal_all)\n",
    "print(neighbor_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can return to the original implementation of `CLC` and identify those that are both 1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCLC = (focal_all == True) & (neighbor_all == True)\n",
    "# Convert to boolean array\n",
    "MCLC = list(MCLC*1)\n",
    "MCLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "manual = pd.DataFrame(adj_list.focal.values, MCLC).reset_index()\n",
    "# Temporarily rename the columns\n",
    "manual.columns = ['MCLC', 'ID']\n",
    "manual = manual.groupby(by='ID').sum()\n",
    "manual.MCLC.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a visual comparison to the original table (remember, x values appear first and z values appear second):\n",
    "\n",
    "Original table\n",
    "\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0,0,0 | 0,1,1 | 0,0,1 | 0,1,1 |\n",
    "| 0,1,1 | 0,1,1 | 0,1,1 | 0,1,1 |\n",
    "| 1,0,0 | 1,0,0 | 1,1,0 | 1,1,1 |\n",
    "| 1,0,0 | 1,0,0 | 1,1,1 | 1,1,1 |\n",
    "\n",
    "\n",
    "Local Join Counts (multivariate)\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 1 |\n",
    "| 0 | 0 | 1 | 2 |\n",
    "\n",
    "This makes sense give our previously stated CLC conditions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Local_Join_Count_MV function <a name=\"LJC\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above manual calculations are implemented in the function called `Local_Join_Count_MV`. We run an ongoing notebook where the functions are being developed. Note that the below is likely to change over time. The following cell loads in the `Local_Join_Count_MV` function from the `migration.ipynb` (available on the [jeffcsauer/GSOC2020/scratch](https://github.com/jeffcsauer/GSOC2020/tree/master/scratch) github work journal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator\n",
    "from libpysal import weights\n",
    "\n",
    "PERMUTATIONS = 999\n",
    "\n",
    "class Local_Join_Count_MV(BaseEstimator):\n",
    "\n",
    "    \"\"\"Multivariate local join counts\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None, permutations=PERMUTATIONS):\n",
    "        \"\"\"\n",
    "        Initialize a Local_Join_Count_MV estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity:   scipy.sparse matrix object\n",
    "                        the connectivity structure describing the relationships\n",
    "                        between observed units. Will be row-standardized.\n",
    "        Attributes\n",
    "        ----------\n",
    "        LJC       :   numpy.ndarray\n",
    "                      array containing the estimated Multivariate Local Join Counts.\n",
    "        p_sim       :   numpy.ndarray\n",
    "                        array containing the simulated p-values for each unit.\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "        self.permutations = permutations\n",
    "\n",
    "    def fit(self, variables, permutations=999):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        variables     :   numpy.ndarray\n",
    "                          array(s) containing binary (0/1) data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`AnselinLi2019`.\n",
    "        \"\"\"\n",
    "\n",
    "        w = self.connectivity\n",
    "        # Fill the diagonal with 0s\n",
    "        w = weights.util.fill_diagonal(w, val=0)\n",
    "        w.transform = 'b'\n",
    "        \n",
    "        self.n = len(variables[0])\n",
    "        self.w = w\n",
    "        \n",
    "        self.variables = variables\n",
    "        \n",
    "        self.ext = np.prod(np.vstack(variables), axis=0)\n",
    "\n",
    "        self.LJC = self._statistic(variables, w)\n",
    "        \n",
    "        if permutations:\n",
    "            self._crand()\n",
    "            sim = np.transpose(self.rjoins)\n",
    "            above = sim >= self.LJC\n",
    "            larger = above.sum(0)\n",
    "            low_extreme = (self.permutations - larger) < larger\n",
    "            larger[low_extreme] = self.permutations - larger[low_extreme]\n",
    "            self.p_sim = (larger + 1.0) / (permutations + 1.0)\n",
    "            # Set p-values for those with LJC of 0 to NaN\n",
    "            self.p_sim[self.LJC==0] = 'NaN'\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(variables, w):\n",
    "        # Create adjacency list. Note that remove_symmetric=False -\n",
    "        # different from the esda.Join_Counts() function.\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "\n",
    "        # The zseries\n",
    "        zseries = [pd.Series(i, index=w.id_order) for i in variables]\n",
    "        # The focal values\n",
    "        focal = [zseries[i].loc[adj_list.focal].values for\n",
    "                 i in range(len(variables))]\n",
    "        # The neighbor values\n",
    "        neighbor = [zseries[i].loc[adj_list.neighbor].values for\n",
    "                    i in range(len(variables))]\n",
    "\n",
    "        # Find instances where all surrounding \n",
    "        # focal and neighbor values == 1\n",
    "        focal_all = np.array(np.all(np.dstack(focal)==1, \n",
    "                                    axis=2))\n",
    "        neighbor_all = np.array(np.all(np.dstack(neighbor)==1, \n",
    "                                       axis=2))\n",
    "        MCLC = (focal_all == True) & (neighbor_all == True)\n",
    "        # Convert list of True/False to boolean array \n",
    "        # and unlist (necessary for building pd.DF)\n",
    "        MCLC = list(MCLC*1)\n",
    "        \n",
    "        # Create a df that uses the adjacency list\n",
    "        # focal values and the BBs counts\n",
    "        adj_list_MCLC = pd.DataFrame(adj_list.focal.values,\n",
    "                                     MCLC).reset_index()\n",
    "        # Temporarily rename the columns\n",
    "        adj_list_MCLC.columns = ['MCLC', 'ID']\n",
    "        adj_list_MCLC = adj_list_MCLC.groupby(by='ID').sum()\n",
    "\n",
    "        return (adj_list_MCLC.MCLC.values)\n",
    "            \n",
    "    def _crand(self):\n",
    "        \"\"\"\n",
    "        conditional randomization\n",
    "\n",
    "        for observation i with ni neighbors,  the candidate set cannot include\n",
    "        i (we don't want i being a neighbor of i). we have to sample without\n",
    "        replacement from a set of ids that doesn't include i. numpy doesn't\n",
    "        directly support sampling wo replacement and it is expensive to\n",
    "        implement this. instead we omit i from the original ids,  permute the\n",
    "        ids and take the first ni elements of the permuted ids as the\n",
    "        neighbors to i in each randomization.\n",
    "\n",
    "        \"\"\"\n",
    "        # converted y to z\n",
    "        # renamed lisas to joins\n",
    "        ext = self.ext\n",
    "        # Get length based on first variable\n",
    "        n = len(ext)\n",
    "        joins = np.zeros((self.n, self.permutations))\n",
    "        n_1 = self.n - 1\n",
    "        prange = list(range(self.permutations))\n",
    "        k = self.w.max_neighbors + 1\n",
    "        nn = self.n - 1\n",
    "        rids = np.array([np.random.permutation(nn)[0:k] for i in prange])\n",
    "        ids = np.arange(self.w.n)\n",
    "        ido = self.w.id_order\n",
    "        w = [self.w.weights[ido[i]] for i in ids]\n",
    "        wc = [self.w.cardinalities[ido[i]] for i in ids]\n",
    "\n",
    "        for i in range(self.w.n):\n",
    "            idsi = ids[ids != i]\n",
    "            np.random.shuffle(idsi)\n",
    "            # Mirroring moran_local_bv()\n",
    "            tmp = ext[idsi[rids[:, 0:wc[i]]]]\n",
    "            joins[i] = ext[i] * (w[i] * tmp).sum(1)\n",
    "        self.rjoins = joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference not working at all - need to figure out how to scale for all input variables..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Local_Join_Count function on the 'toy' dataset <a name=\"LJCToy\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate inputs and weights (otherwise they are altered when running notebook)\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "y_1 = np.ones(16)\n",
    "# Set the first 9 of the ones to 0\n",
    "y_1[0:8] = 0\n",
    "# Set x equal to y_1\n",
    "x = y_1\n",
    "x = x.astype(np.int32)\n",
    "# Create another random sequences of 0 and 1\n",
    "z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "y = [0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1]\n",
    "# Run function\n",
    "toy_results = Local_Join_Count_MV(connectivity=w).fit([x, y, z])\n",
    "toy_results.LJC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare output of `Local_Join_Count` function to the manually-calculated `LJC` from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of toy function to manual values\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison of toy function to manual values\")\n",
    "print(toy_results.LJC == manual.MCLC.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All values match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Local_Join_Count_BV function on 'real world' datasets <a name=\"LJCRealWorld\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would look to compare the output to the values from the original Anselin and Li 2019 paper. However, the example use cases in Anselin and Li 2019 do not provide full tables of LJC and associate p-values to confirm equivalency. Thus, we compare the results from the PySAL implementation of `Local_Join_Counts_MV` to the output from GeoDa using a GeoDa example dataset. Specifically, we use the [Baltimore Housing Sales dataset](https://geodacenter.github.io/data-and-lab/baltim/) and focus on the 'dwell', 'patio', and 'firepl' binary variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to GeoDa output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load in the Baltimore Housing Sales dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>price</th>\n",
       "      <th>nroom</th>\n",
       "      <th>dwell</th>\n",
       "      <th>nbath</th>\n",
       "      <th>patio</th>\n",
       "      <th>firepl</th>\n",
       "      <th>ac</th>\n",
       "      <th>bment</th>\n",
       "      <th>nstor</th>\n",
       "      <th>gar</th>\n",
       "      <th>age</th>\n",
       "      <th>citcou</th>\n",
       "      <th>lotsz</th>\n",
       "      <th>sqft</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>11.25</td>\n",
       "      <td>907.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>POINT (907.000 534.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>279.51</td>\n",
       "      <td>28.92</td>\n",
       "      <td>922.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>POINT (922.000 574.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.64</td>\n",
       "      <td>30.62</td>\n",
       "      <td>920.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>POINT (920.000 581.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>104.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>174.63</td>\n",
       "      <td>26.12</td>\n",
       "      <td>923.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>POINT (923.000 578.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.80</td>\n",
       "      <td>22.04</td>\n",
       "      <td>918.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>POINT (918.000 574.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station  price  nroom  dwell  nbath  patio  firepl   ac  bment  nstor  gar  \\\n",
       "0      1.0   47.0    4.0    0.0    1.0    0.0     0.0  0.0    2.0    3.0  0.0   \n",
       "1      2.0  113.0    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  2.0   \n",
       "2      3.0  165.0    7.0    1.0    2.5    1.0     1.0  0.0    3.0    2.0  2.0   \n",
       "3      4.0  104.3    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  2.0   \n",
       "4      5.0   62.5    7.0    1.0    1.5    1.0     1.0  0.0    2.0    2.0  0.0   \n",
       "\n",
       "     age  citcou   lotsz   sqft      x      y                 geometry  \n",
       "0  148.0     0.0    5.70  11.25  907.0  534.0  POINT (907.000 534.000)  \n",
       "1    9.0     1.0  279.51  28.92  922.0  574.0  POINT (922.000 574.000)  \n",
       "2   23.0     1.0   70.64  30.62  920.0  581.0  POINT (920.000 581.000)  \n",
       "3    5.0     1.0  174.63  26.12  923.0  578.0  POINT (923.000 578.000)  \n",
       "4   19.0     1.0  107.80  22.04  918.0  574.0  POINT (918.000 574.000)  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "balt = gpd.read_file('https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/baltimore/baltimore_housing.gpkg')\n",
    "balt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate the variable of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_balt = balt['dwell']\n",
    "z_balt = balt['patio']\n",
    "y_balt = balt['firepl']\n",
    "\n",
    "x_balt = np.asarray(x_balt).flatten()\n",
    "z_balt = np.asarray(z_balt).flatten()\n",
    "y_balt = np.asarray(y_balt).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with points in PySAL we need to arrange them into a tree-able list of x and y points. Thus we extract the x and y columns of the baltimore dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = list(zip(balt['x'], balt['y']))\n",
    "import libpysal\n",
    "kd = libpysal.cg.KDTree(np.array(points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to recreate the weights used in the GeoDa analysis. The weight scheme used was a k-nearest neighbor (knn) approach, using 5 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "balt_knn5 = libpysal.weights.KNN(kd, k=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply our PySAL `Local_Join_Count_MV` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 5, 5, 3, 1, 4, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = Local_Join_Count_MV(connectivity=balt_knn5).fit([x_balt, z_balt, y_balt])\n",
    "test_results.LJC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in the results from GeoDa analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>price</th>\n",
       "      <th>nroom</th>\n",
       "      <th>dwell</th>\n",
       "      <th>nbath</th>\n",
       "      <th>patio</th>\n",
       "      <th>firepl</th>\n",
       "      <th>ac</th>\n",
       "      <th>bment</th>\n",
       "      <th>nstor</th>\n",
       "      <th>gar</th>\n",
       "      <th>age</th>\n",
       "      <th>citcou</th>\n",
       "      <th>lotsz</th>\n",
       "      <th>sqft</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>MV_JC</th>\n",
       "      <th>MV_NN</th>\n",
       "      <th>MV_PP_VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>11.25</td>\n",
       "      <td>907.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>113.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>279.51</td>\n",
       "      <td>28.92</td>\n",
       "      <td>922.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>165.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.64</td>\n",
       "      <td>30.62</td>\n",
       "      <td>920.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>104.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>174.63</td>\n",
       "      <td>26.12</td>\n",
       "      <td>923.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.80</td>\n",
       "      <td>22.04</td>\n",
       "      <td>918.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139.64</td>\n",
       "      <td>39.42</td>\n",
       "      <td>900.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>127.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>21.88</td>\n",
       "      <td>918.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>36.72</td>\n",
       "      <td>907.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>64.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.90</td>\n",
       "      <td>25.60</td>\n",
       "      <td>918.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>145.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.07</td>\n",
       "      <td>44.12</td>\n",
       "      <td>897.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station  price  nroom  dwell  nbath  patio  firepl   ac  bment  nstor  gar  \\\n",
       "0        1   47.0    4.0    0.0    1.0    0.0     0.0  0.0    2.0    3.0  0.0   \n",
       "1        2  113.0    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  2.0   \n",
       "2        3  165.0    7.0    1.0    2.5    1.0     1.0  0.0    3.0    2.0  2.0   \n",
       "3        4  104.3    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  2.0   \n",
       "4        5   62.5    7.0    1.0    1.5    1.0     1.0  0.0    2.0    2.0  0.0   \n",
       "5        6   70.0    6.0    1.0    2.5    1.0     1.0  0.0    3.0    3.0  1.0   \n",
       "6        7  127.5    6.0    1.0    2.5    1.0     1.0  1.0    3.0    1.0  2.0   \n",
       "7        8   53.0    8.0    1.0    1.5    1.0     0.0  0.0    0.0    3.0  0.0   \n",
       "8        9   64.5    6.0    1.0    1.0    1.0     1.0  1.0    3.0    2.0  0.0   \n",
       "9       10  145.0    7.0    1.0    2.5    1.0     1.0  1.0    3.0    2.0  2.0   \n",
       "\n",
       "     age  citcou   lotsz   sqft      x      y  MV_JC  MV_NN  MV_PP_VAL  \n",
       "0  148.0     0.0    5.70  11.25  907.0  534.0      0      5        NaN  \n",
       "1    9.0     1.0  279.51  28.92  922.0  574.0      4      5      0.001  \n",
       "2   23.0     1.0   70.64  30.62  920.0  581.0      5      5      0.001  \n",
       "3    5.0     1.0  174.63  26.12  923.0  578.0      5      5      0.001  \n",
       "4   19.0     1.0  107.80  22.04  918.0  574.0      3      5      0.007  \n",
       "5   20.0     1.0  139.64  39.42  900.0  577.0      1      5      0.274  \n",
       "6   20.0     1.0  250.00  21.88  918.0  576.0      4      5      0.001  \n",
       "7   22.0     1.0  100.00  36.72  907.0  576.0      0      5        NaN  \n",
       "8   22.0     1.0  115.90  25.60  918.0  562.0      0      5        NaN  \n",
       "9    4.0     1.0  365.07  44.12  897.0  576.0      1      5      0.274  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load GeoDa analysis results\n",
    "GeoDa_LJC = pd.read_csv('https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/baltimore/balt_knn_5_LJC_multivariate.csv')\n",
    "GeoDa_LJC.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the PySAL LJC results to to the GeoDa LJC results. Due to the somewhat high (n=211) number of comparisons, we will tabulate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of GeoDa multivariate LJC to PySAL implementation:\n",
      "True    211\n",
      "Name: MV_JC, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison of GeoDa multivariate LJC to PySAL implementation:\")\n",
    "results = test_results.LJC == GeoDa_LJC['MV_JC']\n",
    "print(results.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 211 elements have the same multivariate LJC between the PySAL implementation and the GeoDa results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing p-values at surface level..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan, 0.001, 0.001, 0.001, 0.001, 0.287, 0.001,   nan,   nan,\n",
       "       0.279])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.p_sim[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan, 0.001, 0.001, 0.001, 0.007, 0.274, 0.001,   nan,   nan,\n",
       "       0.274])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(GeoDa_LJC.MV_PP_VAL[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences in p-values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   nan,  0.   ,  0.   ,  0.   , -0.006,  0.013,  0.   ,    nan,\n",
       "          nan,  0.005])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.p_sim[0:10] - np.array(GeoDa_LJC.MV_PP_VAL[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between the two sets of p-values is 0.9996291912567704\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x22a60718>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assess correlation between p-values\n",
    "corrdf = pd.DataFrame(test_results.p_sim, GeoDa_LJC.MV_PP_VAL).reset_index()\n",
    "corrdf.columns = ['pysal', 'geoda']\n",
    "print(\"The correlation between the two sets of p-values is\", corrdf['pysal'].corr(corrdf['geoda']))\n",
    "\n",
    "corrdf.plot.scatter(x='pysal',\n",
    "                    y='geoda',\n",
    "                    c='DarkBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "- Ensure docstrings include all relevant information and formatting\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 32-bit",
   "language": "python",
   "name": "python38232bit07c05656855047638d93928e72c365e6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
