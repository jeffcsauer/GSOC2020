{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This is the validation notebook for the PySAL implementation of the local join count (LJC) multivariate statistic. This notebook will begin with a brief review of the multivariate LJC and a manual calculation of the values on a 'toy' dataset. We will then introduce the PySAL implementation of the `Local_Join_Count_MV` function. Output from the `Local_Join_Count_MV` function will be compared to the results from the manual calculation on the 'toy' dataset. Following the 'toy' dataset will be a comparison of the PySAL `Local_Join_Count_MV` function to the external `GeoDa` results on an external dataset. As of now, calculations of inference are not included in the function.\n",
    "\n",
    "1. [Review of the bivariate LJC statistic](#Review)\n",
    "2. [Manual calculations on a 'toy' dataset](#Toy)\n",
    "3. [Implementation of Local_Join_Count_MV function](#LJC)\n",
    "4. [Application of Local_Join_Count_MV function on the 'toy' dataset](#LJCToy)\n",
    "5. [Application of Local_Join_Count_MV function on 'real world' datasets](#LJCRealWorld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of the multivariate LJC statistic <a name=\"Review\"></a>\n",
    "\n",
    "Multivariate local join counts are an expansion of the bivariate local join count statistic (case 2) for co-location clusters. Formally:\n",
    "\n",
    "$$ CLC_i = \\Pi^m_{h=1} x_{hi} \\sum_j w_{ij} \\Pi^m_{h=1} x_{hj} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual calculations on a 'toy' dataset <a name=\"Toy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the multivariate test, let's consider the variables `x`, `z`, and a new third variable called `y`. We now create a small 'toy' dataset to illustrate the local join counts. This toy dataset is a 4x4 lattice grid filled with 0s and 1s for each of the x, z, y binary variables. Note that for a given cell, the value of the x variable comes first, the value of the z variable comes second, and the value of the y variable comes third. \n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0,0,0 | 0,1,1 | 0,0,1 | 0,1,1 |\n",
    "| 0,1,1 | 0,1,1 | 0,1,1 | 0,1,1 |\n",
    "| 1,0,0 | 1,0,0 | 1,1,0 | 1,1,1 |\n",
    "| 1,0,0 | 1,0,0 | 1,1,1 | 1,1,1 |\n",
    "\n",
    "The arrangement of the above grid is captured in the `x`, `z`, and `y` objects below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "z [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n",
      "y [0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import libpysal\n",
    "import pandas as pd\n",
    "\n",
    "# Create a 16x16 grid\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "y_1 = np.ones(16)\n",
    "# Set the first 9 of the ones to 0\n",
    "y_1[0:8] = 0\n",
    "# Set x equal to y_1\n",
    "x = y_1\n",
    "x = x.astype(np.int32)\n",
    "# Create another random sequences of 0 and 1\n",
    "z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "y = [0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1]\n",
    "print('x', x)\n",
    "print('z', z)\n",
    "print('y', y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given cell of the above table, we are interest in the adjacent grid cells that are equal to 1. We can find these through the use of **binary weights**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1]\n",
      "[0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1]\n",
      "[0 1 1 1 1 1 1 1 0 0 0 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the input vector y\n",
    "x = np.asarray(x).flatten()\n",
    "z = np.asarray(z).flatten()\n",
    "y = np.asarray(y).flatten()\n",
    "print(x)\n",
    "print(z)\n",
    "print(y)\n",
    "# ensure weights are binary transformed\n",
    "w.transform = 'b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does PySAL identify these cells? Through an adjacency list. This creates a list object of unique focal ($i$) and neighbor ($j$) pairs. The `remove_symmetric=True` ensure that there are not duplicated (but reversed) adjacency pairs. This is a great shortcut when calculating global join counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "0       0         4     1.0\n",
      "1       0         1     1.0\n",
      "3       1         5     1.0\n",
      "4       1         2     1.0\n",
      "6       2         6     1.0\n",
      "7       2         3     1.0\n",
      "9       3         7     1.0\n",
      "11      4         8     1.0\n",
      "12      4         5     1.0\n",
      "15      5         9     1.0\n",
      "16      5         6     1.0\n",
      "19      6        10     1.0\n",
      "20      6         7     1.0\n",
      "23      7        11     1.0\n",
      "25      8        12     1.0\n",
      "26      8         9     1.0\n",
      "29      9        13     1.0\n",
      "30      9        10     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "37     11        15     1.0\n",
      "39     12        13     1.0\n",
      "42     13        14     1.0\n",
      "45     14        15     1.0\n",
      "{4: 1.0, 1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "adj_list = w.to_adjlist(remove_symmetric=True) \n",
    "print(adj_list)\n",
    "print(w[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list we can validate neighbors. For example, in our 4x4 grid, we know that the upper-left hand corner of the grid (w[0]) only touches its right and bottom neighbor(remember: we are not using a queen contiguity in this example). Thus, the first weight object will capture these relationships and they will be reflected in the adj_list table (see row 1 [0 1 1.0] and 4 [4 0 1.0]). \n",
    "\n",
    "**However, the Local Join Count (LJC) statistics do not use the `remove_symmetric=True`.** This allows us to identify the specific join counts for each area $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "0       0         4     1.0\n",
      "1       0         1     1.0\n",
      "2       1         0     1.0\n",
      "3       1         5     1.0\n",
      "4       1         2     1.0\n",
      "5       2         1     1.0\n",
      "6       2         6     1.0\n",
      "7       2         3     1.0\n",
      "8       3         2     1.0\n",
      "9       3         7     1.0\n",
      "10      4         0     1.0\n",
      "11      4         8     1.0\n",
      "12      4         5     1.0\n",
      "13      5         1     1.0\n",
      "14      5         4     1.0\n",
      "15      5         9     1.0\n",
      "16      5         6     1.0\n",
      "17      6         2     1.0\n",
      "18      6         5     1.0\n",
      "19      6        10     1.0\n",
      "20      6         7     1.0\n",
      "21      7         3     1.0\n",
      "22      7         6     1.0\n",
      "23      7        11     1.0\n",
      "24      8         4     1.0\n",
      "25      8        12     1.0\n",
      "26      8         9     1.0\n",
      "27      9         5     1.0\n",
      "28      9         8     1.0\n",
      "29      9        13     1.0\n",
      "30      9        10     1.0\n",
      "31     10         6     1.0\n",
      "32     10         9     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "35     11         7     1.0\n",
      "36     11        10     1.0\n",
      "37     11        15     1.0\n",
      "38     12         8     1.0\n",
      "39     12        13     1.0\n",
      "40     13         9     1.0\n",
      "41     13        12     1.0\n",
      "42     13        14     1.0\n",
      "43     14        10     1.0\n",
      "44     14        13     1.0\n",
      "45     14        15     1.0\n",
      "46     15        11     1.0\n",
      "47     15        14     1.0\n"
     ]
    }
   ],
   "source": [
    "adj_list = w.to_adjlist(remove_symmetric=False) \n",
    "print(adj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now mirror the existing implementation of `Join_Counts` to create some objects that count the number of 1 value for the focal ($i$) and neighbor ($j$) cells. We do this for both the x, z, and y variables. **Note: perhaps an area for optimization?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "variables = [x,y,z]\n",
    "# The zseries\n",
    "zseries = [pd.Series(i, index=w.id_order) for i in variables]\n",
    "# The focal values\n",
    "focal = np.array([zseries[i].loc[adj_list.focal].values for i in range(len(variables))])\n",
    "# The neighbor values\n",
    "neighbor = np.array([zseries[i].loc[adj_list.neighbor].values for i in range(len(variables))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the results and manually validate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0     0\n",
      "1     0\n",
      "2     0\n",
      "3     0\n",
      "4     0\n",
      "5     0\n",
      "6     0\n",
      "7     0\n",
      "8     1\n",
      "9     1\n",
      "10    1\n",
      "11    1\n",
      "12    1\n",
      "13    1\n",
      "14    1\n",
      "15    1\n",
      "dtype: int32, 0     0\n",
      "1     1\n",
      "2     1\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     0\n",
      "9     0\n",
      "10    0\n",
      "11    1\n",
      "12    0\n",
      "13    0\n",
      "14    1\n",
      "15    1\n",
      "dtype: int32, 0     0\n",
      "1     1\n",
      "2     0\n",
      "3     1\n",
      "4     1\n",
      "5     1\n",
      "6     1\n",
      "7     1\n",
      "8     0\n",
      "9     0\n",
      "10    1\n",
      "11    1\n",
      "12    0\n",
      "13    0\n",
      "14    1\n",
      "15    1\n",
      "dtype: int32]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 1\n",
      "  1 1 0 0 0 0 0 1 1 1 1 1]\n",
      " [0 0 1 1 1 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 0 0 0 1 1 1 1 1\n",
      "  1 1 0 0 0 0 0 1 1 1 1 1]]\n",
      "[[0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 1 0 0 0 1 0 1 1 0 1 1 1 0 1 1 1 0\n",
      "  1 1 1 1 1 1 1 1 1 1 1 1]\n",
      " [1 1 0 1 1 1 1 1 1 1 0 0 1 1 1 0 1 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 1\n",
      "  0 1 0 0 0 0 1 0 0 1 1 1]\n",
      " [1 1 0 1 0 1 1 1 0 1 0 0 1 1 1 0 1 0 1 1 1 1 1 1 1 0 0 1 0 0 1 1 0 1 1 1\n",
      "  1 1 0 0 0 0 1 1 0 1 1 1]]\n"
     ]
    }
   ],
   "source": [
    "print(zseries)\n",
    "print(focal)\n",
    "print(neighbor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now comes the most important part, we need to expand the following function to as many variables are input. For former co-location cluster (CLC) now becomes the multivariate co-location cluster (MCLC):\n",
    "\n",
    "`MCLC = (focal_x == 1) & (focal_z == 1) & (focal_y == 1) & (neighbor_x == 1) & (neighbor_z == 1) & (neighbor_y == 1) & \n",
    "... (focal_m == 1) & (neighbor_m == 1)`\n",
    "\n",
    "From this point we need to do a bit of code golf. We have a list-of-lists and we need to check to make sure that the vlaues across all the lists have the value of interest (1). Thus, we can combine the `np.all()` function with an `np.dstack()==1` conditional function. This does scalable, row-wise evaluation to find rows where all are equal to True (i.e. all values equal 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False  True\n",
      "   True  True False False False False False  True  True  True  True  True]]\n",
      "[[False False False False False False False False False False False False\n",
      "  False False False False False False False False False False False  True\n",
      "  False False False False False False False False False  True  True False\n",
      "  False  True False False False False  True False False  True  True  True]]\n"
     ]
    }
   ],
   "source": [
    "focal_all = np.all(np.dstack(focal)==1, axis=2)\n",
    "neighbor_all = np.all(np.dstack(neighbor)==1, axis=2)\n",
    "print(focal_all)\n",
    "print(neighbor_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can return to the original implementation of `CLC` and identify those that are both 1..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 1, 1, 1])]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MCLC = (focal_all == True) & (neighbor_all == True)\n",
    "# Convert to boolean array\n",
    "MCLC = list(MCLC*1)\n",
    "MCLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "manual = pd.DataFrame(adj_list.focal.values, MCLC).reset_index()\n",
    "# Temporarily rename the columns\n",
    "manual.columns = ['MCLC', 'ID']\n",
    "manual = manual.groupby(by='ID').sum()\n",
    "manual.MCLC.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a visual comparison to the original table (remember, x values appear first and z values appear second):\n",
    "\n",
    "Original table\n",
    "\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0,0,0 | 0,1,1 | 0,0,1 | 0,1,1 |\n",
    "| 0,1,1 | 0,1,1 | 0,1,1 | 0,1,1 |\n",
    "| 1,0,0 | 1,0,0 | 1,1,0 | 1,1,1 |\n",
    "| 1,0,0 | 1,0,0 | 1,1,1 | 1,1,1 |\n",
    "\n",
    "\n",
    "Local Join Counts (multivariate)\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 1 |\n",
    "| 0 | 0 | 1 | 2 |\n",
    "\n",
    "This makes sense give our previously stated CLC conditions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Local_Join_Count_MV function <a name=\"LJC\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above manual calculations are implemented in the function called `Local_Join_Count_MV`. We run an ongoing notebook where the functions are being developed. Note that the below is likely to change over time. The following cell loads in the `Local_Join_Count_MV` function from the `migration.ipynb` (available on the [jeffcsauer/GSOC2020/scratch](https://github.com/jeffcsauer/GSOC2020/tree/master/scratch) github work journal. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pycodestyle_on"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator\n",
    "from libpysal import weights\n",
    "\n",
    "\n",
    "PERMUTATIONS = 999\n",
    "\n",
    "\n",
    "class Local_Join_Count_MV(BaseEstimator):\n",
    "\n",
    "    \"\"\"Multivariate Local Join Count Statistic\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None, permutations=PERMUTATIONS):\n",
    "        \"\"\"\n",
    "        Initialize a Local_Join_Count_MV estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity     : scipy.sparse matrix object\n",
    "                           the connectivity structure describing\n",
    "                           the relationships between observed units.\n",
    "                           Need not be row-standardized.\n",
    "        Attributes\n",
    "        ----------\n",
    "        LJC              : numpy.ndarray\n",
    "                           array containing the estimated\n",
    "                           Multivariate Local Join Counts\n",
    "        p_sim            : numpy.ndarray\n",
    "                           array containing the simulated p-values for each unit.\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "        self.permutations = permutations\n",
    "\n",
    "    def fit(self, variables, permutations=999):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        variables     : numpy.ndarray\n",
    "                        array(s) containing binary (0/1) data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`AnselinLi2019`.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> import libpysal\n",
    "        >>> w = libpysal.weights.lat2W(4, 4)\n",
    "        >>> x = np.ones(16)\n",
    "        >>> x[0:8] = 0\n",
    "        >>> z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "        >>> y = [0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1]\n",
    "        >>> LJC_MV = Local_Join_Count_MV(connectivity=w).fit([x, y, z])\n",
    "        >>> LJC_MV.LJC\n",
    "        >>> LJC_MV.p_sim\n",
    "\n",
    "        Guerry data extending GeoDa tutorial\n",
    "        >>> import libpysal\n",
    "        >>> import geopandas as gpd\n",
    "        >>> guerry = libpysal.examples.load_example('Guerry')\n",
    "        >>> guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))\n",
    "        >>> guerry_ds['infq5'] = 0\n",
    "        >>> guerry_ds['donq5'] = 0\n",
    "        >>> guerry_ds['suic5'] = 0\n",
    "        >>> guerry_ds.loc[(guerry_ds['Infants'] > 23574), 'infq5'] = 1\n",
    "        >>> guerry_ds.loc[(guerry_ds['Donatns'] > 10973), 'donq5'] = 1\n",
    "        >>> guerry_ds.loc[(guerry_ds['Suicids'] > 55564), 'suic5'] = 1\n",
    "        >>> w = libpysal.weights.Queen.from_dataframe(guerry_ds)\n",
    "        >>> LJC_MV = Local_Join_Count_MV(connectivity=w).fit([guerry_ds['infq5'], guerry_ds['donq5'], guerry_ds['suic5']])\n",
    "        >>> LJC_MV.LJC\n",
    "        >>> LJC_MV.p_sim\n",
    "        \"\"\"\n",
    "\n",
    "        w = self.connectivity\n",
    "        # Fill the diagonal with 0s\n",
    "        w = weights.util.fill_diagonal(w, val=0)\n",
    "        w.transform = 'b'\n",
    "\n",
    "        self.n = len(variables[0])\n",
    "        self.w = w\n",
    "\n",
    "        self.variables = variables\n",
    "\n",
    "        self.ext = np.prod(np.vstack(variables), axis=0)\n",
    "\n",
    "        self.LJC = self._statistic(variables, w)\n",
    "\n",
    "        if permutations:\n",
    "            self._crand()\n",
    "            sim = np.transpose(self.rjoins)\n",
    "            above = sim >= self.LJC\n",
    "            larger = above.sum(0)\n",
    "            low_extreme = (self.permutations - larger) < larger\n",
    "            larger[low_extreme] = self.permutations - larger[low_extreme]\n",
    "            self.p_sim = (larger + 1.0) / (permutations + 1.0)\n",
    "            # Set p-values for those with LJC of 0 to NaN\n",
    "            self.p_sim[self.LJC == 0] = 'NaN'\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(variables, w):\n",
    "        # Create adjacency list. Note that remove_symmetric=False -\n",
    "        # different from the esda.Join_Counts() function.\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "\n",
    "        # The zseries\n",
    "        zseries = [pd.Series(i, index=w.id_order) for i in variables]\n",
    "        # The focal values\n",
    "        focal = [zseries[i].loc[adj_list.focal].values for\n",
    "                 i in range(len(variables))]\n",
    "        # The neighbor values\n",
    "        neighbor = [zseries[i].loc[adj_list.neighbor].values for\n",
    "                    i in range(len(variables))]\n",
    "\n",
    "        # Find instances where all surrounding\n",
    "        # focal and neighbor values == 1\n",
    "        focal_all = np.array(np.all(np.dstack(focal) == 1,\n",
    "                                    axis=2))\n",
    "        neighbor_all = np.array(np.all(np.dstack(neighbor) == 1,\n",
    "                                       axis=2))\n",
    "        MCLC = (focal_all == True) & (neighbor_all == True)\n",
    "        # Convert list of True/False to boolean array \n",
    "        # and unlist (necessary for building pd.DF)\n",
    "        MCLC = list(MCLC*1)\n",
    "\n",
    "        # Create a df that uses the adjacency list\n",
    "        # focal values and the BBs counts\n",
    "        adj_list_MCLC = pd.DataFrame(adj_list.focal.values,\n",
    "                                     MCLC).reset_index()\n",
    "        # Temporarily rename the columns\n",
    "        adj_list_MCLC.columns = ['MCLC', 'ID']\n",
    "        adj_list_MCLC = adj_list_MCLC.groupby(by='ID').sum()\n",
    "\n",
    "        return (adj_list_MCLC.MCLC.values)\n",
    "\n",
    "    def _crand(self):\n",
    "        \"\"\"\n",
    "        conditional randomization\n",
    "\n",
    "        for observation i with ni neighbors,  the candidate set cannot include\n",
    "        i (we don't want i being a neighbor of i). we have to sample without\n",
    "        replacement from a set of ids that doesn't include i. numpy doesn't\n",
    "        directly support sampling wo replacement and it is expensive to\n",
    "        implement this. instead we omit i from the original ids,  permute the\n",
    "        ids and take the first ni elements of the permuted ids as the\n",
    "        neighbors to i in each randomization.\n",
    "\n",
    "        \"\"\"\n",
    "        # converted y to z\n",
    "        # renamed lisas to joins\n",
    "        ext = self.ext\n",
    "        # Get length based on first variable\n",
    "        n = len(ext)\n",
    "        joins = np.zeros((self.n, self.permutations))\n",
    "        n_1 = self.n - 1\n",
    "        prange = list(range(self.permutations))\n",
    "        k = self.w.max_neighbors + 1\n",
    "        nn = self.n - 1\n",
    "        rids = np.array([np.random.permutation(nn)[0:k] for i in prange])\n",
    "        ids = np.arange(self.w.n)\n",
    "        ido = self.w.id_order\n",
    "        w = [self.w.weights[ido[i]] for i in ids]\n",
    "        wc = [self.w.cardinalities[ido[i]] for i in ids]\n",
    "\n",
    "        for i in range(self.w.n):\n",
    "            idsi = ids[ids != i]\n",
    "            np.random.shuffle(idsi)\n",
    "            # Mirroring moran_local_bv()\n",
    "            tmp = ext[idsi[rids[:, 0:wc[i]]]]\n",
    "            joins[i] = ext[i] * (w[i] * tmp).sum(1)\n",
    "        self.rjoins = joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Local_Join_Count_MV function on the 'toy' dataset <a name=\"LJCToy\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2], dtype=int64)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Recreate inputs and weights (otherwise they are altered when running notebook)\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "y_1 = np.ones(16)\n",
    "# Set the first 9 of the ones to 0\n",
    "y_1[0:8] = 0\n",
    "# Set x equal to y_1\n",
    "x = y_1\n",
    "x = x.astype(np.int32)\n",
    "# Create another random sequences of 0 and 1\n",
    "z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "y = [0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1]\n",
    "# Run function\n",
    "toy_results = Local_Join_Count_MV(connectivity=w).fit([x, y, z])\n",
    "toy_results.LJC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare output of `Local_Join_Count` function to the manually-calculated `LJC` from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of toy function to manual values\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison of toy function to manual values\")\n",
    "print(toy_results.LJC == manual.MCLC.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All values match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan,   nan, 0.342,   nan,   nan, 0.386, 0.011])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_results.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Local_Join_Count_BV function on 'real world' datasets <a name=\"LJCRealWorld\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would look to compare the output to the values from the original Anselin and Li 2019 paper. However, the example use cases in Anselin and Li 2019 do not provide full tables of LJC and associate p-values to confirm equivalency. Thus, we compare the results from the PySAL implementation of `Local_Join_Counts_MV` to the output from GeoDa using a GeoDa example dataset. Specifically, we use the [Baltimore Housing Sales dataset](https://geodacenter.github.io/data-and-lab/baltim/) and focus on the 'dwell', 'patio', and 'firepl' binary variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to GeoDa output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load in the Baltimore Housing Sales dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>price</th>\n",
       "      <th>nroom</th>\n",
       "      <th>dwell</th>\n",
       "      <th>nbath</th>\n",
       "      <th>patio</th>\n",
       "      <th>firepl</th>\n",
       "      <th>ac</th>\n",
       "      <th>bment</th>\n",
       "      <th>nstor</th>\n",
       "      <th>gar</th>\n",
       "      <th>age</th>\n",
       "      <th>citcou</th>\n",
       "      <th>lotsz</th>\n",
       "      <th>sqft</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>11.25</td>\n",
       "      <td>907.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>POINT (907.000 534.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>279.51</td>\n",
       "      <td>28.92</td>\n",
       "      <td>922.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>POINT (922.000 574.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.64</td>\n",
       "      <td>30.62</td>\n",
       "      <td>920.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>POINT (920.000 581.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>104.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>174.63</td>\n",
       "      <td>26.12</td>\n",
       "      <td>923.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>POINT (923.000 578.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.80</td>\n",
       "      <td>22.04</td>\n",
       "      <td>918.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>POINT (918.000 574.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station  price  nroom  dwell  nbath  patio  firepl   ac  bment  nstor  gar  \\\n",
       "0      1.0   47.0    4.0    0.0    1.0    0.0     0.0  0.0    2.0    3.0  0.0   \n",
       "1      2.0  113.0    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  2.0   \n",
       "2      3.0  165.0    7.0    1.0    2.5    1.0     1.0  0.0    3.0    2.0  2.0   \n",
       "3      4.0  104.3    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  2.0   \n",
       "4      5.0   62.5    7.0    1.0    1.5    1.0     1.0  0.0    2.0    2.0  0.0   \n",
       "\n",
       "     age  citcou   lotsz   sqft      x      y                 geometry  \n",
       "0  148.0     0.0    5.70  11.25  907.0  534.0  POINT (907.000 534.000)  \n",
       "1    9.0     1.0  279.51  28.92  922.0  574.0  POINT (922.000 574.000)  \n",
       "2   23.0     1.0   70.64  30.62  920.0  581.0  POINT (920.000 581.000)  \n",
       "3    5.0     1.0  174.63  26.12  923.0  578.0  POINT (923.000 578.000)  \n",
       "4   19.0     1.0  107.80  22.04  918.0  574.0  POINT (918.000 574.000)  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "balt = gpd.read_file('https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/baltimore/baltimore_housing.gpkg')\n",
    "balt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate the variable of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_balt = balt['dwell']\n",
    "z_balt = balt['patio']\n",
    "y_balt = balt['firepl']\n",
    "\n",
    "x_balt = np.asarray(x_balt).flatten()\n",
    "z_balt = np.asarray(z_balt).flatten()\n",
    "y_balt = np.asarray(y_balt).flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with points in PySAL we need to arrange them into a tree-able list of x and y points. Thus we extract the x and y columns of the baltimore dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = list(zip(balt['x'], balt['y']))\n",
    "import libpysal\n",
    "kd = libpysal.cg.KDTree(np.array(points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to recreate the weights used in the GeoDa analysis. The weight scheme used was a k-nearest neighbor (knn) approach, using 5 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "balt_knn5 = libpysal.weights.KNN(kd, k=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply our PySAL `Local_Join_Count_MV` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 4, 5, 5, 3, 1, 4, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results = Local_Join_Count_MV(connectivity=balt_knn5).fit([x_balt, z_balt, y_balt])\n",
    "test_results.LJC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27.2 ms ± 263 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit Local_Join_Count_MV(connectivity=balt_knn5).fit([x_balt, z_balt, y_balt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in the results from GeoDa analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>price</th>\n",
       "      <th>nroom</th>\n",
       "      <th>dwell</th>\n",
       "      <th>nbath</th>\n",
       "      <th>patio</th>\n",
       "      <th>firepl</th>\n",
       "      <th>ac</th>\n",
       "      <th>bment</th>\n",
       "      <th>nstor</th>\n",
       "      <th>gar</th>\n",
       "      <th>age</th>\n",
       "      <th>citcou</th>\n",
       "      <th>lotsz</th>\n",
       "      <th>sqft</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>MV_JC</th>\n",
       "      <th>MV_NN</th>\n",
       "      <th>MV_PP_VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>11.25</td>\n",
       "      <td>907.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>113.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>279.51</td>\n",
       "      <td>28.92</td>\n",
       "      <td>922.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>165.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.64</td>\n",
       "      <td>30.62</td>\n",
       "      <td>920.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>104.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>174.63</td>\n",
       "      <td>26.12</td>\n",
       "      <td>923.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.80</td>\n",
       "      <td>22.04</td>\n",
       "      <td>918.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>70.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>139.64</td>\n",
       "      <td>39.42</td>\n",
       "      <td>900.0</td>\n",
       "      <td>577.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>127.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>250.00</td>\n",
       "      <td>21.88</td>\n",
       "      <td>918.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>53.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>100.00</td>\n",
       "      <td>36.72</td>\n",
       "      <td>907.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>64.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>115.90</td>\n",
       "      <td>25.60</td>\n",
       "      <td>918.0</td>\n",
       "      <td>562.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>145.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>365.07</td>\n",
       "      <td>44.12</td>\n",
       "      <td>897.0</td>\n",
       "      <td>576.0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.274</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station  price  nroom  dwell  nbath  patio  firepl   ac  bment  nstor  gar  \\\n",
       "0        1   47.0    4.0    0.0    1.0    0.0     0.0  0.0    2.0    3.0  0.0   \n",
       "1        2  113.0    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  2.0   \n",
       "2        3  165.0    7.0    1.0    2.5    1.0     1.0  0.0    3.0    2.0  2.0   \n",
       "3        4  104.3    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  2.0   \n",
       "4        5   62.5    7.0    1.0    1.5    1.0     1.0  0.0    2.0    2.0  0.0   \n",
       "5        6   70.0    6.0    1.0    2.5    1.0     1.0  0.0    3.0    3.0  1.0   \n",
       "6        7  127.5    6.0    1.0    2.5    1.0     1.0  1.0    3.0    1.0  2.0   \n",
       "7        8   53.0    8.0    1.0    1.5    1.0     0.0  0.0    0.0    3.0  0.0   \n",
       "8        9   64.5    6.0    1.0    1.0    1.0     1.0  1.0    3.0    2.0  0.0   \n",
       "9       10  145.0    7.0    1.0    2.5    1.0     1.0  1.0    3.0    2.0  2.0   \n",
       "\n",
       "     age  citcou   lotsz   sqft      x      y  MV_JC  MV_NN  MV_PP_VAL  \n",
       "0  148.0     0.0    5.70  11.25  907.0  534.0      0      5        NaN  \n",
       "1    9.0     1.0  279.51  28.92  922.0  574.0      4      5      0.001  \n",
       "2   23.0     1.0   70.64  30.62  920.0  581.0      5      5      0.001  \n",
       "3    5.0     1.0  174.63  26.12  923.0  578.0      5      5      0.001  \n",
       "4   19.0     1.0  107.80  22.04  918.0  574.0      3      5      0.007  \n",
       "5   20.0     1.0  139.64  39.42  900.0  577.0      1      5      0.274  \n",
       "6   20.0     1.0  250.00  21.88  918.0  576.0      4      5      0.001  \n",
       "7   22.0     1.0  100.00  36.72  907.0  576.0      0      5        NaN  \n",
       "8   22.0     1.0  115.90  25.60  918.0  562.0      0      5        NaN  \n",
       "9    4.0     1.0  365.07  44.12  897.0  576.0      1      5      0.274  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load GeoDa analysis results\n",
    "GeoDa_LJC = pd.read_csv('https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/baltimore/balt_knn_5_LJC_multivariate.csv')\n",
    "GeoDa_LJC.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the PySAL LJC results to to the GeoDa LJC results. Due to the somewhat high (n=211) number of comparisons, we will tabulate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of GeoDa multivariate LJC to PySAL implementation:\n",
      "True    211\n",
      "Name: MV_JC, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison of GeoDa multivariate LJC to PySAL implementation:\")\n",
    "results = test_results.LJC == GeoDa_LJC['MV_JC']\n",
    "print(results.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 211 elements have the same multivariate LJC between the PySAL implementation and the GeoDa results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing p-values at surface level..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan, 0.001, 0.001, 0.001, 0.002, 0.275, 0.001,   nan,   nan,\n",
       "       0.282])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.p_sim[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan, 0.001, 0.001, 0.001, 0.007, 0.274, 0.001,   nan,   nan,\n",
       "       0.274])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(GeoDa_LJC.MV_PP_VAL[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences in p-values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   nan,  0.   ,  0.   ,  0.   , -0.005,  0.001,  0.   ,    nan,\n",
       "          nan,  0.008])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results.p_sim[0:10] - np.array(GeoDa_LJC.MV_PP_VAL[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between the two sets of p-values is 0.9995805497108962\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='pysal', ylabel='geoda'>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assess correlation between p-values\n",
    "corrdf = pd.DataFrame(test_results.p_sim, GeoDa_LJC.MV_PP_VAL).reset_index()\n",
    "corrdf.columns = ['pysal', 'geoda']\n",
    "print(\"The correlation between the two sets of p-values is\", corrdf['pysal'].corr(corrdf['geoda']))\n",
    "\n",
    "corrdf.plot.scatter(x='pysal',\n",
    "                    y='geoda',\n",
    "                    c='DarkBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "- Ensure docstrings include all relevant information and formatting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Quick comparison to [GeoDa Guerry Example](https://geodacenter.github.io/workbook/6b_local_adv/lab6b.html#bivariate-and-multivariate---co-location)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>POLY_ID</th>\n",
       "      <th>CODE_DE</th>\n",
       "      <th>COUNT</th>\n",
       "      <th>AVE_ID_</th>\n",
       "      <th>dept</th>\n",
       "      <th>Region</th>\n",
       "      <th>Dprtmnt</th>\n",
       "      <th>Crm_prs</th>\n",
       "      <th>Crm_prp</th>\n",
       "      <th>Litercy</th>\n",
       "      <th>...</th>\n",
       "      <th>Distanc</th>\n",
       "      <th>Area</th>\n",
       "      <th>Pop1831</th>\n",
       "      <th>INF</th>\n",
       "      <th>DON</th>\n",
       "      <th>SELECTED</th>\n",
       "      <th>JC_MV</th>\n",
       "      <th>NN_MV</th>\n",
       "      <th>PP_VAL_MV</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>1</td>\n",
       "      <td>E</td>\n",
       "      <td>Ain</td>\n",
       "      <td>28870</td>\n",
       "      <td>15890</td>\n",
       "      <td>37</td>\n",
       "      <td>...</td>\n",
       "      <td>218.372</td>\n",
       "      <td>5762</td>\n",
       "      <td>346.03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((801150.000 2092615.000, 800669...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>02</td>\n",
       "      <td>1.0</td>\n",
       "      <td>812.0</td>\n",
       "      <td>2</td>\n",
       "      <td>N</td>\n",
       "      <td>Aisne</td>\n",
       "      <td>26226</td>\n",
       "      <td>5521</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>65.945</td>\n",
       "      <td>7369</td>\n",
       "      <td>513.00</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((729326.000 2521619.000, 729320...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>03</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1418.0</td>\n",
       "      <td>3</td>\n",
       "      <td>C</td>\n",
       "      <td>Allier</td>\n",
       "      <td>26747</td>\n",
       "      <td>7925</td>\n",
       "      <td>13</td>\n",
       "      <td>...</td>\n",
       "      <td>161.927</td>\n",
       "      <td>7340</td>\n",
       "      <td>298.26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((710830.000 2137350.000, 711746...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>04</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1603.0</td>\n",
       "      <td>4</td>\n",
       "      <td>E</td>\n",
       "      <td>Basses-Alpes</td>\n",
       "      <td>12935</td>\n",
       "      <td>7289</td>\n",
       "      <td>46</td>\n",
       "      <td>...</td>\n",
       "      <td>351.399</td>\n",
       "      <td>6925</td>\n",
       "      <td>155.90</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((882701.000 1920024.000, 882408...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>05</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1802.0</td>\n",
       "      <td>5</td>\n",
       "      <td>E</td>\n",
       "      <td>Hautes-Alpes</td>\n",
       "      <td>17488</td>\n",
       "      <td>8174</td>\n",
       "      <td>69</td>\n",
       "      <td>...</td>\n",
       "      <td>320.280</td>\n",
       "      <td>5549</td>\n",
       "      <td>129.10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>MULTIPOLYGON (((886504.000 1922890.000, 885733...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   POLY_ID CODE_DE  COUNT  AVE_ID_  dept Region       Dprtmnt  Crm_prs  \\\n",
       "0        1      01    1.0     49.0     1      E           Ain    28870   \n",
       "1        2      02    1.0    812.0     2      N         Aisne    26226   \n",
       "2        3      03    1.0   1418.0     3      C        Allier    26747   \n",
       "3        4      04    1.0   1603.0     4      E  Basses-Alpes    12935   \n",
       "4        5      05    1.0   1802.0     5      E  Hautes-Alpes    17488   \n",
       "\n",
       "   Crm_prp  Litercy  ...  Distanc  Area  Pop1831  INF  DON  SELECTED  JC_MV  \\\n",
       "0    15890       37  ...  218.372  5762   346.03    1    0         0      0   \n",
       "1     5521       51  ...   65.945  7369   513.00    0    0         0      0   \n",
       "2     7925       13  ...  161.927  7340   298.26    0    1         0      0   \n",
       "3     7289       46  ...  351.399  6925   155.90    0    0         0      0   \n",
       "4     8174       69  ...  320.280  5549   129.10    0    0         0      0   \n",
       "\n",
       "   NN_MV  PP_VAL_MV                                           geometry  \n",
       "0      4        NaN  MULTIPOLYGON (((801150.000 2092615.000, 800669...  \n",
       "1      6        NaN  MULTIPOLYGON (((729326.000 2521619.000, 729320...  \n",
       "2      6        NaN  MULTIPOLYGON (((710830.000 2137350.000, 711746...  \n",
       "3      4        NaN  MULTIPOLYGON (((882701.000 1920024.000, 882408...  \n",
       "4      3        NaN  MULTIPOLYGON (((886504.000 1922890.000, 885733...  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "guerry = gpd.read_file('D:/Dropbox/GSOC2020/validation/data/guerry/guerry_geodavalues.gpkg')\n",
    "guerry.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guerry.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from libpysal.weights import Queen\n",
    "guerry_wq = Queen.from_dataframe(guerry)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pass through function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guerry_results = Local_Join_Count_MV(connectivity=guerry_wq).fit([guerry['INF'], guerry['DON']])\n",
    "guerry_results.LJC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit Local_Join_Count_MV(connectivity=guerry_wq).fit([guerry['INF'], guerry['DON']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparison of GeoDa multivariate LJC to PySAL implementation for Guerry dataset:\")\n",
    "results = guerry_results.LJC == guerry['JC_MV']\n",
    "print(results.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess correlation between p-values\n",
    "corrdf = pd.DataFrame(guerry_results.p_sim, guerry.PP_VAL_MV).reset_index()\n",
    "corrdf.columns = ['pysal', 'geoda']\n",
    "print(\"The correlation between the two sets of p-values is\", corrdf['pysal'].corr(corrdf['geoda']))\n",
    "\n",
    "corrdf.plot.scatter(x='pysal',\n",
    "                    y='geoda',\n",
    "                    c='DarkBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Matching the GeoDa MV guerry example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning out some `unittest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based off: https://github.com/pysal/esda/blob/master/tests/test_join_counts.py\n",
    "import unittest\n",
    "import numpy as np\n",
    "from libpysal.weights.util import lat2W\n",
    "from libpysal.common import pandas\n",
    "\n",
    "PANDAS_EXTINCT = pandas is None\n",
    "\n",
    "class Local_Join_Counts_MV_Tester(unittest.TestCase):\n",
    "    \"\"\"Unit test for Local Join Counts (univariate)\"\"\"\n",
    "    def setUp(self):\n",
    "        self.w = lat2W(4, 4)\n",
    "        self.x = np.ones(16)\n",
    "        self.x[0:8] = 0\n",
    "        self.y = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "        self.z = [0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1]\n",
    "\n",
    "\n",
    "    def test_Local_Join_Counts_MV(self):\n",
    "            \"\"\"Test method\"\"\"\n",
    "            np.random.seed(12345)\n",
    "            ljc_mv = Local_Join_Count_MV(connectivity=self.w).fit([self.x, self.y, self.z])\n",
    "            self.assertAlmostEqual(ljc_mv.LJC, [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# To-do\n",
    "\n",
    "- convert to numba (below)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator\n",
    "from libpysal import weights\n",
    "from esda.crand import (\n",
    "    crand as _crand_plus,\n",
    "    njit as _njit,\n",
    "    _prepare_univariate\n",
    ")\n",
    "\n",
    "\n",
    "PERMUTATIONS = 999\n",
    "\n",
    "\n",
    "class Local_Join_Count_MV(BaseEstimator):\n",
    "\n",
    "    \"\"\"Multivariate Local Join Count Statistic\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None, permutations=PERMUTATIONS, n_jobs=1, \n",
    "                 keep_simulations=True, seed=None):\n",
    "        \"\"\"\n",
    "        Initialize a Local_Join_Count_MV estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity     : scipy.sparse matrix object\n",
    "                           the connectivity structure describing\n",
    "                           the relationships between observed units.\n",
    "                           Need not be row-standardized.\n",
    "        permutations     : int\n",
    "                           number of random permutations for calculation of pseudo\n",
    "                           p_values\n",
    "        n_jobs           : int\n",
    "                           Number of cores to be used in the conditional randomisation. If -1,\n",
    "                           all available cores are used.    \n",
    "        keep_simulations : Boolean\n",
    "                           (default=True)\n",
    "                           If True, the entire matrix of replications under the null \n",
    "                           is stored in memory and accessible; otherwise, replications \n",
    "                           are not saved\n",
    "        seed             : None/int\n",
    "                           Seed to ensure reproducibility of conditional randomizations. \n",
    "                           Must be set here, and not outside of the function, since numba \n",
    "                           does not correctly interpret external seeds \n",
    "                           nor numpy.random.RandomState instances.              \n",
    "                           \n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "        self.permutations = permutations\n",
    "        self.n_jobs = n_jobs\n",
    "        self.keep_simulations = keep_simulations\n",
    "        self.seed = seed\n",
    "\n",
    "    def fit(self, variables, n_jobs=1, permutations=999):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        variables     : numpy.ndarray\n",
    "                        array(s) containing binary (0/1) data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`AnselinLi2019`.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> import libpysal\n",
    "        >>> w = libpysal.weights.lat2W(4, 4)\n",
    "        >>> x = np.ones(16)\n",
    "        >>> x[0:8] = 0\n",
    "        >>> z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "        >>> y = [0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1]\n",
    "        >>> LJC_MV = Local_Join_Count_MV(connectivity=w).fit([x, y, z])\n",
    "        >>> LJC_MV.LJC\n",
    "        >>> LJC_MV.p_sim\n",
    "\n",
    "        Guerry data extending GeoDa tutorial\n",
    "        >>> import libpysal\n",
    "        >>> import geopandas as gpd\n",
    "        >>> guerry = libpysal.examples.load_example('Guerry')\n",
    "        >>> guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))\n",
    "        >>> guerry_ds['infq5'] = 0\n",
    "        >>> guerry_ds['donq5'] = 0\n",
    "        >>> guerry_ds['suic5'] = 0\n",
    "        >>> guerry_ds.loc[(guerry_ds['Infants'] > 23574), 'infq5'] = 1\n",
    "        >>> guerry_ds.loc[(guerry_ds['Donatns'] > 10973), 'donq5'] = 1\n",
    "        >>> guerry_ds.loc[(guerry_ds['Suicids'] > 55564), 'suic5'] = 1\n",
    "        >>> w = libpysal.weights.Queen.from_dataframe(guerry_ds)\n",
    "        >>> LJC_MV = Local_Join_Count_MV(connectivity=w).fit([guerry_ds['infq5'], guerry_ds['donq5'], guerry_ds['suic5']])\n",
    "        >>> LJC_MV.LJC\n",
    "        >>> LJC_MV.p_sim\n",
    "        \"\"\"\n",
    "\n",
    "        w = self.connectivity\n",
    "        # Fill the diagonal with 0s\n",
    "        w = weights.util.fill_diagonal(w, val=0)\n",
    "        w.transform = 'b'\n",
    "\n",
    "        self.n = len(variables[0])\n",
    "        self.w = w\n",
    "\n",
    "        self.variables = np.array(variables, dtype='float')\n",
    "        \n",
    "        keep_simulations = self.keep_simulations\n",
    "        n_jobs = self.n_jobs\n",
    "        seed = self.seed\n",
    "\n",
    "        # Need to ensure that the product is an \n",
    "        # np.array() of dtype='float' for numba\n",
    "        self.ext = np.array(np.prod(np.vstack(variables), axis=0), \n",
    "                            dtype='float')\n",
    "\n",
    "        self.LJC = self._statistic(variables, w)\n",
    "\n",
    "        if permutations:\n",
    "            self.p_sim, self.rjoins = _crand_plus(\n",
    "                z=self.ext, \n",
    "                w=self.w, \n",
    "                observed=self.LJC,\n",
    "                permutations=permutations, \n",
    "                keep=True, \n",
    "                n_jobs=n_jobs,\n",
    "                stat_func=_ljc_mv\n",
    "            )\n",
    "            # Set p-values for those with LJC of 0 to NaN\n",
    "            self.p_sim[self.LJC == 0] = 'NaN'\n",
    "        \n",
    "        del (self.n, self.keep_simulations, self.n_jobs, \n",
    "             self.permutations, self.seed, self.w, self.ext,\n",
    "             self.variables, self.connectivity, self.rjoins)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(variables, w):\n",
    "        # Create adjacency list. Note that remove_symmetric=False -\n",
    "        # different from the esda.Join_Counts() function.\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "\n",
    "        # The zseries\n",
    "        zseries = [pd.Series(i, index=w.id_order) for i in variables]\n",
    "        # The focal values\n",
    "        focal = [zseries[i].loc[adj_list.focal].values for\n",
    "                 i in range(len(variables))]\n",
    "        # The neighbor values\n",
    "        neighbor = [zseries[i].loc[adj_list.neighbor].values for\n",
    "                    i in range(len(variables))]\n",
    "\n",
    "        # Find instances where all surrounding\n",
    "        # focal and neighbor values == 1\n",
    "        focal_all = np.array(np.all(np.dstack(focal) == 1,\n",
    "                                    axis=2))\n",
    "        neighbor_all = np.array(np.all(np.dstack(neighbor) == 1,\n",
    "                                       axis=2))\n",
    "        MCLC = (focal_all == True) & (neighbor_all == True)\n",
    "        # Convert list of True/False to boolean array \n",
    "        # and unlist (necessary for building pd.DF)\n",
    "        MCLC = list(MCLC*1)\n",
    "\n",
    "        # Create a df that uses the adjacency list\n",
    "        # focal values and the BBs counts\n",
    "        adj_list_MCLC = pd.DataFrame(adj_list.focal.values,\n",
    "                                     MCLC).reset_index()\n",
    "        # Temporarily rename the columns\n",
    "        adj_list_MCLC.columns = ['MCLC', 'ID']\n",
    "        adj_list_MCLC = adj_list_MCLC.groupby(by='ID').sum()\n",
    "\n",
    "        return (np.array(adj_list_MCLC.MCLC.values, dtype='float'))\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Conditional Randomization Function Implementations\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Note: scaling not used\n",
    "\n",
    "@_njit(fastmath=True)\n",
    "def _ljc_mv(i, z, permuted_ids, weights_i, scaling):\n",
    "    zi, zrand = _prepare_univariate(i, z, permuted_ids, weights_i)\n",
    "    return zi * (zrand @ weights_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "x = np.ones(16)\n",
    "x[0:8] = 0\n",
    "z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "y = [0,1,1,1,1,1,1,1,0,0,0,1,0,0,1,1]\n",
    "LJC_MV = Local_Join_Count_MV(connectivity=w).fit([x, y, z])\n",
    "LJC_MV.LJC\n",
    "LJC_MV.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correct values: \n",
    "#array([  nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
    "#         nan,   nan, 0.369,   nan,   nan, 0.363, 0.007])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esda.crand import crand as _crand_plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@_njit(fastmath=True)\n",
    "def _ljc_uni(i, z, permuted_ids, weights_i, scaling):\n",
    "    zi, zrand = _prepare_univariate(i, z, permuted_ids, weights_i)\n",
    "    return zi * (zrand @ weights_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(x.dtype)\n",
    "print(guerry_results.LJC.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sim, rjoins = _crand_plus(z=x, w=guerry_wq, observed=guerry_results.LJC, \n",
    "            permutations=999, keep=True, n_jobs=1, \n",
    "            stat_func=_ljc_uni)\n",
    "print(p_sim)\n",
    "print(rjoins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Apply numba-ized function to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "guerry_results_v2 = Local_Join_Count_MV(connectivity=guerry_wq).fit([guerry['INF'], guerry['DON']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit Local_Join_Count_MV(connectivity=guerry_wq).fit([guerry['INF'], guerry['DON']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((32.1 - 19.4)/32.1)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 40% increase in speed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess correlation between p-values\n",
    "corrdf = pd.DataFrame(guerry_results_v2.p_sim, guerry.PP_VAL_MV).reset_index()\n",
    "corrdf.columns = ['pysal', 'geoda']\n",
    "print(\"The correlation between the two sets of p-values is\", corrdf['pysal'].corr(corrdf['geoda']))\n",
    "\n",
    "corrdf.plot.scatter(x='pysal',\n",
    "                    y='geoda',\n",
    "                    c='DarkBlue')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
