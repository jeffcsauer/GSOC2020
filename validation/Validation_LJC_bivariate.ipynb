{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This is the validation notebook for the PySAL implementation of the local join count (LJC) bivariate statistic. This notebook will begin with a brief review of the bivariate LJC and a manual calculation of the values on a 'toy' dataset. We will then introduce the PySAL implementation of the `Local_Join_Count_BV` function. Output from the `Local_Join_Count_BV` function will be compared to the results from the manual calculation on the 'toy' dataset. Following the 'toy' dataset will be a comparison of the PySAL `Local_Join_Count_BV` function to the external `GeoDa` results on an external dataset. As of now, calculations of inference are not included in the function.\n",
    "\n",
    "1. [Review of the bivariate LJC statistic](#Review)\n",
    "2. [Manual calculations on a 'toy' dataset](#Toy)\n",
    "3. [Implementation of Local_Join_Count_BV function](#LJC)\n",
    "4. [Application of Local_Join_Count_BV function on the 'toy' dataset](#LJCToy)\n",
    "5. [Application of Local_Join_Count_BV function on 'real world' datasets](#LJCRealWorld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of the bivariate LJC statistic <a name=\"Review\"></a>\n",
    "\n",
    "To review, global join counts focus on the total number of adjacent counts of certain values across the entire study area.  This is represented as $BB$:\n",
    "\n",
    "$$BB = \\sum_{i} \\sum_j w_{ij} x_{i} x_{j}$$\n",
    "\n",
    "Of particular interest to us are the number of local black-black (1-1) join counts. This is represented as $BB_i$: \n",
    "\n",
    "$$ BB_i = x_i \\sum_{j} w_{ij} x_j$$\n",
    "\n",
    "...where a count of the neighbors with an observation of $x_j=1$ for those locations where $x_i=1$. This focuses on the BB counts of a given polygon (x_i).\n",
    "\n",
    "When considering two variables, we extend the above equation to: \n",
    "\n",
    "$$ BJC = x_i (1 - z_i) \\sum_{j} w_{ij} z_j (1-x_j)$$\n",
    "\n",
    "Note that although x and z can be reserved, the statistic is not symmetric. Results may be different whether x or z is in focus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual calculations on a 'toy' dataset <a name=\"Toy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a small 'toy' dataset to illustrate the local join counts. This toy dataset is a 4x4 lattice grid filled with 0s and 1s for each of the x and z binary variables. Note that for a given cell, the value of the x variable comes first and the value of the z variable comes second. \n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0,0 | 0,1 | 0,0 | 0,1 |\n",
    "| 0,1 | 0,1 | 0,1 | 0,1 |\n",
    "| 1,0 | 1,0 | 1,1 | 1,1 |\n",
    "| 1,0 | 1,0 | 1,1 | 1,1 |\n",
    "\n",
    "The arrangement of the above grid is captured in the `x` and `z` objects below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "z [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import libpysal\n",
    "import pandas as pd\n",
    "\n",
    "# Create a 16x16 grid\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "y_1 = np.ones(16)\n",
    "# Set the first 9 of the ones to 0\n",
    "y_1[0:8] = 0\n",
    "# Set x equal to y_1\n",
    "x = y_1\n",
    "# Create another random sequence of 0 and 1\n",
    "z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "\n",
    "print('x', x)\n",
    "print('z', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given cell of the above table, we are interest in the adjacent grid cells that are equal to 1. We can find these through the use of **binary weights**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the input vector y\n",
    "x = np.asarray(x).flatten()\n",
    "z = np.asarray(z).flatten()\n",
    "print(x)\n",
    "print(z)\n",
    "# ensure weights are binary transformed\n",
    "w.transformation = 'b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does PySAL identify these cells? Through an adjacency list. This creates a list object of unique focal ($i$) and neighbor ($j$) pairs. The `remove_symmetric=True` ensure that there are not duplicated (but reversed) adjacency pairs. This is a great shortcut when calculating global join counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "1       0         1     1.0\n",
      "3       1         5     1.0\n",
      "5       2         1     1.0\n",
      "7       2         3     1.0\n",
      "10      4         0     1.0\n",
      "12      4         5     1.0\n",
      "16      5         6     1.0\n",
      "17      6         2     1.0\n",
      "21      7         3     1.0\n",
      "22      7         6     1.0\n",
      "23      7        11     1.0\n",
      "24      8         4     1.0\n",
      "25      8        12     1.0\n",
      "27      9         5     1.0\n",
      "28      9         8     1.0\n",
      "31     10         6     1.0\n",
      "32     10         9     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "37     11        15     1.0\n",
      "39     12        13     1.0\n",
      "40     13         9     1.0\n",
      "44     14        13     1.0\n",
      "45     14        15     1.0\n",
      "{4: 1.0, 1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "adj_list = w.to_adjlist(remove_symmetric=True) \n",
    "print(adj_list)\n",
    "print(w[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list we can validate neighbors. For example, in our 4x4 grid, we know that the upper-left hand corner of the grid (w[0]) only touches its right and bottom neighbor(remember: we are not using a queen contiguity in this example). Thus, the first weight object will capture these relationships and they will be reflected in the adj_list table (see row 1 [0 1 1.0] and 4 [4 0 1.0]). \n",
    "\n",
    "**However, in the Local Join Count (LJC) statisticsnot use the `remove_symmetric=True`.** This allows us to identify the specific join counts for each area $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "0       0         4     1.0\n",
      "1       0         1     1.0\n",
      "2       1         0     1.0\n",
      "3       1         5     1.0\n",
      "4       1         2     1.0\n",
      "5       2         1     1.0\n",
      "6       2         6     1.0\n",
      "7       2         3     1.0\n",
      "8       3         2     1.0\n",
      "9       3         7     1.0\n",
      "10      4         0     1.0\n",
      "11      4         8     1.0\n",
      "12      4         5     1.0\n",
      "13      5         1     1.0\n",
      "14      5         4     1.0\n",
      "15      5         9     1.0\n",
      "16      5         6     1.0\n",
      "17      6         2     1.0\n",
      "18      6         5     1.0\n",
      "19      6        10     1.0\n",
      "20      6         7     1.0\n",
      "21      7         3     1.0\n",
      "22      7         6     1.0\n",
      "23      7        11     1.0\n",
      "24      8         4     1.0\n",
      "25      8        12     1.0\n",
      "26      8         9     1.0\n",
      "27      9         5     1.0\n",
      "28      9         8     1.0\n",
      "29      9        13     1.0\n",
      "30      9        10     1.0\n",
      "31     10         6     1.0\n",
      "32     10         9     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "35     11         7     1.0\n",
      "36     11        10     1.0\n",
      "37     11        15     1.0\n",
      "38     12         8     1.0\n",
      "39     12        13     1.0\n",
      "40     13         9     1.0\n",
      "41     13        12     1.0\n",
      "42     13        14     1.0\n",
      "43     14        10     1.0\n",
      "44     14        13     1.0\n",
      "45     14        15     1.0\n",
      "46     15        11     1.0\n",
      "47     15        14     1.0\n"
     ]
    }
   ],
   "source": [
    "adj_list = w.to_adjlist(remove_symmetric=False) \n",
    "print(adj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now mirror the existing implementation of `Join_Counts` to create some objects that count the number of 1 value for the focal ($i$) and neighbor ($j$) cells. We do this for both the x and z variables. **Note: perhaps an area for optimization?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, set up a series that maps the y values (input as self.y) to the weights table \n",
    "zseries_x = pd.Series(x, index=w.id_order)\n",
    "zseries_z = pd.Series(z, index=w.id_order)\n",
    "\n",
    "# Next, map the y values to the focal (i) values \n",
    "focal_x = zseries_x.loc[adj_list.focal].values\n",
    "focal_z = zseries_z.loc[adj_list.focal].values\n",
    "\n",
    "# Repeat the mapping but for the neighbor (j) values\n",
    "neighbor_x = zseries_x.loc[adj_list.neighbor].values\n",
    "neighbor_z = zseries_z.loc[adj_list.neighbor].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: No co-location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the bivariate join count there are two situations (no co-location, and co-location). We first compute case 1 (no co-location)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BJC = (focal_x == 1) & (focal_z == 0) & (neighbor_x == 0) & (neighbor_z == 1)\n",
    "BJC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to map these values to the adjacency list. By grouping by the 'ID\" column of the adjacnecy list, we can get the sum of agreements where focal x and neighbor z have the same 1 value (while ensuring that the focal z and neighbor x have a value of 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], dtype=uint64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "manual_case1 = pd.DataFrame(adj_list.focal.values, BJC.astype('uint8')).reset_index()\n",
    "# Temporarily rename the columns\n",
    "manual_case1.columns = ['BJC', 'ID']\n",
    "manual_case1 = manual_case1.groupby(by='ID').sum()\n",
    "manual_case1.BJC.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a visual comparison to the original table (remember, x values appear first and z values appear second):\n",
    "\n",
    "Original table\n",
    "\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0,0 | 0,1 | 0,0 | 0,1 |\n",
    "| 0,1 | 0,1 | 0,1 | 0,1 |\n",
    "| 1,0 | 1,0 | 1,1 | 1,1 |\n",
    "| 1,0 | 1,0 | 1,1 | 1,1 |\n",
    "\n",
    "\n",
    "Local Join Counts (bivariate)\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 1 | 1 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 0 |\n",
    "\n",
    "This makes sense give our case 1 conditions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: Co-location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to case 2, this is when the interest is in co-located events being surrounded by other co-located events.\n",
    "\n",
    "This requires $x_i=z_i=1$ as well as $x_j=z_j=1$ for the neighbors. Reviewing, we formally write this as:\n",
    "\n",
    "$$ CLC_i = x_i * z_i \\sum_j w_{ij} x_j z_j $$\n",
    "\n",
    "Given that $x_i=z_i=1$, this becomes:\n",
    "\n",
    "$$ CLC_i = 1 * 1 \\sum_j w_{ij} x_j z_j $$\n",
    "\n",
    "Let's now implement this from the above code. The only thing we need to change is how `BJC` are calculated (now `CLC`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "        True,  True, False, False, False, False, False,  True, False,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLC = (focal_x == 1) & (focal_z == 1) & (neighbor_x == 1) & (neighbor_z == 1)\n",
    "CLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2], dtype=uint64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "manual_case2 = pd.DataFrame(adj_list.focal.values, CLC.astype('uint8')).reset_index()\n",
    "# Temporarily rename the columns\n",
    "manual_case2.columns = ['CLC', 'ID']\n",
    "manual_case2 = manual_case2.groupby(by='ID').sum()\n",
    "manual_case2.CLC.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a visual comparison to the original table (remember, x values appear first and z values appear second):\n",
    "\n",
    "Original table\n",
    "\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0,0 | 0,1 | 0,0 | 0,1 |\n",
    "| 0,1 | 0,1 | 0,1 | 0,1 |\n",
    "| 1,0 | 1,0 | 1,1 | 1,1 |\n",
    "| 1,0 | 1,0 | 1,1 | 1,1 |\n",
    "\n",
    "\n",
    "Local Join Counts (bivariate, case 2 clc)\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 2 | 2 |\n",
    "| 0 | 0 | 2 | 2 |\n",
    "\n",
    "This makes sense give our case 2 conditions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Local_Join_Count_BV function <a name=\"LJC\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above manual calculations are implemented in the function called `local_join_count_bv.py` (available on the [jeffcsauer/GSOC2020/scratch](https://github.com/jeffcsauer/GSOC2020/tree/master/functions) github work journal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator\n",
    "\n",
    "PERMUTATIONS = 999\n",
    "\n",
    "class Local_Join_Count_BV(BaseEstimator):\n",
    "\n",
    "    \"\"\"Bivariate local join counts\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None, permutations=PERMUTATIONS):\n",
    "        \"\"\"\n",
    "        Initialize a Join_Counts_Local estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity:   scipy.sparse matrix object\n",
    "                        the connectivity structure describing the relationships\n",
    "                        between observed units. Will be row-standardized.\n",
    "        Attributes\n",
    "        ----------\n",
    "        LJC :  numpy.ndarray (1,)\n",
    "               array containing the estimated Bivariate Local Join Counts\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "        self.permutations = permutations\n",
    "\n",
    "    def fit(self, x, z, case=None, permutations=999):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        y       :   numpy.ndarray\n",
    "                    array containing binary (0/1) data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`AnselinLi2019`.\n",
    "        \"\"\"\n",
    "        x = np.asarray(x).flatten()\n",
    "        z = np.asarray(z).flatten()\n",
    "\n",
    "        w = self.connectivity\n",
    "        w.transformation = 'b'\n",
    "\n",
    "        self.x = x\n",
    "        self.z = z\n",
    "        self.n = len(x)\n",
    "        self.w = w\n",
    "\n",
    "        self.LJC = self._statistic(x, z, w, case=case)\n",
    "\n",
    "        if permutations:\n",
    "            self._crand()\n",
    "            sim = np.transpose(self.rjoins)\n",
    "            above = sim >= self.LJC\n",
    "            larger = above.sum(0)\n",
    "            low_extreme = (self.permutations - larger) < larger\n",
    "            larger[low_extreme] = self.permutations - larger[low_extreme]\n",
    "            # 1 - simulated p-value? or just the simulated p-value?\n",
    "            # values of 0.001 seem to be NA or error?\n",
    "            self.p_sim = (larger + 1.0) / (permutations + 1.0)\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(x, z, w, case=None):\n",
    "        # Create adjacency list. Note that remove_symmetric=False - this is\n",
    "        # different from the esda.Join_Counts() function.\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "\n",
    "        # First, set up a series that maps the y values\n",
    "        # (input as self.y) to the weights table\n",
    "        zseries_x = pd.Series(x, index=w.id_order)\n",
    "        zseries_z = pd.Series(z, index=w.id_order)\n",
    "\n",
    "        # Next, map the y values to the focal (i) values\n",
    "        focal_x = zseries_x.loc[adj_list.focal].values\n",
    "        focal_z = zseries_z.loc[adj_list.focal].values\n",
    "\n",
    "        # Repeat the mapping but for the neighbor (j) values\n",
    "        neighbor_x = zseries_x.loc[adj_list.neighbor].values\n",
    "        neighbor_z = zseries_z.loc[adj_list.neighbor].values\n",
    "\n",
    "        if case == \"BJC\":\n",
    "            BJC = (focal_x == 1) & (focal_z == 0) & \\\n",
    "                  (neighbor_x == 0) & (neighbor_z == 1)\n",
    "            adj_list_BJC = pd.DataFrame(adj_list.focal.values,\n",
    "                                        BJC.astype('uint8')).reset_index()\n",
    "            adj_list_BJC.columns = ['BJC', 'ID']\n",
    "            adj_list_BJC = adj_list_BJC.groupby(by='ID').sum()\n",
    "            return (adj_list_BJC.BJC.values)\n",
    "        elif case == \"CLC\":\n",
    "            CLC = (focal_x == 1) & (focal_z == 1) & \\\n",
    "                  (neighbor_x == 1) & (neighbor_z == 1)\n",
    "            adj_list_CLC = pd.DataFrame(adj_list.focal.values,\n",
    "                                        CLC.astype('uint8')).reset_index()\n",
    "            adj_list_CLC.columns = ['CLC', 'ID']\n",
    "            adj_list_CLC = adj_list_CLC.groupby(by='ID').sum()\n",
    "            return (adj_list_CLC.CLC.values)\n",
    "        else:\n",
    "            print(\"Please specify which type of bivariate Local Join Count \\\n",
    "            you would like to calculate (either 'BJC' or 'CLC'). See Anselin \\\n",
    "            and Li 2019 p. 9-10 for more information\")\n",
    "            \n",
    "    def _crand(self):\n",
    "        \"\"\"\n",
    "        conditional randomization\n",
    "\n",
    "        for observation i with ni neighbors,  the candidate set cannot include\n",
    "        i (we don't want i being a neighbor of i). we have to sample without\n",
    "        replacement from a set of ids that doesn't include i. numpy doesn't\n",
    "        directly support sampling wo replacement and it is expensive to\n",
    "        implement this. instead we omit i from the original ids,  permute the\n",
    "        ids and take the first ni elements of the permuted ids as the\n",
    "        neighbors to i in each randomization.\n",
    "\n",
    "        \"\"\"\n",
    "        # converted z to y\n",
    "        # renamed lisas to joins\n",
    "        x = self.x\n",
    "        z = self.z\n",
    "        n = len(x)\n",
    "        joins = np.zeros((self.n, self.permutations))\n",
    "        n_1 = self.n - 1\n",
    "        prange = list(range(self.permutations))\n",
    "        k = self.w.max_neighbors + 1\n",
    "        nn = self.n - 1\n",
    "        rids = np.array([np.random.permutation(nn)[0:k] for i in prange])\n",
    "        ids = np.arange(self.w.n)\n",
    "        ido = self.w.id_order\n",
    "        w = [self.w.weights[ido[i]] for i in ids]\n",
    "        wc = [self.w.cardinalities[ido[i]] for i in ids]\n",
    "\n",
    "        for i in range(self.w.n):\n",
    "            idsi = ids[ids != i]\n",
    "            np.random.shuffle(idsi)\n",
    "            # Mirroring moran_local_bv()\n",
    "            tmp = x[idsi[rids[:, 0:wc[i]]]]\n",
    "            joins[i] = z[i] * (w[i] * tmp).sum(1)\n",
    "        self.rjoins = joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Local_Join_Count function on the 'toy' dataset <a name=\"LJCToy\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Recreate inputs and weights (otherwise they are altered when running notebook)\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "y_1 = np.ones(16)\n",
    "# Set the first 9 of the ones to 0\n",
    "y_1[0:8] = 0\n",
    "# Set x equal to y_1\n",
    "x = y_1\n",
    "x = x.astype(np.int32)\n",
    "# Create another random sequences of 0 and 1\n",
    "z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "# Case 1\n",
    "toy_results_case1 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"BJC\")\n",
    "print(toy_results_case1.LJC)\n",
    "# Case 2\n",
    "toy_results_case2 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"CLC\")\n",
    "print(toy_results_case2.LJC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare output of `Local_Join_Count` function to the manually-calculated `LJC` from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of toy function to manual values (Case 1)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "----------------------------------------------------\n",
      "Comparison of toy function to manual values (Case 2)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Case 1\n",
    "print(\"Comparison of toy function to manual values (Case 1)\")\n",
    "print(toy_results_case1.LJC == manual_case1.BJC.values)\n",
    "print(\"----------------------------------------------------\")\n",
    "# Case 2\n",
    "print(\"Comparison of toy function to manual values (Case 2)\")\n",
    "print(toy_results_case2.LJC == manual_case2.CLC.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All values match."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Local_Join_Count_BV function on 'real world' datasets <a name=\"LJCRealWorld\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would look to compare the output to the values from the original Anselin and Li 2019 paper. However, the example use cases in Anselin and Li 2019 do not provide full tables of LJC and associate p-values to confirm equivalency. Thus, we compare the results from the PySAL implementation of `Local_Join_Counts_BV` to the output from GeoDa using a GeoDa example dataset. Specifically, we use the [Baltimore Housing Sales dataset](https://geodacenter.github.io/data-and-lab/baltim/) and focus on the 'dwell' and 'patio' binary variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to GeoDa output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first load in the Baltimore Housing Sales dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>price</th>\n",
       "      <th>nroom</th>\n",
       "      <th>dwell</th>\n",
       "      <th>nbath</th>\n",
       "      <th>patio</th>\n",
       "      <th>firepl</th>\n",
       "      <th>ac</th>\n",
       "      <th>bment</th>\n",
       "      <th>nstor</th>\n",
       "      <th>gar</th>\n",
       "      <th>age</th>\n",
       "      <th>citcou</th>\n",
       "      <th>lotsz</th>\n",
       "      <th>sqft</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>11.25</td>\n",
       "      <td>907.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>POINT (907.000 534.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>279.51</td>\n",
       "      <td>28.92</td>\n",
       "      <td>922.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>POINT (922.000 574.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.64</td>\n",
       "      <td>30.62</td>\n",
       "      <td>920.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>POINT (920.000 581.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>104.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>174.63</td>\n",
       "      <td>26.12</td>\n",
       "      <td>923.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>POINT (923.000 578.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.80</td>\n",
       "      <td>22.04</td>\n",
       "      <td>918.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>POINT (918.000 574.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station  price  nroom  dwell  nbath  patio  firepl   ac  bment  nstor  gar  \\\n",
       "0      1.0   47.0    4.0    0.0    1.0    0.0     0.0  0.0    2.0    3.0  0.0   \n",
       "1      2.0  113.0    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  2.0   \n",
       "2      3.0  165.0    7.0    1.0    2.5    1.0     1.0  0.0    3.0    2.0  2.0   \n",
       "3      4.0  104.3    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  2.0   \n",
       "4      5.0   62.5    7.0    1.0    1.5    1.0     1.0  0.0    2.0    2.0  0.0   \n",
       "\n",
       "     age  citcou   lotsz   sqft      x      y                 geometry  \n",
       "0  148.0     0.0    5.70  11.25  907.0  534.0  POINT (907.000 534.000)  \n",
       "1    9.0     1.0  279.51  28.92  922.0  574.0  POINT (922.000 574.000)  \n",
       "2   23.0     1.0   70.64  30.62  920.0  581.0  POINT (920.000 581.000)  \n",
       "3    5.0     1.0  174.63  26.12  923.0  578.0  POINT (923.000 578.000)  \n",
       "4   19.0     1.0  107.80  22.04  918.0  574.0  POINT (918.000 574.000)  "
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import geopandas as gpd\n",
    "balt = gpd.read_file('https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/baltimore/baltimore_housing.gpkg')\n",
    "balt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate the variable of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_balt = balt['dwell']\n",
    "z_balt = balt['patio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with points in PySAL we need to arrange them into a tree-able list of x and y points. Thus we extract the x and y columns of the baltimore dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = list(zip(balt['x'], balt['y']))\n",
    "import libpysal\n",
    "kd = libpysal.cg.KDTree(np.array(points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to recreate the weights used in the GeoDa analysis. The weight scheme used was a k-nearest neighbor (knn) approach, using 5 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "balt_knn5 = libpysal.weights.KNN(kd, k=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply our PySAL `Local_Join_Count_BV` function. **Note: it is unclear as to which case GeoDa defaults to. We compute both here and compare.** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test results case 1\n",
    "test_results_case1 = Local_Join_Count_BV(connectivity=balt_knn5).fit(x_balt, z_balt, case=\"BJC\")\n",
    "    #test_results_case1.LJC\n",
    "# Test results case 2\n",
    "test_results_case2 = Local_Join_Count_BV(connectivity=balt_knn5).fit(x_balt, z_balt, case=\"CLC\")\n",
    "    #test_results_case2.LJC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in the results from GeoDa analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>price</th>\n",
       "      <th>nroom</th>\n",
       "      <th>dwell</th>\n",
       "      <th>nbath</th>\n",
       "      <th>patio</th>\n",
       "      <th>firepl</th>\n",
       "      <th>ac</th>\n",
       "      <th>bment</th>\n",
       "      <th>nstor</th>\n",
       "      <th>...</th>\n",
       "      <th>lotsz</th>\n",
       "      <th>sqft</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>JC</th>\n",
       "      <th>NN</th>\n",
       "      <th>PP_VAL</th>\n",
       "      <th>BV_JC</th>\n",
       "      <th>BV_NN</th>\n",
       "      <th>BV_PP_VAL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.70</td>\n",
       "      <td>11.25</td>\n",
       "      <td>907.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>113.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>279.51</td>\n",
       "      <td>28.92</td>\n",
       "      <td>922.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.252</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>165.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.64</td>\n",
       "      <td>30.62</td>\n",
       "      <td>920.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.046</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>104.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>174.63</td>\n",
       "      <td>26.12</td>\n",
       "      <td>923.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.050</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>107.80</td>\n",
       "      <td>22.04</td>\n",
       "      <td>918.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.219</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   station  price  nroom  dwell  nbath  patio  firepl   ac  bment  nstor  ...  \\\n",
       "0        1   47.0    4.0    0.0    1.0    0.0     0.0  0.0    2.0    3.0  ...   \n",
       "1        2  113.0    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  ...   \n",
       "2        3  165.0    7.0    1.0    2.5    1.0     1.0  0.0    3.0    2.0  ...   \n",
       "3        4  104.3    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  ...   \n",
       "4        5   62.5    7.0    1.0    1.5    1.0     1.0  0.0    2.0    2.0  ...   \n",
       "\n",
       "    lotsz   sqft      x      y  JC  NN  PP_VAL  BV_JC  BV_NN  BV_PP_VAL  \n",
       "0    5.70  11.25  907.0  534.0   0   5     NaN      0      5        NaN  \n",
       "1  279.51  28.92  922.0  574.0   4   5   0.252      4      5      0.001  \n",
       "2   70.64  30.62  920.0  581.0   5   5   0.046      5      5      0.001  \n",
       "3  174.63  26.12  923.0  578.0   5   5   0.050      5      5      0.001  \n",
       "4  107.80  22.04  918.0  574.0   4   5   0.219      3      5      0.015  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load GeoDa analysis results\n",
    "GeoDa_LJC = pd.read_csv('https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/baltimore/balt_knn_5_LJC_bivariate.csv')\n",
    "GeoDa_LJC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the PySAL LJC results to to the GeoDa LJC results. Due to the somewhat high (n=211) number of comparisons, we will tabulate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of GeoDa bivariate LJC to PySAL implementation (Case 1):\n",
      "True     179\n",
      "False     32\n",
      "Name: BV_JC, dtype: int64\n",
      "--------------------------\n",
      "Comparison of GeoDa bivariate LJC to PySAL implementation (Case 2):\n",
      "True    211\n",
      "Name: BV_JC, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison of GeoDa bivariate LJC to PySAL implementation (Case 1):\")\n",
    "results = test_results_case1.LJC == GeoDa_LJC['BV_JC']\n",
    "print(results.value_counts())\n",
    "print(\"--------------------------\")\n",
    "print(\"Comparison of GeoDa bivariate LJC to PySAL implementation (Case 2):\")\n",
    "results = test_results_case2.LJC == GeoDa_LJC['BV_JC']\n",
    "print(results.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All 211 elements have the same LJC between the PySAL implementation and the GeoDa results **when using Case 2**. Thus, it seems GeoDa defaults to the co-location cluster (CLC) case. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing p-values at surface level...don't think this is working!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001, 0.207, 0.038, 0.048, 0.454, 0.142, 0.224, 0.139, 0.001,\n",
       "       0.13 ])"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_case2.p_sim[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan, 0.252, 0.046, 0.05 , 0.219, 0.247, 0.048, 0.207, 0.165,\n",
       "       0.043])"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(GeoDa_LJC.PP_VAL[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences in p-values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   nan, -0.045, -0.008, -0.002,  0.235, -0.105,  0.176, -0.068,\n",
       "       -0.164,  0.087])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_case2.p_sim[0:10] - np.array(GeoDa_LJC.PP_VAL[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "- Develop inference \n",
    "- Ensure docstrings include all relevant information and formatting\n",
    "- When constructing demonstration notebooks, ensure that notebooks are as standalone as possible (for GeoDa comparison make sure to include all relevant files in case the user does not want to download the program)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 32-bit",
   "language": "python",
   "name": "python38232bit07c05656855047638d93928e72c365e6"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
