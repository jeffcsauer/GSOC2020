{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This is the validation notebook for the PySAL implementation of the local join count (LJC) bivariate statistic. This notebook will begin with a brief review of the bivariate LJC and a manual calculation of the values on a 'toy' dataset. We will then introduce the PySAL implementation of the `Local_Join_Count_BV` function. Output from the `Local_Join_Count_BV` function will be compared to the results from the manual calculation on the 'toy' dataset. Following the 'toy' dataset will be a comparison of the PySAL `Local_Join_Count_BV` function to the external `GeoDa` results on an external dataset. As of now, calculations of inference are not included in the function.\n",
    "\n",
    "1. [Review of the bivariate LJC statistic](#Review)\n",
    "2. [Manual calculations on a 'toy' dataset](#Toy)\n",
    "3. [Implementation of Local_Join_Count_BV function](#LJC)\n",
    "4. [Application of Local_Join_Count_BV function on the 'toy' dataset](#LJCToy)\n",
    "5. [Application of Local_Join_Count_BV function on 'real world' datasets](#LJCRealWorld)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review of the bivariate LJC statistic <a name=\"Review\"></a>\n",
    "\n",
    "To review, global join counts focus on the total number of adjacent counts of certain values across the entire study area.  This is represented as $BB$:\n",
    "\n",
    "$$BB = \\sum_{i} \\sum_j w_{ij} x_{i} x_{j}$$\n",
    "\n",
    "Of particular interest to us are the number of local black-black (1-1) join counts. This is represented as $BB_i$: \n",
    "\n",
    "$$ BB_i = x_i \\sum_{j} w_{ij} x_j$$\n",
    "\n",
    "...where a count of the neighbors with an observation of $x_j=1$ for those locations where $x_i=1$. This focuses on the BB counts of a given polygon (x_i).\n",
    "\n",
    "When considering two variables, we extend the above equation to: \n",
    "\n",
    "$$ BJC_i = x_i (1 - z_i) \\sum_{j} w_{ij} z_j (1-x_j)$$\n",
    "\n",
    "Note that although x and z can be reserved, the statistic is not symmetric. Results may be different whether x or z is in focus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual calculations on a 'toy' dataset <a name=\"Toy\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now create a small 'toy' dataset to illustrate the local join counts. This toy dataset is a 4x4 lattice grid filled with 0s and 1s for each of the x and z binary variables. Note that for a given cell, the value of the x variable comes first and the value of the z variable comes second. \n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0,0 | 0,1 | 0,0 | 0,1 |\n",
    "| 0,1 | 0,1 | 0,1 | 0,1 |\n",
    "| 1,0 | 1,0 | 1,1 | 1,1 |\n",
    "| 1,0 | 1,0 | 1,1 | 1,1 |\n",
    "\n",
    "The arrangement of the above grid is captured in the `x` and `z` objects below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x [0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "z [0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import libpysal\n",
    "import pandas as pd\n",
    "\n",
    "# Create a 16x16 grid\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "y_1 = np.ones(16)\n",
    "# Set the first 9 of the ones to 0\n",
    "y_1[0:8] = 0\n",
    "# Set x equal to y_1\n",
    "x = y_1\n",
    "# Create another random sequence of 0 and 1\n",
    "z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "\n",
    "print('x', x)\n",
    "print('z', z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a given cell of the above table, we are interest in the adjacent grid cells that are equal to 1. We can find these through the use of **binary weights**. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 1. 1. 1.]\n",
      "[0 1 0 1 1 1 1 1 0 0 1 1 0 0 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Flatten the input vector y\n",
    "x = np.asarray(x).flatten()\n",
    "z = np.asarray(z).flatten()\n",
    "print(x)\n",
    "print(z)\n",
    "# ensure weights are binary transformed\n",
    "w.transform = 'b'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How does PySAL identify these cells? Through an adjacency list. This creates a list object of unique focal ($i$) and neighbor ($j$) pairs. The `remove_symmetric=True` ensure that there are not duplicated (but reversed) adjacency pairs. This is a great shortcut when calculating global join counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "0       0         4     1.0\n",
      "1       0         1     1.0\n",
      "3       1         5     1.0\n",
      "4       1         2     1.0\n",
      "6       2         6     1.0\n",
      "7       2         3     1.0\n",
      "9       3         7     1.0\n",
      "11      4         8     1.0\n",
      "12      4         5     1.0\n",
      "15      5         9     1.0\n",
      "16      5         6     1.0\n",
      "19      6        10     1.0\n",
      "20      6         7     1.0\n",
      "23      7        11     1.0\n",
      "25      8        12     1.0\n",
      "26      8         9     1.0\n",
      "29      9        13     1.0\n",
      "30      9        10     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "37     11        15     1.0\n",
      "39     12        13     1.0\n",
      "42     13        14     1.0\n",
      "45     14        15     1.0\n",
      "{4: 1.0, 1: 1.0}\n"
     ]
    }
   ],
   "source": [
    "adj_list = w.to_adjlist(remove_symmetric=True) \n",
    "print(adj_list)\n",
    "print(w[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From this list we can validate neighbors. For example, in our 4x4 grid, we know that the upper-left hand corner of the grid (w[0]) only touches its right and bottom neighbor(remember: we are not using a queen contiguity in this example). Thus, the first weight object will capture these relationships and they will be reflected in the adj_list table (see row 1 [0 1 1.0] and 4 [4 0 1.0]). \n",
    "\n",
    "**However, in the Local Join Count (LJC) we use `remove_symmetric=True`.** This allows us to identify the specific join counts for each area $i$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    focal  neighbor  weight\n",
      "0       0         4     1.0\n",
      "1       0         1     1.0\n",
      "2       1         0     1.0\n",
      "3       1         5     1.0\n",
      "4       1         2     1.0\n",
      "5       2         1     1.0\n",
      "6       2         6     1.0\n",
      "7       2         3     1.0\n",
      "8       3         2     1.0\n",
      "9       3         7     1.0\n",
      "10      4         0     1.0\n",
      "11      4         8     1.0\n",
      "12      4         5     1.0\n",
      "13      5         1     1.0\n",
      "14      5         4     1.0\n",
      "15      5         9     1.0\n",
      "16      5         6     1.0\n",
      "17      6         2     1.0\n",
      "18      6         5     1.0\n",
      "19      6        10     1.0\n",
      "20      6         7     1.0\n",
      "21      7         3     1.0\n",
      "22      7         6     1.0\n",
      "23      7        11     1.0\n",
      "24      8         4     1.0\n",
      "25      8        12     1.0\n",
      "26      8         9     1.0\n",
      "27      9         5     1.0\n",
      "28      9         8     1.0\n",
      "29      9        13     1.0\n",
      "30      9        10     1.0\n",
      "31     10         6     1.0\n",
      "32     10         9     1.0\n",
      "33     10        14     1.0\n",
      "34     10        11     1.0\n",
      "35     11         7     1.0\n",
      "36     11        10     1.0\n",
      "37     11        15     1.0\n",
      "38     12         8     1.0\n",
      "39     12        13     1.0\n",
      "40     13         9     1.0\n",
      "41     13        12     1.0\n",
      "42     13        14     1.0\n",
      "43     14        10     1.0\n",
      "44     14        13     1.0\n",
      "45     14        15     1.0\n",
      "46     15        11     1.0\n",
      "47     15        14     1.0\n"
     ]
    }
   ],
   "source": [
    "adj_list = w.to_adjlist(remove_symmetric=False) \n",
    "print(adj_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now mirror the existing implementation of `Join_Counts` to create some objects that count the number of 1 value for the focal ($i$) and neighbor ($j$) cells. We do this for both the x and z variables. **Note: perhaps an area for optimization?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, set up a series that maps the y values (input as self.y) to the weights table \n",
    "zseries_x = pd.Series(x, index=w.id_order)\n",
    "zseries_z = pd.Series(z, index=w.id_order)\n",
    "\n",
    "# Next, map the y values to the focal (i) values \n",
    "focal_x = zseries_x.loc[adj_list.focal].values\n",
    "focal_z = zseries_z.loc[adj_list.focal].values\n",
    "\n",
    "# Repeat the mapping but for the neighbor (j) values\n",
    "neighbor_x = zseries_x.loc[adj_list.neighbor].values\n",
    "neighbor_z = zseries_z.loc[adj_list.neighbor].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1: No co-location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the bivariate join count there are two situations (no co-location, and co-location). We first compute case 1 (no co-location)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True, False, False,\n",
       "        True, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BJC = (focal_x == 1) & (focal_z == 0) & (neighbor_x == 0) & (neighbor_z == 1)\n",
    "BJC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to map these values to the adjacency list. By grouping by the 'ID\" column of the adjacnecy list, we can get the sum of agreements where focal x and neighbor z have the same 1 value (while ensuring that the focal z and neighbor x have a value of 0). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0], dtype=uint64)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "manual_case1 = pd.DataFrame(adj_list.focal.values, BJC.astype('uint8')).reset_index()\n",
    "# Temporarily rename the columns\n",
    "manual_case1.columns = ['BJC', 'ID']\n",
    "manual_case1 = manual_case1.groupby(by='ID').sum()\n",
    "manual_case1.BJC.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a visual comparison to the original table (remember, x values appear first and z values appear second):\n",
    "\n",
    "Original table\n",
    "\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0,0 | 0,1 | 0,0 | 0,1 |\n",
    "| 0,1 | 0,1 | 0,1 | 0,1 |\n",
    "| 1,0 | 1,0 | 1,1 | 1,1 |\n",
    "| 1,0 | 1,0 | 1,1 | 1,1 |\n",
    "\n",
    "\n",
    "Local Join Counts (bivariate)\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 1 | 1 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 0 |\n",
    "\n",
    "This makes sense give our case 1 conditions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2: Co-location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Moving on to case 2, this is when the interest is in co-located events being surrounded by other co-located events.\n",
    "\n",
    "This requires $x_i=z_i=1$ as well as $x_j=z_j=1$ for the neighbors. Reviewing, we formally write this as:\n",
    "\n",
    "$$ CLC_i = x_i * z_i \\sum_j w_{ij} x_j z_j $$\n",
    "\n",
    "Given that $x_i=z_i=1$, this becomes:\n",
    "\n",
    "$$ CLC_i = 1 * 1 \\sum_j w_{ij} x_j z_j $$\n",
    "\n",
    "Let's now implement this from the above code. The only thing we need to change is how `BJC` are calculated (now `CLC`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False, False, False, False,\n",
       "       False, False, False, False, False, False,  True,  True, False,\n",
       "        True,  True, False, False, False, False, False,  True, False,\n",
       "        True,  True,  True])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CLC = (focal_x == 1) & (focal_z == 1) & (neighbor_x == 1) & (neighbor_z == 1)\n",
    "CLC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2], dtype=uint64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a df that uses the adjacency list focal values and the BBs counts\n",
    "manual_case2 = pd.DataFrame(adj_list.focal.values, CLC.astype('uint8')).reset_index()\n",
    "# Temporarily rename the columns\n",
    "manual_case2.columns = ['CLC', 'ID']\n",
    "manual_case2 = manual_case2.groupby(by='ID').sum()\n",
    "manual_case2.CLC.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's do a visual comparison to the original table (remember, x values appear first and z values appear second):\n",
    "\n",
    "Original table\n",
    "\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0,0 | 0,1 | 0,0 | 0,1 |\n",
    "| 0,1 | 0,1 | 0,1 | 0,1 |\n",
    "| 1,0 | 1,0 | 1,1 | 1,1 |\n",
    "| 1,0 | 1,0 | 1,1 | 1,1 |\n",
    "\n",
    "\n",
    "Local Join Counts (bivariate, case 2 clc)\n",
    "\n",
    "|   |   |   |   |\n",
    "|---|---|---|---|\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 0 | 0 |\n",
    "| 0 | 0 | 2 | 2 |\n",
    "| 0 | 0 | 2 | 2 |\n",
    "\n",
    "This makes sense give our case 2 conditions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of Local_Join_Count_BV function <a name=\"LJC\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above manual calculations are implemented in the function called `local_join_count_bv.py` (available on the [jeffcsauer/GSOC2020/scratch](https://github.com/jeffcsauer/GSOC2020/tree/master/functions) github work journal)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext pycodestyle_magic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%pycodestyle_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator\n",
    "from libpysal import weights\n",
    "\n",
    "\n",
    "PERMUTATIONS = 999\n",
    "\n",
    "\n",
    "class Local_Join_Count_BV(BaseEstimator):\n",
    "\n",
    "    \"\"\"Univariate Local Join Count Statistic\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None, permutations=PERMUTATIONS):\n",
    "        \"\"\"\n",
    "        Initialize a Local_Join_Count_BV estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity     : scipy.sparse matrix object\n",
    "                           the connectivity structure describing\n",
    "                           the relationships between observed units.\n",
    "                           Need not be row-standardized.\n",
    "        Attributes\n",
    "        ----------\n",
    "        LJC              : numpy.ndarray\n",
    "                           array containing the estimated\n",
    "                           Bivariate Local Join Counts\n",
    "        p_sim            : numpy.ndarray\n",
    "                           array containing the simulated\n",
    "                           p-values for each unit.\n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "        self.permutations = permutations\n",
    "\n",
    "    def fit(self, x, z, case=\"CLC\", permutations=999):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        x                : numpy.ndarray\n",
    "                           array containing binary (0/1) data\n",
    "        z                : numpy.ndarray\n",
    "                           array containing binary (0/1) data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`AnselinLi2019`.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> import libpysal\n",
    "        >>> w = libpysal.weights.lat2W(4, 4)\n",
    "        >>> x = np.ones(16)\n",
    "        >>> x[0:8] = 0\n",
    "        >>> z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "        >>> LJC_BV_C1 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"BJC\")\n",
    "        >>> LJC_BV_C2 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"CLC\")\n",
    "        >>> LJC_BV_C1.LJC\n",
    "        >>> LJC_BV_C1.p_sim\n",
    "        >>> LJC_BV_C2.LJC\n",
    "        >>> LJC_BV_C2.p_sim\n",
    "\n",
    "        Commpop data replicating GeoDa tutorial (Case 1)\n",
    "        >>> import libpysal\n",
    "        >>> import geopandas as gpd\n",
    "        >>> commpop = gpd.read_file(\"https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/commpop.gpkg\")\n",
    "        >>> w = libpysal.weights.Queen.from_dataframe(commpop)\n",
    "        >>> LJC_BV_Case1 = Local_Join_Count_BV(connectivity=w).fit(commpop['popneg'], commpop['popplus'], case='BJC')\n",
    "        >>> LJC_BV_Case1.LJC\n",
    "        >>> LJC_BV_Case1.p_sim\n",
    "\n",
    "        Guerry data replicating GeoDa tutorial (Case 2)\n",
    "        >>> import libpysal\n",
    "        >>> import geopandas as gpd\n",
    "        >>> guerry = libpysal.examples.load_example('Guerry')\n",
    "        >>> guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))\n",
    "        >>> guerry_ds['infq5'] = 0\n",
    "        >>> guerry_ds['donq5'] = 0\n",
    "        >>> guerry_ds.loc[(guerry['Infants'] > 23574), 'infq5'] = 1\n",
    "        >>> guerry_ds.loc[(guerry['Donatns'] > 10973), 'donq5'] = 1\n",
    "        >>> w = libpysal.weights.Queen.from_dataframe(guerry_ds)\n",
    "        >>> LJC_BV_Case2 = Local_Join_Count_BV(connectivity=w).fit(guerry_ds['infq5'], guerry_ds['donq5'], case='CLC')\n",
    "        >>> LJC_BV_Case2.LJC\n",
    "        >>> LJC_BV_Case2.p_sim\n",
    "        \"\"\"\n",
    "        x = np.asarray(x).flatten()\n",
    "        z = np.asarray(z).flatten()\n",
    "\n",
    "        w = self.connectivity\n",
    "        # Fill the diagonal with 0s\n",
    "        w = weights.util.fill_diagonal(w, val=0)\n",
    "        w.transform = 'b'\n",
    "\n",
    "        self.x = x\n",
    "        self.z = z\n",
    "        self.n = len(x)\n",
    "        self.w = w\n",
    "        self.case = case\n",
    "\n",
    "        self.LJC = self._statistic(x, z, w, case=case)\n",
    "\n",
    "        if permutations:\n",
    "            self._crand()\n",
    "            sim = np.transpose(self.rjoins)\n",
    "            above = sim >= self.LJC\n",
    "            larger = above.sum(0)\n",
    "            low_extreme = (self.permutations - larger) < larger\n",
    "            larger[low_extreme] = self.permutations - larger[low_extreme]\n",
    "            self.p_sim = (larger + 1.0) / (permutations + 1.0)\n",
    "            # Set p-values for those with LJC of 0 to NaN\n",
    "            self.p_sim[self.LJC == 0] = 'NaN'\n",
    "\n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(x, z, w, case):\n",
    "        # Create adjacency list. Note that remove_symmetric=False - this is\n",
    "        # different from the esda.Join_Counts() function.\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "\n",
    "        # First, set up a series that maps the values\n",
    "        # to the weights table\n",
    "        zseries_x = pd.Series(x, index=w.id_order)\n",
    "        zseries_z = pd.Series(z, index=w.id_order)\n",
    "\n",
    "        # Map the values to the focal (i) values\n",
    "        focal_x = zseries_x.loc[adj_list.focal].values\n",
    "        focal_z = zseries_z.loc[adj_list.focal].values\n",
    "\n",
    "        # Map the values to the neighbor (j) values\n",
    "        neighbor_x = zseries_x.loc[adj_list.neighbor].values\n",
    "        neighbor_z = zseries_z.loc[adj_list.neighbor].values\n",
    "\n",
    "        if case == \"BJC\":\n",
    "            BJC = (focal_x == 1) & (focal_z == 0) & \\\n",
    "                  (neighbor_x == 0) & (neighbor_z == 1)\n",
    "            adj_list_BJC = pd.DataFrame(adj_list.focal.values,\n",
    "                                        BJC.astype('uint8')).reset_index()\n",
    "            adj_list_BJC.columns = ['BJC', 'ID']\n",
    "            adj_list_BJC = adj_list_BJC.groupby(by='ID').sum()\n",
    "            return (adj_list_BJC.BJC.values)\n",
    "        elif case == \"CLC\":\n",
    "            CLC = (focal_x == 1) & (focal_z == 1) & \\\n",
    "                  (neighbor_x == 1) & (neighbor_z == 1)\n",
    "            adj_list_CLC = pd.DataFrame(adj_list.focal.values,\n",
    "                                        CLC.astype('uint8')).reset_index()\n",
    "            adj_list_CLC.columns = ['CLC', 'ID']\n",
    "            adj_list_CLC = adj_list_CLC.groupby(by='ID').sum()\n",
    "            return (adj_list_CLC.CLC.values)\n",
    "        else:\n",
    "            raise NotImplementedError(f'The requested LJC method ({case}) \\\n",
    "            is not currently supported!')\n",
    "\n",
    "    def _crand(self):\n",
    "        \"\"\"\n",
    "        conditional randomization\n",
    "\n",
    "        for observation i with ni neighbors,  the candidate set cannot include\n",
    "        i (we don't want i being a neighbor of i). we have to sample without\n",
    "        replacement from a set of ids that doesn't include i. numpy doesn't\n",
    "        directly support sampling wo replacement and it is expensive to\n",
    "        implement this. instead we omit i from the original ids,  permute the\n",
    "        ids and take the first ni elements of the permuted ids as the\n",
    "        neighbors to i in each randomization.\n",
    "\n",
    "        \"\"\"\n",
    "        x = self.x\n",
    "        z = self.z\n",
    "        case = self.case\n",
    "\n",
    "        n = len(x)\n",
    "        joins = np.zeros((self.n, self.permutations))\n",
    "        n_1 = self.n - 1\n",
    "        prange = list(range(self.permutations))\n",
    "        k = self.w.max_neighbors + 1\n",
    "        nn = self.n - 1\n",
    "        rids = np.array([np.random.permutation(nn)[0:k] for i in prange])\n",
    "        ids = np.arange(self.w.n)\n",
    "        ido = self.w.id_order\n",
    "        w = [self.w.weights[ido[i]] for i in ids]\n",
    "        wc = [self.w.cardinalities[ido[i]] for i in ids]\n",
    "\n",
    "        for i in range(self.w.n):\n",
    "            idsi = ids[ids != i]\n",
    "            np.random.shuffle(idsi)\n",
    "            tmp_x = x[idsi[rids[:, 0:wc[i]]]]\n",
    "            tmp_z = z[idsi[rids[:, 0:wc[i]]]]\n",
    "            if case == \"BJC\":\n",
    "                joins[i] = x[i] * (w[i] * tmp_z).sum(1)\n",
    "            elif case == \"CLC\":\n",
    "                joins[i] = z[i] * (w[i] * tmp_z * tmp_x).sum(1)\n",
    "            else:\n",
    "                raise NotImplementedError(f'The requested LJC method \\\n",
    "                ({case}) is not currently supported!')\n",
    "        self.rjoins = joins"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Local_Join_Count function on the 'toy' dataset <a name=\"LJCToy\"></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 2 2 0 0 2 2]\n"
     ]
    }
   ],
   "source": [
    "# Recreate inputs and weights (otherwise they are altered when running notebook)\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "y_1 = np.ones(16)\n",
    "# Set the first 9 of the ones to 0\n",
    "y_1[0:8] = 0\n",
    "# Set x equal to y_1\n",
    "x = y_1\n",
    "x = x.astype(np.int32)\n",
    "# Create another random sequences of 0 and 1\n",
    "z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "# Case 1\n",
    "toy_results_case1 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"BJC\")\n",
    "print(toy_results_case1.LJC)\n",
    "# Case 2\n",
    "toy_results_case2 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"CLC\")\n",
    "print(toy_results_case2.LJC)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try passing a 'bad' case value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"Garbage\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare output of `Local_Join_Count` function to the manually-calculated `LJC` from above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of toy function to manual values (Case 1)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n",
      "----------------------------------------------------\n",
      "Comparison of toy function to manual values (Case 2)\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True]\n"
     ]
    }
   ],
   "source": [
    "# Case 1\n",
    "print(\"Comparison of toy function to manual values (Case 1)\")\n",
    "print(toy_results_case1.LJC == manual_case1.BJC.values)\n",
    "print(\"----------------------------------------------------\")\n",
    "# Case 2\n",
    "print(\"Comparison of toy function to manual values (Case 2)\")\n",
    "print(toy_results_case2.LJC == manual_case2.CLC.values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All values match."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan, 0.031,\n",
       "       0.004,   nan,   nan,   nan,   nan,   nan,   nan])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_results_case1.p_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,   nan,\n",
       "         nan, 0.163, 0.077,   nan,   nan, 0.088, 0.032])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toy_results_case2.p_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Application of Local_Join_Count_BV function on 'real world' datasets <a name=\"LJCRealWorld\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideally, we would look to compare the output to the values from the original Anselin and Li 2019 paper. However, the example use cases in Anselin and Li 2019 do not provide full tables of LJC and associate p-values to confirm equivalency. Thus, we compare the results from the PySAL implementation of `Local_Join_Counts_BV` to the output from GeoDa using a GeoDa example dataset. Specifically, we use the [Baltimore Housing Sales dataset](https://geodacenter.github.io/data-and-lab/baltim/) and focus on the 'dwell' ($x$) and 'patio' ($z$) binary variables. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to GeoDa output - Case 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the Case 1 comparison we use the `commpop` dataset, the same dataset used in the GeoDa tutorial on [Bivariate Local Join Counts](https://geodacenter.github.io/workbook/6b_local_adv/lab6b.html#bivariate-and-multivariate-local-join-count-statistics). The variables of interest are $x$ (`popneg`) and $z$ (`popplus`). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import libpysal\n",
    "\n",
    "commpop = gpd.read_file(\"https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/commpop_geodavalues.gpkg\")\n",
    "\n",
    "w = libpysal.weights.Queen.from_dataframe(commpop)\n",
    "\n",
    "LJC_BV_Case1 = Local_Join_Count_BV(connectivity=w).fit(commpop['popneg'], commpop['popplus'], case='BJC')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34.6 ms ± 5.9 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit Local_Join_Count_BV(connectivity=w).fit(commpop['popneg'], commpop['popplus'], case='BJC')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's compare the local join count values from `Local_Join_Count_BV` to that of GeoDa."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of GeoDa bivariate LJC to PySAL implementation (Case 1):\n",
      "True    77\n",
      "Name: JC_BV_C1, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison of GeoDa bivariate LJC to PySAL implementation (Case 1):\")\n",
    "results = LJC_BV_Case1.LJC == commpop['JC_BV_C1']\n",
    "print(results.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, a 100% match! Now let's examine how the p-values compare."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between the two sets of p-values is 0.9957068123144417\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ec767d8>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assess correlation between p-values\n",
    "corrdf = pd.DataFrame(LJC_BV_Case1.p_sim, commpop.PP_VAL_BV_C1).reset_index()\n",
    "corrdf.columns = ['pysal', 'geoda']\n",
    "print(\"The correlation between the two sets of p-values is\", corrdf['pysal'].corr(corrdf['geoda']))\n",
    "\n",
    "corrdf.plot.scatter(x='pysal',\n",
    "                    y='geoda',\n",
    "                    c='DarkBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Strong correlation and agreement between the two functions. No strange outlier values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison to GeoDa output - Case 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For Case 2 we use the Baltimore Home Sales dataset. Although this dataset is not used in the GeoDa tutorial, it is a relatively common dataset used in teaching examples. Moreover, it initiates a point of discussion between some strange disagreements between the two functions. The actual doctest of `Local_Join_Counts_BV` uses the Guerry dataset and replicates the GeoDa online tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>price</th>\n",
       "      <th>nroom</th>\n",
       "      <th>dwell</th>\n",
       "      <th>nbath</th>\n",
       "      <th>patio</th>\n",
       "      <th>firepl</th>\n",
       "      <th>ac</th>\n",
       "      <th>bment</th>\n",
       "      <th>nstor</th>\n",
       "      <th>gar</th>\n",
       "      <th>age</th>\n",
       "      <th>citcou</th>\n",
       "      <th>lotsz</th>\n",
       "      <th>sqft</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.70</td>\n",
       "      <td>11.25</td>\n",
       "      <td>907.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>POINT (907.000 534.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.0</td>\n",
       "      <td>113.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>279.51</td>\n",
       "      <td>28.92</td>\n",
       "      <td>922.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>POINT (922.000 574.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>70.64</td>\n",
       "      <td>30.62</td>\n",
       "      <td>920.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>POINT (920.000 581.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.0</td>\n",
       "      <td>104.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>174.63</td>\n",
       "      <td>26.12</td>\n",
       "      <td>923.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>POINT (923.000 578.000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>62.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>107.80</td>\n",
       "      <td>22.04</td>\n",
       "      <td>918.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>POINT (918.000 574.000)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   station  price  nroom  dwell  nbath  patio  firepl   ac  bment  nstor  gar  \\\n",
       "0      1.0   47.0    4.0    0.0    1.0    0.0     0.0  0.0    2.0    3.0  0.0   \n",
       "1      2.0  113.0    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  2.0   \n",
       "2      3.0  165.0    7.0    1.0    2.5    1.0     1.0  0.0    3.0    2.0  2.0   \n",
       "3      4.0  104.3    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  2.0   \n",
       "4      5.0   62.5    7.0    1.0    1.5    1.0     1.0  0.0    2.0    2.0  0.0   \n",
       "\n",
       "     age  citcou   lotsz   sqft      x      y                 geometry  \n",
       "0  148.0     0.0    5.70  11.25  907.0  534.0  POINT (907.000 534.000)  \n",
       "1    9.0     1.0  279.51  28.92  922.0  574.0  POINT (922.000 574.000)  \n",
       "2   23.0     1.0   70.64  30.62  920.0  581.0  POINT (920.000 581.000)  \n",
       "3    5.0     1.0  174.63  26.12  923.0  578.0  POINT (923.000 578.000)  \n",
       "4   19.0     1.0  107.80  22.04  918.0  574.0  POINT (918.000 574.000)  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "balt = gpd.read_file('https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/baltimore/baltimore_housing.gpkg')\n",
    "balt.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolate the variable of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_balt = balt['dwell']\n",
    "z_balt = balt['patio']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When working with points in PySAL we need to arrange them into a tree-able list of x and y points. Thus we extract the x and y columns of the baltimore dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "points = list(zip(balt['x'], balt['y']))\n",
    "import libpysal\n",
    "kd = libpysal.cg.KDTree(np.array(points))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to recreate the weights used in the GeoDa analysis. The weight scheme used was a k-nearest neighbor (knn) approach, using 5 neighbors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "balt_knn5 = libpysal.weights.KNN(kd, k=5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now apply our PySAL `Local_Join_Count_BV` function to the dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test results case 1\n",
    "test_results_case1 = Local_Join_Count_BV(connectivity=balt_knn5).fit(x_balt, z_balt, case=\"BJC\")\n",
    "    #test_results_case1.LJC\n",
    "# Test results case 2\n",
    "test_results_case2 = Local_Join_Count_BV(connectivity=balt_knn5).fit(x_balt, z_balt, case=\"CLC\")\n",
    "    #test_results_case2.LJC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63 ms ± 5.03 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit Local_Join_Count_BV(connectivity=balt_knn5).fit(x_balt, z_balt, case=\"BJC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "65.3 ms ± 7.26 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit Local_Join_Count_BV(connectivity=balt_knn5).fit(x_balt, z_balt, case=\"CLC\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's read in the results from GeoDa analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>station</th>\n",
       "      <th>price</th>\n",
       "      <th>nroom</th>\n",
       "      <th>dwell</th>\n",
       "      <th>nbath</th>\n",
       "      <th>patio</th>\n",
       "      <th>firepl</th>\n",
       "      <th>ac</th>\n",
       "      <th>bment</th>\n",
       "      <th>nstor</th>\n",
       "      <th>...</th>\n",
       "      <th>lotsz</th>\n",
       "      <th>sqft</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>JC_C1</th>\n",
       "      <th>NN_C1</th>\n",
       "      <th>PP_VAL_C1</th>\n",
       "      <th>JC_C2</th>\n",
       "      <th>NN_C2</th>\n",
       "      <th>PP_VAL_C2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>47.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.70</td>\n",
       "      <td>11.25</td>\n",
       "      <td>907.0</td>\n",
       "      <td>534.0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>113.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>279.51</td>\n",
       "      <td>28.92</td>\n",
       "      <td>922.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>165.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>70.64</td>\n",
       "      <td>30.62</td>\n",
       "      <td>920.0</td>\n",
       "      <td>581.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>104.3</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>174.63</td>\n",
       "      <td>26.12</td>\n",
       "      <td>923.0</td>\n",
       "      <td>578.0</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>62.5</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>107.80</td>\n",
       "      <td>22.04</td>\n",
       "      <td>918.0</td>\n",
       "      <td>574.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.015</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>0.015</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   station  price  nroom  dwell  nbath  patio  firepl   ac  bment  nstor  ...  \\\n",
       "0        1   47.0    4.0    0.0    1.0    0.0     0.0  0.0    2.0    3.0  ...   \n",
       "1        2  113.0    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  ...   \n",
       "2        3  165.0    7.0    1.0    2.5    1.0     1.0  0.0    3.0    2.0  ...   \n",
       "3        4  104.3    7.0    1.0    2.5    1.0     1.0  1.0    2.0    2.0  ...   \n",
       "4        5   62.5    7.0    1.0    1.5    1.0     1.0  0.0    2.0    2.0  ...   \n",
       "\n",
       "    lotsz   sqft      x      y  JC_C1  NN_C1  PP_VAL_C1  JC_C2  NN_C2  \\\n",
       "0    5.70  11.25  907.0  534.0      0      5        NaN      0      5   \n",
       "1  279.51  28.92  922.0  574.0      4      5      0.001      4      5   \n",
       "2   70.64  30.62  920.0  581.0      5      5      0.001      5      5   \n",
       "3  174.63  26.12  923.0  578.0      5      5      0.001      5      5   \n",
       "4  107.80  22.04  918.0  574.0      3      5      0.015      3      5   \n",
       "\n",
       "   PP_VAL_C2  \n",
       "0        NaN  \n",
       "1      0.001  \n",
       "2      0.001  \n",
       "3      0.001  \n",
       "4      0.015  \n",
       "\n",
       "[5 rows x 23 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load GeoDa analysis results\n",
    "GeoDa_LJC = pd.read_csv('https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/baltimore/balt_knn_5_LJC_bivariate.csv')\n",
    "GeoDa_LJC.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare the PySAL LJC results to to the GeoDa LJC results. Due to the somewhat high (n=211) number of comparisons, we will tabulate the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comparison of GeoDa bivariate LJC to PySAL implementation (Case 1):\n",
      "True     179\n",
      "False     32\n",
      "Name: JC_C1, dtype: int64\n",
      "--------------------------\n",
      "Comparison of GeoDa bivariate LJC to PySAL implementation (Case 2):\n",
      "True    211\n",
      "Name: JC_C2, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Comparison of GeoDa bivariate LJC to PySAL implementation (Case 1):\")\n",
    "results = test_results_case1.LJC == GeoDa_LJC['JC_C1']\n",
    "print(results.value_counts())\n",
    "print(\"--------------------------\")\n",
    "print(\"Comparison of GeoDa bivariate LJC to PySAL implementation (Case 2):\")\n",
    "results = test_results_case2.LJC == GeoDa_LJC['JC_C2']\n",
    "print(results.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is some disagreement with Case 1, but we want to focus on Case 2 implementation here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing p-values at surface level..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan, 0.001, 0.001, 0.001, 0.013, 0.101, 0.001, 0.105,   nan,\n",
       "       0.087])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_case2.p_sim[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  nan, 0.001, 0.001, 0.001, 0.015, 0.098, 0.002, 0.104,   nan,\n",
       "       0.095])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(GeoDa_LJC.PP_VAL_C2[0:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences in p-values..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   nan,  0.   ,  0.   ,  0.   , -0.002,  0.003, -0.001,  0.001,\n",
       "          nan, -0.008])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_results_case2.p_sim[0:10] - np.array(GeoDa_LJC.PP_VAL_C2[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The correlation between the two sets of p-values is 0.9992982973684615\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1ed1c5c8>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assess correlation between p-values\n",
    "corrdf = pd.DataFrame(test_results_case2.p_sim, GeoDa_LJC.PP_VAL_C2).reset_index()\n",
    "corrdf.columns = ['pysal', 'geoda']\n",
    "print(\"The correlation between the two sets of p-values is\", corrdf['pysal'].corr(corrdf['geoda']))\n",
    "\n",
    "corrdf.plot.scatter(x='pysal',\n",
    "                    y='geoda',\n",
    "                    c='DarkBlue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planning out some `unittest`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# based off: https://github.com/pysal/esda/blob/master/esda/tests/test_join_counts.py\n",
    "import unittest\n",
    "import numpy as np\n",
    "from libpysal.weights.util import lat2W\n",
    "from libpysal.common import pandas\n",
    "\n",
    "PANDAS_EXTINCT = pandas is None\n",
    "\n",
    "class Local_Join_Counts_Tester(unittest.TestCase):\n",
    "    \"\"\"Unit test for Local Join Counts (univariate)\"\"\"\n",
    "    def setUp(self):\n",
    "        self.w = lat2W(4, 4)\n",
    "        self.x = np.ones(16)\n",
    "        self.x[0:8] = 0\n",
    "        self.z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "\n",
    "    def test_Local_Join_Counts(self):\n",
    "            \"\"\"Test method\"\"\"\n",
    "            np.random.seed(12345)\n",
    "            ljc_bv_case1 = Local_Join_Count_BV(connectivity=self.w).fit(self.x, self.z, case=\"BJC\")\n",
    "            ljc_bv_case2 = Local_Join_Count_BV(connectivity=self.w).fit(self.x, self.z, case=\"CLC\")\n",
    "            self.assertAlmostEqual(ljc_bv_case1.LJC, [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0])\n",
    "            self.assertAlmostEqual(ljc_bv_case2.LJC, [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2])\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    " \n",
    "- Migrating to numba (below)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from scipy import sparse\n",
    "from sklearn.base import BaseEstimator\n",
    "from libpysal import weights\n",
    "from esda.crand import (\n",
    "    crand as _crand_plus,\n",
    "    njit as _njit,\n",
    "    _prepare_univariate,\n",
    "    _prepare_bivariate\n",
    ")\n",
    "\n",
    "\n",
    "PERMUTATIONS = 999\n",
    "\n",
    "\n",
    "class Local_Join_Count_BV(BaseEstimator):\n",
    "\n",
    "    \"\"\"Univariate Local Join Count Statistic\"\"\"\n",
    "\n",
    "    def __init__(self, connectivity=None, permutations=PERMUTATIONS, n_jobs=1, \n",
    "                 keep_simulations=True, seed=None):\n",
    "        \"\"\"\n",
    "        Initialize a Local_Join_Count_BV estimator\n",
    "        Arguments\n",
    "        ---------\n",
    "        connectivity     : scipy.sparse matrix object\n",
    "                           the connectivity structure describing\n",
    "                           the relationships between observed units.\n",
    "                           Need not be row-standardized.\n",
    "        permutations     : int\n",
    "                           number of random permutations for calculation of pseudo\n",
    "                           p_values\n",
    "        n_jobs           : int\n",
    "                           Number of cores to be used in the conditional randomisation. If -1,\n",
    "                           all available cores are used.    \n",
    "        keep_simulations : Boolean\n",
    "                           (default=True)\n",
    "                           If True, the entire matrix of replications under the null \n",
    "                           is stored in memory and accessible; otherwise, replications \n",
    "                           are not saved\n",
    "        seed             : None/int\n",
    "                           Seed to ensure reproducibility of conditional randomizations. \n",
    "                           Must be set here, and not outside of the function, since numba \n",
    "                           does not correctly interpret external seeds \n",
    "                           nor numpy.random.RandomState instances.              \n",
    "                           \n",
    "        \"\"\"\n",
    "\n",
    "        self.connectivity = connectivity\n",
    "        self.permutations = permutations\n",
    "        self.n_jobs = n_jobs\n",
    "        self.keep_simulations = keep_simulations\n",
    "        self.seed = seed\n",
    "\n",
    "    def fit(self, x, z, case=\"CLC\", n_jobs=1, permutations=999):\n",
    "        \"\"\"\n",
    "        Arguments\n",
    "        ---------\n",
    "        x                : numpy.ndarray\n",
    "                           array containing binary (0/1) data\n",
    "        z                : numpy.ndarray\n",
    "                           array containing binary (0/1) data\n",
    "        Returns\n",
    "        -------\n",
    "        the fitted estimator.\n",
    "\n",
    "        Notes\n",
    "        -----\n",
    "        Technical details and derivations can be found in :cite:`AnselinLi2019`.\n",
    "\n",
    "        Examples\n",
    "        --------\n",
    "        >>> import libpysal\n",
    "        >>> w = libpysal.weights.lat2W(4, 4)\n",
    "        >>> x = np.ones(16)\n",
    "        >>> x[0:8] = 0\n",
    "        >>> z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]\n",
    "        >>> LJC_BV_C1 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"BJC\")\n",
    "        >>> LJC_BV_C2 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"CLC\")\n",
    "        >>> LJC_BV_C1.LJC\n",
    "        >>> LJC_BV_C1.p_sim\n",
    "        >>> LJC_BV_C2.LJC\n",
    "        >>> LJC_BV_C2.p_sim\n",
    "\n",
    "        Commpop data replicating GeoDa tutorial (Case 1)\n",
    "        >>> import libpysal\n",
    "        >>> import geopandas as gpd\n",
    "        >>> commpop = gpd.read_file(\"https://github.com/jeffcsauer/GSOC2020/raw/master/validation/data/commpop.gpkg\")\n",
    "        >>> w = libpysal.weights.Queen.from_dataframe(commpop)\n",
    "        >>> LJC_BV_Case1 = Local_Join_Count_BV(connectivity=w).fit(commpop['popneg'], commpop['popplus'], case='BJC')\n",
    "        >>> LJC_BV_Case1.LJC\n",
    "        >>> LJC_BV_Case1.p_sim\n",
    "\n",
    "        Guerry data replicating GeoDa tutorial (Case 2)\n",
    "        >>> import libpysal\n",
    "        >>> import geopandas as gpd\n",
    "        >>> guerry = libpysal.examples.load_example('Guerry')\n",
    "        >>> guerry_ds = gpd.read_file(guerry.get_path('Guerry.shp'))\n",
    "        >>> guerry_ds['infq5'] = 0\n",
    "        >>> guerry_ds['donq5'] = 0\n",
    "        >>> guerry_ds.loc[(guerry_ds['Infants'] > 23574), 'infq5'] = 1\n",
    "        >>> guerry_ds.loc[(guerry_ds['Donatns'] > 10973), 'donq5'] = 1\n",
    "        >>> w = libpysal.weights.Queen.from_dataframe(guerry_ds)\n",
    "        >>> LJC_BV_Case2 = Local_Join_Count_BV(connectivity=w).fit(guerry_ds['infq5'], guerry_ds['donq5'], case='CLC')\n",
    "        >>> LJC_BV_Case2.LJC\n",
    "        >>> LJC_BV_Case2.p_sim\n",
    "        \"\"\"\n",
    "        # Need to ensure that the np.array() are of\n",
    "        # dtype='float' for numba\n",
    "        x = np.array(x, dtype='float')\n",
    "        z = np.array(z, dtype='float')\n",
    "\n",
    "        w = self.connectivity\n",
    "        # Fill the diagonal with 0s\n",
    "        w = weights.util.fill_diagonal(w, val=0)\n",
    "        w.transform = 'b'\n",
    "\n",
    "        self.x = x\n",
    "        self.z = z\n",
    "        self.n = len(x)\n",
    "        self.w = w\n",
    "        self.case = case\n",
    "        \n",
    "        keep_simulations = self.keep_simulations\n",
    "        n_jobs = self.n_jobs\n",
    "        seed = self.seed\n",
    "\n",
    "        self.LJC = self._statistic(x, z, w, case=case)\n",
    "\n",
    "        if permutations:\n",
    "            if case == \"BJC\":\n",
    "                self.p_sim, self.rjoins = _crand_plus(\n",
    "                    z=np.column_stack((x, z)),\n",
    "                    w=self.w, \n",
    "                    observed=self.LJC,\n",
    "                    permutations=permutations, \n",
    "                    keep=True, \n",
    "                    n_jobs=n_jobs,\n",
    "                    stat_func=_ljc_bv_case1\n",
    "                )\n",
    "                # Set p-values for those with LJC of 0 to NaN\n",
    "                self.p_sim[self.LJC == 0] = 'NaN'\n",
    "            elif case == \"CLC\":\n",
    "                self.p_sim, self.rjoins = _crand_plus(\n",
    "                    z=np.column_stack((x, z)),\n",
    "                    w=self.w, \n",
    "                    observed=self.LJC,\n",
    "                    permutations=permutations, \n",
    "                    keep=True, \n",
    "                    n_jobs=n_jobs,\n",
    "                    stat_func=_ljc_bv_case2\n",
    "                )\n",
    "                # Set p-values for those with LJC of 0 to NaN\n",
    "                self.p_sim[self.LJC == 0] = 'NaN'\n",
    "            else:\n",
    "                raise NotImplementedError(f'The requested LJC method ({case}) \\\n",
    "                is not currently supported!')\n",
    "\n",
    "        del (self.n, self.keep_simulations, self.n_jobs, \n",
    "             self.permutations, self.seed, self.w, self.x,\n",
    "             self.z, self.connectivity, self.rjoins)\n",
    "                \n",
    "        return self\n",
    "\n",
    "    @staticmethod\n",
    "    def _statistic(x, z, w, case):\n",
    "        # Create adjacency list. Note that remove_symmetric=False - this is\n",
    "        # different from the esda.Join_Counts() function.\n",
    "        adj_list = w.to_adjlist(remove_symmetric=False)\n",
    "\n",
    "        # First, set up a series that maps the values\n",
    "        # to the weights table\n",
    "        zseries_x = pd.Series(x, index=w.id_order)\n",
    "        zseries_z = pd.Series(z, index=w.id_order)\n",
    "\n",
    "        # Map the values to the focal (i) values\n",
    "        focal_x = zseries_x.loc[adj_list.focal].values\n",
    "        focal_z = zseries_z.loc[adj_list.focal].values\n",
    "\n",
    "        # Map the values to the neighbor (j) values\n",
    "        neighbor_x = zseries_x.loc[adj_list.neighbor].values\n",
    "        neighbor_z = zseries_z.loc[adj_list.neighbor].values\n",
    "\n",
    "        if case == \"BJC\":\n",
    "            BJC = (focal_x == 1) & (focal_z == 0) & \\\n",
    "                  (neighbor_x == 0) & (neighbor_z == 1)\n",
    "            adj_list_BJC = pd.DataFrame(adj_list.focal.values,\n",
    "                                        BJC.astype('uint8')).reset_index()\n",
    "            adj_list_BJC.columns = ['BJC', 'ID']\n",
    "            adj_list_BJC = adj_list_BJC.groupby(by='ID').sum()\n",
    "            return (np.array(adj_list_BJC.BJC.values, dtype='float'))\n",
    "        elif case == \"CLC\":\n",
    "            CLC = (focal_x == 1) & (focal_z == 1) & \\\n",
    "                  (neighbor_x == 1) & (neighbor_z == 1)\n",
    "            adj_list_CLC = pd.DataFrame(adj_list.focal.values,\n",
    "                                        CLC.astype('uint8')).reset_index()\n",
    "            adj_list_CLC.columns = ['CLC', 'ID']\n",
    "            adj_list_CLC = adj_list_CLC.groupby(by='ID').sum()\n",
    "            return (np.array(adj_list_CLC.CLC.values, dtype='float'))\n",
    "        else:\n",
    "            raise NotImplementedError(f'The requested LJC method ({case}) \\\n",
    "            is not currently supported!')\n",
    "\n",
    "# --------------------------------------------------------------\n",
    "# Conditional Randomization Function Implementations\n",
    "# --------------------------------------------------------------\n",
    "\n",
    "# Note: scaling not used\n",
    "\n",
    "@_njit(fastmath=True)\n",
    "def _ljc_bv_case1(i, z, permuted_ids, weights_i, scaling):\n",
    "    zx = z[:, 0]\n",
    "    zy = z[:, 1]\n",
    "    zyi, zyrand = _prepare_univariate(i, zy, permuted_ids, weights_i)\n",
    "    return zx[i] * (zyrand @ weights_i)\n",
    "\n",
    "@_njit(fastmath=True)\n",
    "def _ljc_bv_case2(i, z, permuted_ids, weights_i, scaling):\n",
    "    zx = z[:, 0]\n",
    "    zy = z[:, 1]\n",
    "    zxi, zxrand, zyi, zyrand = _prepare_bivariate(i, z, permuted_ids, weights_i)\n",
    "    zf = zxrand * zyrand\n",
    "    return zy[i] * (zf @ weights_i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import libpysal\n",
    "w = libpysal.weights.lat2W(4, 4)\n",
    "x = np.ones(16)\n",
    "x[0:8] = 0\n",
    "z = [0,1,0,1,1,1,1,1,0,0,1,1,0,0,1,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "LJC_case1 = [0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0]\n",
    "LJC_case2 = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 0, 0, 2, 2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "LJC_BV_C1 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"BJC\")\n",
    "LJC_BV_C2 = Local_Join_Count_BV(connectivity=w).fit(x, z, case=\"CLC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  nan   nan   nan   nan   nan   nan   nan   nan 0.022 0.004   nan   nan\n",
      "   nan   nan   nan   nan]\n",
      "[  nan   nan   nan   nan   nan   nan   nan   nan   nan   nan 0.17  0.086\n",
      "   nan   nan 0.084 0.032]\n"
     ]
    }
   ],
   "source": [
    "print(LJC_BV_C1.p_sim)\n",
    "print(LJC_BV_C2.p_sim)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Validation of numba functions against real world datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'commpop' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-78b6aaeb6b3e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mLJC_BV_Case1_v2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLocal_Join_Count_BV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mconnectivity\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcommpop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'popneg'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcommpop\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'popplus'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcase\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'BJC'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'commpop' is not defined"
     ]
    }
   ],
   "source": [
    "LJC_BV_Case1_v2 = Local_Join_Count_BV(connectivity=w).fit(commpop['popneg'], commpop['popplus'], case='BJC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LJC_BV_Case1_v2.LJC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit Local_Join_Count_BV(connectivity=w).fit(commpop['popneg'], commpop['popplus'], case='BJC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((37.9-14.6)/37.9)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A 57% increase in speed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess correlation between p-values\n",
    "corrdf = pd.DataFrame(LJC_BV_Case1_v2.p_sim, commpop.PP_VAL_BV_C1).reset_index()\n",
    "corrdf.columns = ['pysal', 'geoda']\n",
    "print(\"The correlation between the two sets of p-values is\", corrdf['pysal'].corr(corrdf['geoda']))\n",
    "\n",
    "corrdf.plot.scatter(x='pysal',\n",
    "                    y='geoda',\n",
    "                    c='DarkBlue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparison of GeoDa bivariate LJC to PySAL implementation (Case 1):\")\n",
    "results = LJC_BV_Case1_v2.LJC == commpop['JC_BV_C1']\n",
    "print(results.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results_case2_v2 = Local_Join_Count_BV(connectivity=balt_knn5).fit(x_balt, z_balt, case=\"CLC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%timeit Local_Join_Count_BV(connectivity=balt_knn5).fit(x_balt, z_balt, case=\"CLC\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "((60.7 - 28.3)/60.7)*100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "53% increase in speed!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assess correlation between p-values\n",
    "corrdf = pd.DataFrame(test_results_case2_v2.p_sim, GeoDa_LJC.PP_VAL_C2).reset_index()\n",
    "corrdf.columns = ['pysal', 'geoda']\n",
    "print(\"The correlation between the two sets of p-values is\", corrdf['pysal'].corr(corrdf['geoda']))\n",
    "\n",
    "corrdf.plot.scatter(x='pysal',\n",
    "                    y='geoda',\n",
    "                    c='DarkBlue')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Comparison of GeoDa bivariate LJC to PySAL implementation (Case 2):\")\n",
    "results = test_results_case2_v2.LJC == GeoDa_LJC['JC_C2']\n",
    "print(results.value_counts())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
